# 파이토치에서의 학습 순서
1. 데이터를 불러오고, 순서대로 전처리를 해줄 pipeline를 구축.
	- 반드시 리스트의 형태로 만들어서, 순차적으로 처리되게 해야함.
ex)	데이터 세트를 텐서의 형태로 바꾸고, 평균 0.5, 표준편차 0.5로 전처리를 하는 순서.
	transform = torchvision.transforms.Compose([
		torchvision.transforms.ToTensor(),
		torchvision.Normalize((0.5,), (0.5,)])

2. 데이터 샘플(MNIST, FashionMNIST, CIFAR-10)을 훈련 세트 / 테스트 세트 들을 가져온다.(다운로드)
ex)	FashionMNIST의 경우
	train_dataset = torchvision.datasets.FashionMNIST(
		root='./fashionMNIST',
		train=True,
		download=True,
		transform=transform)

3. 학습 데이터 세트를 검증 데이터 세트로 나눔.
ex)	검증 세트를 20%만 떼준다면
	train_size = int(0.8 * len(train_dataset))
	val_size = len(train_dataset) - train_size
	train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])

4. 각 데이터 세트를 배치단위로 나누어줌.
ex)	각 데이터 세트를 64개의 배치 사이즈로 나눈다.
	train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
	test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)
	val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)

5. 파이토치에서의 모델 정의.
	: 아레는 nn.Module을 상속받는 내 모델을 정의한 클래스를 만든다.

ex) 	torch.nn.Module을 상속받는 클래스를 만들어서, Layer를 정의하고, 순전파, forward()를 정의한다.
class MyModel(nn.Module):
	def __init__(self):
		super(MyModel, self).__init__() # 이거로 부모 클래스의 생성자를 호출하여 부모 클래스의 기능을 사용할 수 있게 함. (model.train()이라던가, 등등)
		self.flatten = nn.Flatten()
		self. fc1 = nn.Linear(28*28, 100)
		self.relu = nn.ReLU()
		self.fc2 = nn.Linear(100, 10)
		self.softmax = nn.Softmax(dim=1) # 여기서 dim=1은 axis=1처럼 뒷 차원 것을 기준으로 사용할 것임을 의미.
	def forward(self, x): # model(inputs)를 하면 호출되는 순전파. 아레의 과정을 거쳐 학습이 진행됨.
		x = self.flatten(x) # x에는 예제에선 
		x = self.fc1(x)
		x = self.relu(x)
		x = self.fc2(x)
		x = self.softmax(x) # 얘는 cross_entropy_loss인 경우 안해도 자동으로 해준다고 함.
		return x
	- model = MyModel() # 을 통해서 모델을 객체화함.

6. optimizer와 criterion(손실함수)를 정의한다.
ex)	optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 모델의 학습 가능한 파라미터들을 미리 알려주어 학습 과정에서 업데이트할 대상으로 지정한다.
		- 미리 옵티마이저가 파라미터를 알지 못하면 어떤 값을 업데이트해야 할지 모름.
	criterion = nn.CrossEntropyLoss() # 모델의 예측과 실제 정답 간의 차이를 계산하는 손실 함수를 정의하는 역할을 함.

7. 실제 학습을 수행하는 함수 정의.
	: 학습을 어떻게 수행할 것인지를 함수로 만들어서 이 함수에 따라 학습이 진행되도록 함.
ex)	
    def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs = 50):
        for epoch in range(num_epochs): # 각 에포크마다 아레를 반복한다.
            model.train()  # 모델을 train()모드로 변환
            train_loss = 0 # 이번 에포크에서 계산할 손실값을 0으로 초기화함.
            correct_train = 0 # 학습 데이터 중 맞춘 것의 개수 초기화
            total_train = 0 # 학습 데이터의 총 개수 초기화
            correct_val = 0 # 검증 데이터 중 맞춘 개수 초기화
            total_val = 0 # 검증 데이터의 총 개수 초기화
            for inputs, targets in train_loader: # train_loader에 배치사이즈만큼 나누어져 들어가있음.
                optimizer.zero_grad() # 이전 배치에서 계산된 기울기가 현재에 영향을 미치지 않도록 함.
                outputs = model(inputs) # 순전파(Forward Pass)로 모델의 예측값을 계산함.
                loss = criterion(outputs, targets) # 예측값과 정답 간의 손실을 계산.
                loss.backward() # 역전파(Backward) 계산한 손실을 기준으로 각 파라미터의 기울기를 계산한다.
                optimizer.step() # 계산한 파라미터의 기울기를 기반으로 모델을 파라미터를 업데이트함.
                train_loss += loss.item() # 이번 batch에서의 손실값을 누적해서 더해줌.
                _, predicted = torch.max(outputs, dim=1) # 최종적으로 softmax를 통해 나온 데이터 하나(1, 10)일텐데, 중 가장 큰 (값, index)를 받아서 predicted에 index를 받음.
                correct_train += (predicted == targets).sum().item() # 예측한 index와 정답을 비교해 맞으면 .item()으로 자료형으로 바꿔서 더해줌.
                total_train += targets.size(dim=0) # targets는 (배치 사이즈, 1)의 크기일텐데 그러니까 이걸 데이터 개수만큼 더해준것임.
            
            model.eval() # 검증을 하는 과정은 위와 동일함.
            val_loss =  0
            with torch.no_grad():
                for inputs, targets in val_loader:
                    outputs = model(inputs)
                    loss = criterion(outputs, targets)
                    val_loss += loss.item()
                    # 정확도
                    _, predicted = torch.max(outputs, dim=1)
                    correct_val = correct_val + (predicted == targets).sum().item()
                    total_val += targets.size(dim=0)
                    
            train_loss /= len(train_loader) # 검증 세트와 훈련 세트의 개수가 다르니, 개수로 나눠줘서 평균 손실값을 계산하는것임.
            val_loss /= len(val_loader)
            
            
            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {(correct_train/total_train):.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {(correct_val/total_val):.4f}') # 출력을 위한 코드
        torch.save(model.state_dict(), 'final_model.pth') # 현재 모델에 저장된 파라미터들의 가중치를 다운로드하여 나중에 바로 불러와서 학습하면 같은 결과가 나올 것.


8. 조기종료를 위한 callback에 대해 공부해보자. 
	: 내가 epoch를 설정하여 학습을 하면 잘 맞추지 않는 이상, 최적의 결과를 얻기 힘들 것이다. (overfitting or underfitting)
	- 그렇기 때문에, validation loss의 값이 일정 수준 줄어들었다가, 다시 증가하는 시점에 조기종료를 실행하고, validation loss가 제일 낮았던 시점의 모델을 저장하도록 변경해보자.
	1. train_model()에 patience 매개변수를 추가함.
	2. 함수의 여러 멤버변수를 추가함
		- best_model_state = None # 가장 최고의 성능이었을 때의 모델의 가중치 파라미터를 저장하기 위해 저장할 객체를 만들어놓는것임.
		- best_val_loss = float('inf') # 가장 validation loss가 낮았을 때를 저장해서 증가했는지를 비교할 값을 저장함. float('inf')(최대)로 하여 무조건 첫 번째 epoch에 validation_loss를 저장하도록 함.
		- patience_counter = 0 # 이게 매개변수 patience와 같아지면 학습을 종료하고, 저장해 놓은 model.state_dict()를 이용하여 모델을 저장한다.
ex)	각 epoch의 마지막에 다음의 코드를 추가함.
	if val_loss < best_val_loss: # 이번 validation_loss가 지금까지의 최소 validation_loss보다 작다면 
		best_val_loss = val_loss # best_val_loss를 업데이트함.
		patience_counter = 0 # patience_counter를 0으로 초기화
		best_model_state = model.state_dict() # 지금 매개변수 가중치를 저장함.
	else:
		patience_counter += 1 # 그게 아니라면 patience_counter를 1증가시킴.
		if patience_counter >= patience: # 넘어선다면
			break # 학습을 종료함 (epoch반복문 종료)
torch.save(best_model_state, 'pytorch/best_model.pth') # 학습이 종료된 후 저장함.


9. dropout층과 Batch Normalization층.
	- dropout 
		: 과적합을 방지하기 위해 사용되며, 뉴런을 무작위로 비활성화하여 학습 중에 각 뉴런의 의존성을 줄인다.
		- Fully Connected Layer에서 주로 사용함. (Linear층과 Linear층 사이에)
ex)	이런 순서로 진행됨
	x = fc(x)
	x = relu(x)
	x = dropout(x)
	x = fc2(x)
	- Batch Normalization 
		: 학습 속도를 높이고, 안정적인 학습을 위해 각 층의 입력을 정규화하여 분포가 변하지 않도록 한다. / 각 미니배치의 평균과 표준편차를 사용해 정규화하여, 학습을 더 안정적이고 빠르게 만드는 기법.
		- Convolution층에서 주로 사용함. 
ex)	이런 순서로 진행됨.
	x = self.conv1(x)
	x = self.batchnorm1(x)
	x = self.relu(x)
	x = self.pooling(x)
	x = self.conv2(x)


### 이미지 분류 문제에서의 활성화 함수
	1. ReLU : f = max(0, x)
		- 입력값이 0보다 크면 그대로 반환하고, 0보다 작으면 0을 반환한다.
	2. 





### Optimizer
1. Adam
	작동 방식 : SGD와 RMSprop의 개념을 결합한 옵티마이저임.
	장점 :
		- 빠른 수렴 속도
		- 적응적 학습률(각 파라미터에 학습률이 다르게 설정됨) → backward()에서 계산된 기울기 정보를 사		용하여 파라미터별로 학습률을 자동으로 조절한다.
		하지만, lr = 0.0001로 설정한 그 lr에 크게 벗어나게 다르진 않음.
	단점 : 
		- 빠르게 수렴하지만, 수렴 이후 진동을 일으킬 수 있다. # 조기종료를 적용해야함.
	- 하이퍼 파라미터
		1. betas=(0.9, 0.999) # 모멘텀과 2차 모멘트 추정에 사용되는 감쇠 계수.
		2. weight_decay = 1e-5 (정규화 항으로 파라미터 값이 너무 커지는 것을 방지함.)
		3. eps = 1e-8 (분모가 0으로 나눠지는 것을 방지)
		4. lr

2. Adagrad
	작동 방식 
		: 각 파라미터마다 학습률을 개별적으로 조정하여 학습 속도를 최적화함.
		- 이전 기울기들의 제곱합을 기반으로 학습률을 점진적으로 줄여가면서 업데이트함.
		- 기울기가 큰 경우에는 학습률이 줄어들고, 작은 경우에는 학습률이 상대적으로 커진다. (이전까지의 epoch들에서 학습되었던 각 파라미터마다의 기울기의 제곱합(G_t)을 추적하고, 이게 크다면, 자주 업데이트된 파라미터라는 의미기 때문에 이 파라미터의 학습률을 줄이고, G_t가 작다면, 드물게 업데이트되는 파라미터이므로 더 많이 업데이트 될 수 있도록 학습률을 올려준다. 
		- 위의 과정을 통해 각 파라미터가 골고루 잘 학습되어 모델에 영향을 미치도록 함.
	단점:
		- 학습률이 계속해서 감소하게 되어 학습 속도가 느려지게 됨.
	- 하이퍼 파라미터
		1. lr
		2. lr_decay : 학습률 감소 값. 학습이 진행될수록 학습률을 줄이기 위한 매개변수
		3. weight_decay : 정규화를 통해 과적합을 방지함.
		4. eps


3. RMSprop
	작동 방식 
		: 기울기의 제곱에 대한 지수 이동 평균(EMA)을 사용하여 기울기의 2차 모멘트를 추적하고 이를 사용하여 학습률을 조정함.
		- 파라미터가 E[g^2]_t에 반비례 하여 이 값이 커지면 적게 업데이트되고, 작으면 크게 업데이트된다.
		- 뭔소린지 모르겠다.
		///
		- Adagrad의 단점인 학습률이 점점 줄어드는 것을 보완하기 위해 나옴.
		- 수렴 속도가 Adagrad보다 개선되었다.
		- 손실 곡률에 맞는 적응적 학습률을 제공해준다.
	- 하이퍼 파라미터
		1. alpha (감쇠율, 지수가중이동 평균을 계산할 때 사용) # 1에 가까울수록 기울기의 최근 변화에 더 많은 가중치를 둔다.
		2. eps (작은 상수 입실론인데, 분모가 0이되는걸 방지한다?)
		3. weight_decay (가중치 감소, default:0)
		4. momentum (모멘텀을 추가할 수 있다. default:0) # 이전의 기울기를 일정 비율 추가하여 최적화 과정을 가속화한다.

4. SGD(+momentum)
	: 미니 배치(batch) 또는 데이터 샘플을 사용하여 기울기(gradient)를 계산하고, 해당 기울기를 사용하여 파라미터를 업데이트한다.
	- Momentum은 기울기 업데이트를 할 때 이전 업데이트 값을 일정 비율 가중치를 부여하여 더해준다. 이렇게 해서 느린 수렴속도를 더 빠르게 해준다.
	- 특징 : 느리지만 안정적으로 수렴함. 진동도 적다.
	- 하이퍼 파라미터
		1. lr
		2. momentum : SGD에서는 기본값은 0.0이지만, 0.9로 설정하는것이 일반적이다. 
		3. weight_decay : 가중치 감소, 정규화를 통해 과적합을 방지함.
		4. nesterov : Nesterov라는 모멘텀을 사용할지 여부를 결정함. # 표준 모멘텀보다 더 빠르게 수렴하도록 도와준다.
		

# 바꿀만한 Optimizer의 하이퍼파라미터
1. learn rate(lr) = 몇으로 할 지 0.0001 0.001 0.01
2. 


### 활성화 함수
	1. ReLU : 
	2. Leaky ReLU : 
	3. ELU : 
	4. Sigmoid : 
	5. Tanh : 

### 드롭아웃 바꿔보기

### 손실함수 바꿔보기
	1. CrossEntropyLoss
		: 다중 클래스 분류 문제에서 기본적으로 많이 사용되는 손실 함수.
		- 모델이 예측한 클래스 확률과 실제 정답 간의 차이를 측정한다.
		- 정답에 해당하는 클래스의 확률이 낮을수록 손실값이 커진다.
		// 얘가 softmax로 각 클래스에 대한 확률을 뱉는데, 실제 정답인 클래스에 대한 확률이 낮을수록 loss가 커진다는 것 같다.
	2. Negative Log Likelihood Loss(NLLLoss)
		: CrossEntropyLoss와 유사하지만, 출력에 softmax를 적용하지 않고 로그 확률을 사용하는 경우 적합.
	3. Mean Squared Error Loss (MSELoss) 
		: 일반적으로 회귀 문제에 사용되지만, 분류 문제에서 가끔 실험적으로 사용함? 
	4. Focal Loss 
		: 클래스 불균형 문제를 다룰 때 유용한 손실함수, 어려운 샘플에 더 많은 가중치를 부여한다.










