# 파이토치에서의 학습 순서
1. 데이터를 불러오고, 순서대로 전처리를 해줄 pipeline를 구축.
ex)	데이터 세트를 텐서의 형태로 바꾸고, 평균 0.5, 표준편차 0.5로 전처리를 하는 순서.
	transform = torchvision.transforms.Compose(
		torchvision.transforms.ToTensor(),
		torchvision.Normalize((0.5,), (0.5,))

2. 데이터 샘플(MNIST, FashionMNIST, CIFAR-10)을 훈련 세트 / 테스트 세트 들을 가져온다.(다운로드)
ex)	FashionMNIST의 경우
	train_dataset = torchvision.datasets.FashionMNIST(
		root='./fashionMNIST',
		train=True,
		download=True,
		transform=transform

3. 학습 데이터 세트를 검증 데이터 세트로 나눔.
ex)	검증 세트를 20%만 떼준다면
	train_size = int(0.8 * len(train_dataset))
	val_size = len(train_dataset) - train_size
	train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])

4. 각 데이터 세트를 배치단위로 나누어줌.
ex)	각 데이터 세트를 64개의 배치 사이즈로 나눈다.
	train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
	test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)
	val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)

5. 파이토치에서의 모델 정의.
	: 아레는 nn.Module을 상속받는 내 모델을 정의한 클래스를 만든다.

ex) 	torch.nn.Module을 상속받는 클래스를 만들어서, Layer를 정의하고, 순전파, forward()를 정의한다.
class MyModel(nn.Module):
	def __init__(self):
		super(MyModel, self).__init__() # 이거로 부모 클래스의 생성자를 호출하여 부모 클래스의 기능을 사용할 수 있게 함. (model.train()이라던가, 등등)
		self.flatten = nn.Flatten()
		self. fc1 = nn.Linear(28*28, 100)
		self.relu = nn.LeRU()
		self.fc2 = nn.Linear(100, 10)
		self.softmax = nn.Softmax(dim=1) # 여기서 dim=1은 axis=1처럼 뒷 차원 것을 기준으로 사용할 것임을 의미.
	def forward(self, x): # model(inputs)를 하면 호출되는 순전파. 아레의 과정을 거쳐 학습이 진행됨.
		x = self.flatten(x) # x에는 예제에선 
		x = self.fc1(x)
		x = self.relu(x)
		x = self.fc2(x)
		x = self.softmax(x) # 얘는 cross_entropy_loss인 경우 안해도 자동으로 해준다고 함.
		return x
	- model = MyModel() # 을 통해서 모델을 객체화함.

6. optimizer와 criterion(손실함수)를 정의한다.
ex)	optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 모델의 학습 가능한 파라미터들을 미리 알려주어 학습 과정에서 업데이트할 대상으로 지정한다.
		- 미리 옵티마이저가 파라미터를 알지 못하면 어떤 값을 업데이트해야 할지 모름.
	criterion = nn.CrossEntropyLoss() # 모델의 예측과 실제 정답 간의 차이를 계산하는 손실 함수를 정의하는 역할을 함.

7. 실제 학습을 수행하는 함수 정의.
	: 학습을 어떻게 수행할 것인지를 함수로 만들어서 이 함수에 따라 학습이 진행되도록 함.
ex)	
    def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs = 50):
        for epoch in range(num_epochs): # 각 에포크마다 아레를 반복한다.
            model.train()  # 모델을 train()모드로 변환
            train_loss = 0 # 이번 에포크에서 계산할 손실값을 0으로 초기화함.
            correct_train = 0 # 학습 데이터 중 맞춘 것의 개수 초기화
            total_train = 0 # 학습 데이터의 총 개수 초기화
            correct_val = 0 # 검증 데이터 중 맞춘 개수 초기화
            total_val = 0 # 검증 데이터의 총 개수 초기화
            for inputs, targets in train_loader: # train_loader에 배치사이즈만큼 나누어져 들어가있음.
                optimizer.zero_grad() # 이전 배치에서 계산된 기울기가 현재에 영향을 미치지 않도록 함.
                outputs = model(inputs) # 순전파(Forward Pass)로 모델의 예측값을 계산함.
                loss = criterion(outputs, targets) # 예측값과 정답 간의 손실을 계산.
                loss.backward() # 역전파(Backward) 계산한 손실을 기준으로 각 파라미터의 기울기를 계산한다.
                optimizer.step() # 계산한 파라미터의 기울기를 기반으로 모델을 파라미터를 업데이트함.
                train_loss += loss.item() # 이번 batch에서의 손실값을 누적해서 더해줌.
                _, predicted = torch.max(outputs, dim=1) # 최종적으로 softmax를 통해 나온 데이터 하나(1, 10)일텐데, 중 가장 큰 (값, index)를 받아서 predicted에 index를 받음.
                correct_train += (predicted == targets).sum().item() # 예측한 index와 정답을 비교해 맞으면 .item()으로 자료형으로 바꿔서 더해줌.
                total_train += targets.size(dim=0) # targets는 (배치 사이즈, 1)의 크기일텐데 그러니까 이걸 데이터 개수만큼 더해준것임.
            
            model.eval() # 검증을 하는 과정은 위와 동일함.
            val_loss =  0
            with torch.no_grad():
                for inputs, targets in val_loader:
                    outputs = model(inputs)
                    loss = criterion(outputs, targets)
                    val_loss += loss.item()
                    # 정확도
                    _, predicted = torch.max(outputs, dim=1)
                    correct_val = correct_val + (predicted == targets).sum().item()
                    total_val += targets.size(dim=0)
                    
            train_loss /= len(train_loader) # 검증 세트와 훈련 세트의 개수가 다르니, 개수로 나눠줘서 평균 손실값을 계산하는것임.
            val_loss /= len(val_loader)
            
            
            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {(correct_train/total_train):.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {(correct_val/total_val):.4f}') # 출력을 위한 코드
        torch.save(model.state_dict(), 'final_model.pth') # 현재 모델에 저장된 파라미터들의 가중치를 다운로드하여 나중에 바로 불러와서 학습하면 같은 결과가 나올 것.


8. 조기종료를 위한 callback에 대해 공부해보자. 
	: 내가 epoch를 설정하여 학습을 하면 잘 맞추지 않는 이상, 최적의 결과를 얻기 힘들 것이다. (overfitting or underfitting)
	- 그렇기 때문에, validation loss의 값이 일정 수준 줄어들었다가, 다시 증가하는 시점에 조기종료를 실행하고, validation loss가 제일 낮았던 시점의 모델을 저장하도록 변경해보자.
	1. train_model()에 patience 매개변수를 추가함.
	2. 함수의 여러 멤버변수를 추가함
		- best_model_state = None # 가장 최고의 성능이었을 때의 모델의 가중치 파라미터를 저장하기 위해 저장할 객체를 만들어놓는것임.
		- best_val_loss = float('inf') # 가장 validation loss가 낮았을 때를 저장해서 증가했는지를 비교할 값을 저장함. float('inf')(최대)로 하여 무조건 첫 번째 epoch에 validation_loss를 저장하도록 함.
		- patience_counter = 0 # 이게 매개변수 patience와 같아지면 학습을 종료하고, 저장해 놓은 model.state_dict()를 이용하여 모델을 저장한다.
ex)	각 epoch의 마지막에 다음의 코드를 추가함.
	if val_loss < best_val_loss: # 이번 validation_loss가 지금까지의 최소 validation_loss보다 작다면 
		best_val_loss = val_loss # best_val_loss를 업데이트함.
		patience_counter = 0 # patience_counter를 0으로 초기화
		best_model_state = model.state_dict() # 지금 매개변수 가중치를 저장함.
	else:
		patience_counter += 1 # 그게 아니라면 patience_counter를 1증가시킴.
		if patience_counter >= patience: # 넘어선다면
			break # 학습을 종료함 (epoch반복문 종료)
torch.save(best_model_state, 'pytorch/best_model.pth') # 학습이 종료된 후 저장함.


9. dropout층과 Batch Normalization층.
	- dropout 
		: 과적합을 방지하기 위해 사용되며, 뉴런을 무작위로 비활성화하여 학습 중에 각 뉴런의 의존성을 줄인다.
		- Fully Connected Layer에서 주로 사용함. (Linear층과 Linear층 사이에)
ex)	이런 순서로 진행됨
	x = fc(x)
	x = relu(x)
	x = dropout(x)
	x = fc2(x)
	- Batch Normalization 
		: 학습 속도를 높이고, 안정적인 학습을 위해 각 층의 입력을 정규화하여 분포가 변하지 않도록 한다. / 각 미니배치의 평균과 표준편차를 사용해 정규화하여, 학습을 더 안정적이고 빠르게 만드는 기법.
		- Convolution층에서 주로 사용함. 
ex)	이런 순서로 진행됨.
	x = self.conv1(x)
	x = self.batchnorm1(x)
	x = self.relu(x)
	x = self.pooling(x)
	x = self.conv2(x)



















