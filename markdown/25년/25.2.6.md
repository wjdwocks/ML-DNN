### 해야 할 것
<li> 2 Teacher (GAF + Sig) 에 대해서 14cls에 대해서 코드를 만들어야 함. (서버에서 돌아가도록 공부해서 만들기.) (완) </li>
<li> 14cls에 대해서는 161-161, 163-161, 281-161, 283-161 조합에 대해 모두 해봐야함. (완) </li>
<li> alpha값 (KD1과 KD2 간의 비중을 0.1, 0.3, 0.5, 0.7, 0.9에 대해서 비교해보기 (3번씩 계산 후 평균 + 표준편차)) (하는중 하루이틀정도 걸릴듯) </li>
<li> 이제는 7cls에 대해서도 GAF를 만들고, GAF Teacher를 만들고, 지금까지 했던 것들을 모두 똑같이 해야 함. (완) </li>
<li> 7cls-500w, 7cls-1000w 에 대해서 각각 GAF만들고, GAF Teacher 학습하고(vanila), 1 Teacher(GAF) KD도 결과를 내보는 것이 목표. (완) </li>
<li> TPKD 논문 9 ~ 11p 부분을 보고, 14cls와 7cls의 결과를 확인하며 비교해보자. (오케이) </li>
<li> PAMAP2 데이터셋에 대해서도 GAF로 변환하고, 위와같은 작업을 수행해야 함. </li>


### 물어볼 것
1. PAMAP2데이터셋에서 30hz와 100hz 데이터의 차이. (둘 다 해봐야하나?) (30hz가 논문에서 말한 33.3hz를 말하는것이라고 함.)
2. Annealing할 때 Student에 어떤 얘를 넣어줄지. (Teacher2에 넣은 그대로 넣는다.)

### 다음주에 할 것.
1. Annealing을 적용한 GENE 14cls, GENE 7cls 결과 내기.
2. Annealing + TPKD(SP Loss를 적용한) GENE 14cls, 7cls 결과내기
3. PAMAP 최대한 진도 빼기 (여기는 엄청오래걸릴듯.)


### 지금까지 결과 추가 (2-Teacher, 14cls)
<li> T1 : WRN16-1(GAF), T2 : WRN16-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 69.7864 </li>
<li> 70.6720 </li>
<li> 70.3247 </li>
<li> 평균 : 70.2610 </li>
<li> 표준편차 : 0.3643 </li>
<br>
</ul>

<li> T1 : WRN16-3(GAF), T2 : WRN16-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 70.1511 </li>
<li> 70.3421 </li>
<li> 70.5504 </li>
<li> 평균 : 70.3479 </li>
<li> 표준편차 : 0.1631 </li>
<br>
</ul>

<li> T1 : WRN28-1(GAF), T2 : WRN28-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 69.2134 </li>
<li> 70.3073 </li>
<li> 69.7517 </li>
<li> 평균 : 69.7575 </li>
<li> 표준편차 : 0.4466 </li>
<br>
</ul>

<li> T1 : WRN28-3(GAF), T2 : WRN28-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 70.5504 </li>
<li> 70.3247 </li>
<li> 69.5781 </li>
<li> 평균 : 70.1511 </li>
<li> 표준편차 : 0.4155 </li>
<br>
</ul>

### 지금까지 결과 추가 (Teacher Network, 7cls, 500w)
<li> Single : WRN161 </li>
<ul>
<li> 84.5852 </li>
<li> 84.8465 </li>
<li> 85.0425 </li>
<li> 평균 : 84.8247 </li>
<li> 표준편차 : 0.1873 </li>
<br>
</ul>

<li> Single : WRN163 </li>
<ul>
<li> 85.4017 </li>
<li> 85.6956 </li>
<li> 86.1855 </li>
<li> 평균 : 85.7609 </li>
<li> 표준편차 : 0.3233 </li>
<br>
</ul>

<li> Single : WRN281 </li>
<ul>
<li> 85.4344 </li>
<li> 84.7159 </li>
<li> 85.0098 </li>
<li> 평균 : 85.0534 </li>
<li> 표준편차 : 0.2949 </li>
<br>
</ul>

<li> Single : WRN283 </li>
<ul>
<li> 86.8060 </li>
<li> 87.1326 </li>
<li> 86.0222 </li>
<li> 평균 : 86.6536 </li>
<li> 표준편차 : 0.4660 </li>
<br>
</ul>

### 지금까지 결과 추가 (Teacher Network, 7cls, 1000w)
<li> Single : WRN161 </li>
<ul>
<li> 84.2913 </li>
<li> 84.9118 </li>
<li> 84.6179 </li>
<li> 평균 : 84.6070 </li>
<li> 표준편차 : 0.2534 </li>
<br>
</ul>

<li> Single : WRN163 </li>
<ul>
<li> 85.4997 </li>
<li> 86.4468 </li>
<li> 86.4468 </li>
<li> 평균 : 86.1311 </li>
<li> 표준편차 : 0.4465 </li>
<br>
</ul>

<li> Single : WRN281 </li>
<ul>
<li> 84.8465 </li>
<li> 84.8792 </li>
<li> 85.1078 </li>
<li> 평균 : 84.9445 </li>
<li> 표준편차 : 0.1162 </li>
<br>
</ul>

<li> Single : WRN283 </li>
<ul>
<li> 86.4794 </li>
<li> 86.6101 </li>
<li> 85.9569 </li>
<li> 평균 : 86.3488 </li>
<li> 표준편차 : 0.2822 </li>
<br>
</ul>

### 지금까지 결과 추가 (1 Teacher KD, 7cls, 500w)
<li> Teacher : WRN161, Student : WRN1611 </li>
<ul>
<li> 89.3860 </li>
<li> 89.6473 </li>
<li> 89.7453 </li>
<li> 평균 : 89.5929 </li>
<li> 표준편차 : 0.1516 </li>
<br>
</ul>

<li> Teacher : WRN163, Student : WRN1611 </li>
<ul>
<li> 89.3534 </li>
<li> 88.7002 </li>
<li> 89.0268 </li>
<li> 평균 : 89.0268 </li>
<li> 표준편차 : 0.2667 </li>
<br>
</ul>

### 지금까지 결과 추가 (1 Teacher KD, 7cls, 1000w)
<li> Teacher : WRN161, Student : WRN1611 </li>
<ul>
<li> 89.8106 </li>
<li> 90.3005 </li>
<li> 90.1045 </li>
<li> 평균 : 90.0719 </li>
<li> 표준편차 : 0.2013 </li>
<br>
</ul>

<li> Teacher : WRN163, Student : WRN1611 </li>
<ul>
<li> 89.9412 </li>
<li> 89.8106 </li>
<li> 89.1574 </li>
<li> 평균 : 89.6364 </li>
<li> 표준편차 : 0.3429 </li>
<br>
</ul>


### 지금까지 결과 추가 (2 Teacher KD, 7cls, 500w)
<li> Teacher1 : WRN161, Teacher2 : WRN1611, Student : WRN1611 </li>
<ul>
<li> 91.0516 </li>
<li> 89.5820 </li>
<li> 89.9412 </li>
<li> 평균 : 90.1916 </li>
<li> 표준편차 : 0.6255 </li>
<br>
</ul>

<li> Teacher1 : WRN163, Teacher2 : WRN1631, Student : WRN1611 </li>
<ul>
<li> 90.6924 </li>
<li> 90.4637 </li>
<li> 90.3658 </li>
<li> 평균 : 90.5073 </li>
<li> 표준편차 : 0.1369 </li>
<br>
</ul>


### 지금까지 결과 추가 (2 Teacher KD, 7cls, 1000w)
<li> Teacher1 : WRN161, Teacher2 : WRN1611, Student : WRN1611 </li>
<ul>
<li> 90.0392 </li>
<li> 89.0268 </li>
<li> 89.3860 </li>
<li> 평균 : 89.4840 </li>
<li> 표준편차 : 0.4191 </li>
<br>
</ul>

<li> Teacher1 : WRN163, Teacher2 : WRN1631, Student : WRN1611 </li>
<ul>
<li> 90.0065 </li>
<li> 90.4311 </li>
<li> 89.7779 </li>
<li> 평균 : 90.0718 </li>
<li> 표준편차 : 0.2706 </li>
<br>
</ul>

### 500w, 14cls에 대한 실험 결과
| Experiment (alpha = 0.3, 500w, 14cls)                                                        | Trial 1  | Trial 2  | Trial 3  | Mean               | Std     |
|----------------------------------------------------------------------------------------------|----------|----------|----------|--------------------|---------|
| WRN16-1 (GAF 단일 네트워크, 500w, 14cls)                                                      | 63.0491  | 63.3270  | 62.9797  | <u>**63.1186**</u> | 0.1501  |
| WRN16-3 (GAF 단일 네트워크, 500w, 14cls)                                                      | 64.0389  | 63.9521  | 63.9173  | <u>**63.9694**</u> | 0.0511  |
| WRN28-1 (GAF 단일 네트워크, 500w, 14cls)                                                      | 63.2922  | 64.0042  | 63.3096  | <u>**63.5353**</u> | 0.3316  |
| WRN28-3 (GAF 단일 네트워크, 500w, 14cls)                                                      | 64.1604  | 64.8029  | 65.3933  | <u>**64.7855**</u> | 0.5035  |
| T: WRN16-1(GAF), S: WRN16-1(sig) (500w, 14cls)                                               | 68.9703  | 67.6680  | 67.0429  | <u>**67.8937**</u> | 0.8029  |
| T: WRN16-3(GAF), S: WRN16-1(sig) (500w, 14cls)                                               | 68.2063  | 67.7201  | 68.3278  | <u>**68.0847**</u> | 0.2626  |
| T: WRN28-1(GAF), S: WRN16-1(sig) (500w, 14cls)                                               | 67.0082  | 66.4004  | 67.0603  | <u>**66.8230**</u> | 0.2996  |
| T: WRN28-3(GAF), S: WRN16-1(sig) (500w, 14cls)                                               | 67.5464  | 66.4872  | 67.7027  | <u>**67.2454**</u> | 0.5399  |
| T1: WRN16-1(GAF), T2: WRN16-1(Sig), S: WRN16-1(sig) (2-Teacher, 14cls)                       | 69.7864  | 70.6720  | 70.3247  | <u>**70.2610**</u> | 0.3643  |
| T1: WRN16-3(GAF), T2: WRN16-3(Sig), S: WRN16-1(sig) (2-Teacher, 14cls)                       | 70.1511  | 70.3421  | 70.5504  | <u>**70.3479**</u> | 0.1631  |
| T1: WRN28-1(GAF), T2: WRN28-1(Sig), S: WRN16-1(sig) (2-Teacher, 14cls)                       | 69.2134  | 70.3073  | 69.7517  | <u>**69.7575**</u> | 0.4466  |
| T1: WRN28-3(GAF), T2: WRN28-3(Sig), S: WRN16-1(sig) (2-Teacher, 14cls)                       | 70.5504  | 70.3247  | 69.5781  | <u>**70.1511**</u> | 0.4155  |

### 500w, 7cls에 대한 실험 결과
| Experiment (alpha = 0.3, 500w, 7cls)                                                         | Trial 1  | Trial 2  | Trial 3  | Mean               | Std     |
|----------------------------------------------------------------------------------------------|----------|----------|----------|--------------------|---------|
| Single: WRN161 (Teacher Network, 7cls, 500w)                                                 | 84.5852  | 84.8465  | 85.0425  | <u>**84.8247**</u> | 0.1873  |
| Single: WRN163 (Teacher Network, 7cls, 500w)                                                 | 85.4017  | 85.6956  | 86.1855  | <u>**85.7609**</u> | 0.3233  |
| Single: WRN281 (Teacher Network, 7cls, 500w)                                                 | 85.4344  | 84.7159  | 85.0098  | <u>**85.0534**</u> | 0.2949  |
| Single: WRN283 (Teacher Network, 7cls, 500w)                                                 | 86.8060  | 87.1326  | 86.0222  | <u>**86.6536**</u> | 0.4660  |
| T: WRN16-1(GAF), S: WRN16-1(Sig) (7cls, 500w)                                                | 89.8106  | 90.3005  | 90.1045  | <u>**90.0719**</u> | 0.2013  |
| T: WRN16-3(GAF), S: WRN16-1(Sig) (7cls, 500w)                                                | 89.9412  | 89.8106  | 89.1574  | <u>**89.6364**</u> | 0.3429  |
| T1: WRN16-1(GAF), T2: WRN16-1(Sig), S: WRN16-1(Sig) (7cls, 500w)                             | 90.0392  | 89.0268  | 89.3860  | <u>**89.4840**</u> | 0.4191  |
| T1: WRN16-3(GAF), T2: WRN16-3(Sig), S: WRN16-1(Sig) (7cls, 500w)                             | 90.0065  | 90.4311  | 89.7779  | <u>**90.0718**</u> | 0.2706  |

### 1000w, 7cls에 대한 실험 결과
| Experiment (alpha = 0.3, 1000w, 7cls)                                                        | Trial 1  | Trial 2  | Trial 3  | Mean               | Std     |
|----------------------------------------------------------------------------------------------|----------|----------|----------|--------------------|---------|
| Single: WRN161 (Teacher Network, 7cls, 1000w)                                                | 84.2913  | 84.9118  | 84.6179  | <u>**84.6070**</u> | 0.2534  |
| Single: WRN163 (Teacher Network, 7cls, 1000w)                                                | 85.4997  | 86.4468  | 86.4468  | <u>**86.1311**</u> | 0.4465  |
| Single: WRN281 (Teacher Network, 7cls, 1000w)                                                | 84.8465  | 84.8792  | 85.1078  | <u>**84.9445**</u> | 0.1162  |
| Single: WRN283 (Teacher Network, 7cls, 1000w)                                                | 86.4794  | 86.6101  | 85.9569  | <u>**86.3488**</u> | 0.2822  |
| T: WRN16-1(GAF), S: WRN16-1(Sig) (7cls, 1000w)                                               | 89.3860  | 89.6473  | 89.7453  | <u>**89.5929**</u> | 0.1516  |
| T: WRN16-3(GAF), S: WRN16-1(Sig) (7cls, 1000w)                                               | 89.3534  | 88.7002  | 89.0268  | <u>**89.0268**</u> | 0.2667  |
| T1: WRN16-1(GAF), T2: WRN16-1(Sig), S: WRN16-1(Sig) (7cls, 1000w)                            | 91.0516  | 89.5820  | 89.9412  | <u>**90.1916**</u> | 0.6255  |
| T1: WRN16-3(GAF), T2: WRN16-3(Sig), S: WRN16-1(Sig) (7cls, 1000w)                            | 90.6924  | 90.4637  | 90.3658  | <u>**90.5073**</u> | 0.1369  |

## Alpha값 바꿔가며 추가 실험 결과
### Alpha = 0.1

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|--------|--------|--------|--------|--------|
| T1: WRN161(GAF), T2: WRN1611(Sig), S: WRN1611 (14cls) | 69.1439 | 69.9080 | 70.0642 | **69.7054** | 0.4021 |
| T1: WRN163(GAF), T2: WRN1631(Sig), S: WRN1611 (14cls) | 70.8283 | 70.9151 | 70.9325 | **70.8920** | 0.0456 |
| T1: WRN281(GAF), T2: WRN2811(Sig), S: WRN1611 (14cls) | 69.7691 | 69.0050 | 69.3523 | **69.3755** | 0.3124 |
| T1: WRN283(GAF), T2: WRN2831(Sig), S: WRN1611 (14cls) | 69.4218 | 69.1439 | 69.8906 | **69.4854** | 0.3081 |

---

### Alpha = 0.3 (280.5175)

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|--------|--------|--------|--------|--------|
| T1: WRN161(GAF), T2: WRN1611(Sig), S: WRN1611 (14cls) | 69.7864 | 70.6720 | 70.3247 | **70.2610** | 0.3643 |
| T1: WRN163(GAF), T2: WRN1631(Sig), S: WRN1611 (14cls) | 70.1511 | 70.3421 | 70.5504 | **70.3479** | 0.1631 |
| T1: WRN281(GAF), T2: WRN2811(Sig), S: WRN1611 (14cls) | 69.2134 | 70.3073 | 69.7517 | **69.7575** | 0.4466 |
| T1: WRN283(GAF), T2: WRN2831(Sig), S: WRN1611 (14cls) | 70.5504 | 70.3247 | 69.5781 | **70.1511** | 0.4155 |

---

### Alpha = 0.5 (280.6044)

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|--------|--------|--------|--------|--------|
| T1: WRN161(GAF), T2: WRN1611(Sig), S: WRN1611 (14cls) | 70.7588 | 70.4115 | 70.9498 | **70.7067** | 0.2228 |
| T1: WRN163(GAF), T2: WRN1631(Sig), S: WRN1611 (14cls) | 70.2205 | 70.3768 | 69.5781 | **70.0585** | 0.3456 |
| T1: WRN281(GAF), T2: WRN2811(Sig), S: WRN1611 (14cls) | 69.4565 | 70.2900 | 68.9877 | **69.5781** | 0.5386 |
| T1: WRN283(GAF), T2: WRN2831(Sig), S: WRN1611 (14cls) | 70.0990 | 69.8038 | 70.8804 | **70.2611** | 0.4542 |

---

### Alpha = 0.7

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|--------|--------|--------|--------|--------|
| T1: WRN161(GAF), T2: WRN1611(Sig), S: WRN1611 (14cls) | 69.2308 | 69.4391 | 70.2032 | **69.6244** | 0.4180 |
| T1: WRN163(GAF), T2: WRN1631(Sig), S: WRN1611 (14cls) | 69.5954 | 68.8661 | 69.8559 | **69.4391** | 0.4189 |
| T1: WRN281(GAF), T2: WRN2811(Sig), S: WRN1611 (14cls) | 68.9356 | 67.7548 | 69.1439 | **68.6114** | 0.6117 |
| T1: WRN283(GAF), T2: WRN2831(Sig), S: WRN1611 (14cls) | 68.7098 | 69.1092 | 69.5954 | **69.1381** | 0.3621 |

---

### Alpha = 0.9

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|--------|--------|--------|--------|--------|
| T1: WRN161(GAF), T2: WRN1611(Sig), S: WRN1611 (14cls) | 69.0224 | 68.9529 | 68.8488 | **68.9414** | 0.0713 |
| T1: WRN163(GAF), T2: WRN1631(Sig), S: WRN1611 (14cls) | 68.5362 | 68.7446 | 68.8835 | **68.7214** | 0.1427 |
| T1: WRN281(GAF), T2: WRN2811(Sig), S: WRN1611 (14cls) | 67.3554 | 68.7446 | 67.7895 | **67.9632** | 0.5803 |
| T1: WRN283(GAF), T2: WRN2831(Sig), S: WRN1611 (14cls) | 67.6854 | 68.3799 | 68.1195 | **68.0616** | 0.2865 |






### 추가실험
<li> GENE_Active 14cls, 500w 데이터에 대해 (T : WRN163, S : WRN161)과 (T : WRN281, S : WRN161)에 대해서 추가 실험을 진행함 (높은 것을 최대한 뽑아보기 위해서.) </li>
<li> T : WRN163, S : WRN 161 - 68.1195, 67.1992, 67.9285, 68.6578, 67.1644, 67.5638 </li>
<li> T : WRN281, S : WRN 161 - 67.0255, 67.1297, 67.4423, 67.5291, 66.2441 </li>


### alpha(두 Teacher간 KD_loss의 비중)을 바꿔가며 실험한 결과
<li> alpha : 0.1 (T1(image)가 10%), T1 : WRN161, T2 : WRN1611, S : WRN1611 </li>
<ul>
<li> 69.1439 </li>
<li> 69.9080 </li>
<li> 70.0642 </li>
<li> mean : 69.7054 </li>
<li> std : 0.4021 </li>
</ul>

<li> alpha : 0.1 (T1(image)가 10%), T1 : WRN163, T2 : WRN1631, S : WRN1611 </li>
<ul>
<li> 70.8283 </li>
<li> 70.9151 </li>
<li> 70.9325 </li>
<li> mean : 70.8920 </li>
<li> std : 0.0456 </li>
</ul>

<li> alpha : 0.1 (T1(image)가 10%), T1 : WRN281, T2 : WRN2811, S : WRN1611 </li>
<ul>
<li> 69.7691 </li>
<li> 69.0050 </li>
<li> 69.3523 </li>
<li> mean : 69.3755 </li>
<li> std : 0.3124 </li>
</ul>

<li> alpha : 0.1 (T1(image)가 10%), T1 : WRN283, T2 : WRN2831, S : WRN1611 </li>
<ul>
<li> 69.4218 </li>
<li> 69.1439 </li>
<li> 69.8906 </li>
<li> mean : 69.4854 </li>
<li> std : 0.3081 </li>
</ul>

<li> alpha : 0.3 (T1(image)가 30%), T1 : WRN161, T2 : WRN1611, S : WRN1611 </li>
<ul>
<li> 69.7864 </li>
<li> 70.6720 </li>
<li> 70.3247 </li>
<li> mean : 70.2610 </li>
<li> std : 0.3643 </li>
</ul>

<li> alpha : 0.3 (T1(image)가 30%), T1 : WRN163, T2 : WRN1631, S : WRN1611 </li>
<ul>
<li> 70.1511 </li>
<li> 70.3421 </li>
<li> 70.5504 </li>
<li> mean : 70.3479 </li>
<li> std : 0.1631 </li>
</ul>

<li> alpha : 0.3 (T1(image)가 30%), T1 : WRN281, T2 : WRN2811, S : WRN1611 </li>
<ul>
<li> 69.2134 </li>
<li> 70.3073 </li>
<li> 69.7517 </li>
<li> mean : 69.7575 </li>
<li> std : 0.4466 </li>
</ul>

<li> alpha : 0.3 (T1(image)가 30%), T1 : WRN283, T2 : WRN2831, S : WRN1611 </li>
<ul>
<li> 70.5504 </li>
<li> 70.3247 </li>
<li> 69.5781 </li>
<li> mean : 70.1511 </li>
<li> std : 0.4155 </li>
</ul>

<li> alpha : 0.5 (T1(image)가 50%), T1 : WRN161, T2 : WRN1611, S : WRN1611 </li>
<ul>
<li> 70.7588 </li>
<li> 70.4115 </li>
<li> 70.9498 </li>
<li> mean : 70.7067 </li>
<li> std : 0.2228 </li>
</ul>

<li> alpha : 0.5 (T1(image)가 50%), T1 : WRN163, T2 : WRN1631, S : WRN1611 </li>
<ul>
<li> 70.2205 </li>
<li> 70.3768 </li>
<li> 69.5781 </li>
<li> mean : 70.0585 </li>
<li> std : 0.3456 </li>
</ul>

<li> alpha : 0.5 (T1(image)가 50%), T1 : WRN281, T2 : WRN2811, S : WRN1611 </li>
<ul>
<li> 69.4565 </li>
<li> 70.2900 </li>
<li> 68.9877 </li>
<li> mean : 69.5781 </li>
<li> std : 0.5386 </li>
</ul>

<li> alpha : 0.5 (T1(image)가 50%), T1 : WRN283, T2 : WRN2831, S : WRN1611 </li>
<ul>
<li> 70.0990 </li>
<li> 69.8038 </li>
<li> 70.8804 </li>
<li> mean : 70.2611 </li>
<li> std : 0.4542 </li>
</ul>

<li> alpha : 0.7 (T1(image)가 70%), T1 : WRN161, T2 : WRN1611, S : WRN1611 </li>
<ul>
<li> 69.2308 </li>
<li> 69.4391 </li>
<li> 70.2032 </li>
<li> mean : 69.6244 </li>
<li> std : 0.4180 </li>
</ul>

<li> alpha : 0.7 (T1(image)가 70%), T1 : WRN163, T2 : WRN1631, S : WRN1611 </li>
<ul>
<li> 69.5954 </li>
<li> 68.8661 </li>
<li> 69.8559 </li>
<li> mean : 69.4391 </li>
<li> std : 0.4189 </li>
</ul>

<li> alpha : 0.7 (T1(image)가 70%), T1 : WRN281, T2 : WRN2811, S : WRN1611 </li>
<ul>
<li> 68.9356 </li>
<li> 67.7548 </li>
<li> 69.1439 </li>
<li> mean : 68.6114 </li>
<li> std : 0.6117 </li>
</ul>

<li> alpha : 0.7 (T1(image)가 70%), T1 : WRN283, T2 : WRN2831, S : WRN1611 </li>
<ul>
<li> 68.7098 </li>
<li> 69.1092 </li>
<li> 69.5954 </li>
<li> mean : 69.1381 </li>
<li> std : 0.3621 </li>
</ul>

<li> alpha : 0.9 (T1(image)가 90%), T1 : WRN161, T2 : WRN1611, S : WRN1611 </li>
<ul>
<li> 69.0224 </li>
<li> 68.9529 </li>
<li> 68.8488 </li>
<li> mean : 68.9414 </li>
<li> std : 0.0713 </li>
</ul>

<li> alpha : 0.9 (T1(image)가 90%), T1 : WRN163, T2 : WRN1631, S : WRN1611 </li>
<ul>
<li> 68.5362 </li>
<li> 68.7446 </li>
<li> 68.8835 </li>
<li> mean : 68.7214 </li>
<li> std : 0.1427 </li>
</ul>

<li> alpha : 0.9 (T1(image)가 90%), T1 : WRN281, T2 : WRN2811, S : WRN1611 </li>
<ul>
<li> 67.3554 </li>
<li> 68.7446 </li>
<li> 67.7895 </li>
<li> mean : 67.9632 </li>
<li> std : 0.5803 </li>
</ul>

<li> alpha : 0.9 (T1(image)가 90%), T1 : WRN283, T2 : WRN2831, S : WRN1611 </li>
<ul>
<li> 67.6854 </li>
<li> 68.3799 </li>
<li> 68.1195 </li>
<li> mean : 68.0616 </li>
<li> std : 0.2865 </li>
</ul>


## PAMAP2 데이터 분석
### 데이터 형태
1. 83319개의 데이터와 각 데이터는 40개의 Feature를 가지고 있다.
2. 83319개의 데이터는 0 ~ 11에 포함하는 라벨을 각각 가지고 있다.
3. 데이터셋에서 9명의 사람으로부터 83319개의 데이터를 얻은 것이다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP.png" alt="PAMAP shape" width="500">

### 학습할 때 데이터의 사용
1. 9명의 사람은 0 ~ 8의 id로 구분되고, 학습을 할 때 그 중 한명을 Test_id로 지정하여 남은 8명은 Train set으로 학습한다.
2. 이렇기 때문에, 같은 사람의 데이터를 학습하고, 테스트하게 되는 불상사는 일어나지 않음.
3. 같은 사람에서 나온 데이터를 학습하고, 테스트때 사용한다면, Acc가 높게 나올 확률이 높다. (GENE_Active때 겪어본 문제.)

### 데이터의 사용
1. .data 파일의 형식으로 저장되어있다. (GENE_Active랑 다르다.)
2. 이렇게 .data 파일로 되어있는 경우 .npy파일과 다르게 pickle.load를 통하여 데이터를 얻어왔다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP_pickle.png" alt="PAMAP Pickle load" width="500">
3. 근데 cls_id = [24, 1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17] 인데, 원래 PAMAP2에는 24번 label이 없다. 24번은 뭘까
4. 0, 9, 10, 11을 묶어서 24로 놓은건가?
5. 근데 데이터를 로드해와서 np.unique(labels)를 찍어보니, 0 ~ 11로 정렬하게 나와있다. (아마 Encoding된 Label인듯.)
6. 뭐 어쨌든 데이터를 로드해왔다고 치고. (이해가 안감.) 데이터를 어떤식으로 불러와서 load하는지 보자.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP2_data_load.png" alt="PAMAP Data Load" width="500">
7. 데이터를 window크기 100씩으로 불러오는데, 시작 지점은 22씩만 늘어난다. (나머지 78개의 sequence는 계속 겹치면서 data를 로드하고 있다.)
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP2_step_size.png" alt="PAMAP Step Size" width="500">
8. 그 다음, 데이터를 만들고 싶은 크기로 x_train, y_train, x_test, y_test를 np.zeros로 만들어주고, 하나씩 넣어준다.
9. 왜하는가? > (idx, window_length, channel)의 형태를 (idx, batch_size, window_length, channel)의 형태로 바꿔주기 위함임.



## Trainning Environment
<ul>
<li> Dataset = GENE(life_log) </li> 
<li> python = 3.8.18 </li>
<li> pytorch = 2.3.0 + (cu12.1), CUDA 11.8 </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 200 </li>
<li> batch size = 128 </li>
<li> learning rate = 0.05 - 0.0001 (Adjust Learning Rate) </li>
<li> optimizer = Momentum + SGD </li>
</ul>