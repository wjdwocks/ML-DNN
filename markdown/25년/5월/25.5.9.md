## 이번주 하려고 하는 것.
<li> PAMAP2 2Teacher에서 Lambda, Alpha 모두 선택 완료. (lambda = 0.99, alpha = 0.7로 결정) </li>
<li> 2Teacher (GAF + Sig → Sig) annealing 적용해서 학습 시작 </li>
<li> VLA 이어서 공부 </li>
<li> https://zhengli97.github.io/PromptKD/ 교수님이 보라한거 보기 (못함) </li>
<li> https://aiflower.tistory.com/19 -> What matters when building vision-language models 논문 리뷰해주는 블로그 (못함)  </li>

## 2Teacher alpha 결정
- 밑에 사진 보면 0.7에서 WRN16-3, WRN28-1 이 각각 86.5589, 84.6616이 나왔다.
- 0.9에서 WRN16-3, WRN28-1이 각각 86.7378, 84.5699 가 나왔다.
- 이렇게 보면 0.7보다 0.9가 성능이 좋은것처럼 보이지만, 큰 차이가 안나고, alpha = 0.9에서 높게 튀는 값이 많았어서 GENE랑 비슷하게 0.7로 결정하려고 합니다.
- 자세히 각 WRN16-3 / WRN28-1 에 대해 Trial 별로 보면 0.7일 때가 평균적으로 높아 보인다.

<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/5월/25.5.9/PAMAP_result2.png" alt="results" width="700">

## ann 학습 시작
<li> 서버 못들어가서 못함.. </li>

## What matters when building vision-language models 논문 리뷰 보기.
- 2024년에 나온 논문임.
- VLM에 대한 관심이 증가하고 있지만, VLM 설계에 대한 중요한 결정들에 대한 근거가 부족한 것 같다고 한다.
- 이 문제를 해결하기 위해서 pretrained 모델, 아키텍처의 선택, 데이터 및 학습 방법에 대해서 실험을 통해 이 이것들의 선택에 대한 성능 비교를 한다고 한다.
- 아직 자세히는 못봤다...

## 지금까지 결과 보기

<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/5월/25.5.9/PAMAP_result.png" alt="results" width="700">