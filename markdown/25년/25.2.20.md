### 이번주 하려고 하는 것.
<li> 1 Teacher에 대해서 PAMAP 데이터 학습을 해보고, 결과를 보자. </li>
<li> Object Detection에 대해서 공부해보려고 한다. v3 버전에서 뭐가 더 좋아졌는지, 그 이후도.</li>
<li> 직접 Yolo에 대해 코드를 통해서 더 익혀보자. (YOLOv8 모델, coco 데이터셋.) </li>
<li> VAE, WAE에 대해 MNIST로 공부 (x) </li>
<li> 고민중... </li>


### SPKD(Similarity Map을 비교하여 KD에 이용함.)
1. Teacher 네트워크와 Student 네트워크에서 생성된 Similarity Map을 서로 비교하여 KD에 사용하는 방법론.
2. SPKD에서 정의하는 특징 행렬 f = B x (W x H x C). (batch, width, height, channel) 임.
3. Similarity Map = f x f.T 로 표현하는데, 이를 통해서 Similarity Map의 Shape = (Batch x Batch) 이 된다.
4. Similarity Map의 형태가 Batch x Batch로 된다는 것은 내가 지금 하고 있듯이, Multi Modal Data의 경우(Teacher와 Student의 네트워크나, 데이터 형태가 다른 경우)에도 KD에 접목시킬 수 있게 된다.
5. 한번 시각화 해보자.
6. YOLO에 대해서도 SPKD를 사용할 수 있는지 궁금하다. 그 데이터가 어떻게 생겼는지와, 사용할 수 있을 지를 보자.


# YOLOv8을 통해 coco Dataset 학습 돌려보기.
## 데이터 준비
- pip install ultralytics
- ultralytics 라이브러리를 통해 yolo 모델을 쉽게 불러오거나, 저장할 수 있다.
- COCO 데이터셋 저장.
- 아레의 명령어를 이용하여 원격으로 서버에 zip 파일을 저장하고, 압축을 해제하여 사용할 수 있다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/coco_download.png" alt="coco_download" width="500">

## 데이터 전처리
- 위에서 저장한 데이터 파일들은 train(.jpg), val(.jpg), annotation(.json) 이렇게 세 가지로 이루어져 있다.
- annotation은 captions, instances, person_keypoints에 대해 각각 train, val이 있다.
- caption은 이미지의 설명이 들어가고, 
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/caption.png" alt="caption" width="500">
- person_keypoints에는 사람의 keypoint 데이터가 들어가고,
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/person_keypoint.png" alt="person_keypoint" width="500">
- instances에는 실제로 yolo가 학습에 사용 할 bounding box, 이미지의 label값, 이미지의 id 등이 들어간다.
- 또한 instances에는 images, annotations, categories의 세 부분으로 나누어지는데, 학습에 필요한 정보는, annotations부분의 bounding box, class_id등의 정보이다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/instances.png" alt="instances" width="500">
- YOLO를 학습하기 위해서는 각 이미지 파일에 대해 대응하는 txt파일로 label을 만들어 주어야 하기에 변환을 해주어야 함.
- 그래서 아레의 코드를 실행하여 coco/labels/ 위치에 label들을 저장해주어야 한다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/data_reshape.png" alt="data_reshape" width="500">
- 그렇게 하면 아레와 같이 image_id가 파일의 이름인 labels(image_id).txt로 label이 잘 만들어 진다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/labels.png" alt="labels" width="500">


## 학습 시작.
- label에 대한 정보(.txt) 파일에 배경만 있고 객체가 없다고 그런다. 오늘은 여기깔즤.
- 안된다.
- 안된다.
- 안된다.
- 안된다.
- 안된다.
- 안된다.
- 안된다.
- 안된다.
- 안된다.
- 안된다.
- 안된다.
- 안된다.


## Trainning Environment
<ul>
<li> Dataset = GENE(life_log), PAMAP(이것도 HAR 데이터) </li> 
<li> python = 3.8.18 </li>
<li> pytorch = 2.3.0 + (cu12.1), CUDA 11.8 </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 200 </li>
<li> batch size = 128 </li>
<li> learning rate = 0.05 - 0.0001 (Adjust Learning Rate) </li>
<li> optimizer = Momentum + SGD </li>
</ul>