### 이번주 하려고 하는 것.
<li> 1 Teacher에 대해서 PAMAP 데이터 학습을 해보고, 결과를 보자. </li>
<li> Object Detection에 대해서 공부해보려고 한다. v3 버전에서 뭐가 더 좋아졌는지, 그 이후도 (v8까지만).</li>
<li> 직접 Yolo에 대해 코드를 통해서 더 익혀보자. (YOLOv8 모델, coco 데이터셋.) </li>
<li> VAE, WAE에 대해 MNIST로 공부 (x) </li>
<li> 고민중... </li>


### SPKD(Similarity Map을 비교하여 KD에 이용함.)
1. Teacher 네트워크와 Student 네트워크에서 생성된 Similarity Map을 서로 비교하여 KD에 사용하는 방법론.
2. SPKD에서 정의하는 특징 행렬 f = B x (W x H x C). (batch, width, height, channel) 임.
3. Similarity Map = f x f.T 로 표현하는데, 이를 통해서 Similarity Map의 Shape = (Batch x Batch) 이 된다.
4. Similarity Map의 형태가 Batch x Batch로 된다는 것은 내가 지금 하고 있듯이, Multi Modal Data의 경우(Teacher와 Student의 네트워크나, 데이터 형태가 다른 경우)에도 KD에 접목시킬 수 있게 된다.
5. 한번 시각화 해보자.
6. YOLO에 대해서도 SPKD를 사용할 수 있는지 궁금하다. 그 데이터가 어떻게 생겼는지와, 사용할 수 있을 지를 보자.


# YOLOv8을 통해 coco Dataset 학습 돌려보기.
## 데이터 준비
- pip install ultralytics
- ultralytics 라이브러리를 통해 yolo 모델을 쉽게 불러오거나, 저장할 수 있다.
- COCO 데이터셋 저장.
- 아레의 명령어를 이용하여 원격으로 서버에 zip 파일을 저장하고, 압축을 해제하여 사용할 수 있다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/2월/25.2.20/coco_download.png" alt="coco_download" width="500">

## 데이터 전처리
- 위에서 저장한 데이터 파일들은 train(.jpg), val(.jpg), annotation(.json) 이렇게 세 가지로 이루어져 있다.
- annotation은 captions, instances, person_keypoints에 대해 각각 train, val이 있다.
- caption은 이미지의 설명이 들어가고, 
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/2월/25.2.20/caption.png" alt="caption" width="800">
- person_keypoints에는 사람의 keypoint 데이터가 들어가고,
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/2월/25.2.20/person_keypoint.png" alt="person_keypoint" width="800">
- instances에는 실제로 yolo가 학습에 사용 할 bounding box, 이미지의 label값, 이미지의 id 등이 들어간다.
- 또한 instances에는 images, annotations, categories의 세 부분으로 나누어지는데, 학습에 필요한 정보는, annotations부분의 bounding box, class_id등의 정보이다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/2월/25.2.20/instances.png" alt="instances" width="500">
- YOLO를 학습하기 위해서는 각 이미지 파일에 대해 대응하는 txt파일로 label을 만들어 주어야 하기에 변환을 해주어야 함.
- 그래서 아레의 코드를 실행하여 coco/labels/ 위치에 label들을 저장해주어야 한다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/2월/25.2.20/data_reshape.png" alt="data_reshape" width="500">
- 그렇게 하면 아레와 같이 image_id가 파일의 이름인 labels(image_id).txt로 label이 잘 만들어 진다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/2월/25.2.20/labels.png" alt="labels" width="500">


## 학습 시작.
- 우선, 처음에 데이터 전처리를 잘못해서 모델이 labels의 위치를 못찾는 문제가 계속 발생했었음.
    - 경로를 잘못 설정했었다. (coco.yaml에 data를 coco/train2017 로 두었는데, labels를 coco/labels/train2017로 두었었음.)
    - coco/train2017/images/.jpg로 train_data를 사용하고, coco/train2017/labels/.txt 로 train_labels를 사용하도록 해야 정상적으로 작동한다.
- coco 학습 코드. (기본 예제 코드이다.)
    - 일단, YOLO를 사용하기 전에는 ultralytics 라이브러리를 설치하고, import해야 한다.
    - 그리고, model = ultralytics.YOLO('yolov8n.pt)를 사용하여 YOLOv8의 경량화 버전을 있으면 사용하고, 없다면 다운받아 사용하게 한다.
    - model.info()로 간단한 정보를 파악함.
    - torchinfo.summary()를 통해서 각 layer마다 input shape, output shape, num_param 을 쉽게 볼 수 있다. (하지만 모델자체가 복잡해서 어렵다.)
    - model.train()을 통해서 args.yaml 에 각종 hyper parameter (정말 많다. lr, cutmix 등...)를 넘겨주어 쉽게 학습을 수행할 수 있다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/2월/Study/coco_train.png" alt="coco 학습코드" width="500">


## 학습 결과.
### 학습 하면서 출력되는 여러 지표들 분석.
- YOLOv8n을 사용했을 때 출력되는 손실 함수
    - box_loss : Bounding Box 손실, CIoU, GIoU, DIoU 등을 사용하여 계산된 loss 값을 의미함. (적을 수록 Ground Truth와 가까운 Bounding Box를 예측함.)
    - cls_loss : 클래스 분류 손실, Sigmoid + BCE Loss를 사용하여 다중 클래스 분류가 가능해짐.
    - dfl_loss : Bounding Box 좌표를 더 정밀하게 조정하는 역할. YOLOv8에서는 좌표(x, y, w, h)를 확률 분포로 예측하여 더 정밀한 위치 조정이 가능해졌다.
- YOLOv8n을 Validation 할 때 출력되는 평가 지표
    - Box(P) : Precision, 예측한 Bounding Box 중에서 실제로 맞은 박스의 비율. (False Positive를 방지함.)
        - 증가할 수록 불필요한 False Positive를 줄이며, 더 정확한 객체 탐지를 수행한다.
    - Box(R) : Recall, 실제 Ground Truth객체 중에서 모델이 제대로 탐지한 비율. (False Negative를 방지함.)
        - 증가할 수록 모델이 놓치는 객체(False Negative)를 줄이며, 더 많은 객체를 탐지할 수 있다.
    - Box(P, R)은 둘 다 높은게 좋지만, 하나가 높아지면 다른 하나는 줄어드는 Trade-off 관계라서 균형을 잘 가져가는게 중요하다.
    - mAP50 : IoU = 0.5일 때의 (50%정도만 GT와 Box가 겹쳐도 맞다고 쳐준다.) 성능평가 지표.
    - mAP50-95 : IoU = 0.5 ~ 0.95(0.05 간격) 에서 평균 mAP를 계산함. mAP50보다 엄격한 Box 평가 지표. (더 일반적인 평가 지표이다.)

### 학습 결과 분석.
- 학습 하는중...... ... ... ... ... ...
- YOLO를 학습할 때 사용할 수 있는 여러 Hyper Parameter들이 무엇이 있는지, 각각 어떤 것을 의미하는지 확인.
- 이번에 한 학습에서 사용한 하이퍼파라미터들과 그것이 결과에 어떤 영향을 미쳤는지.
- YOLO를 학습하면 나오는 여러 결과 분석 그래프들을 보고 학습이 잘 되었는지 분석.
- 다시 해보면 좋을 것 같다면 왜, 어떻게 하면 좋을지.


# PAMAP 데이터셋 1_teacher KD 결과 (lambda값 바꿔가며 수행중.)
## lambda = 0.1
### 학습 진행 사항 (Test_id : 0)
<li> WRN16-1 </li>
<ul>
<li> 75.9796 </li>
<li> 74.7182 </li>
<li> 74.2351 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 75.5770 </li>
<li> 75.2281 </li>
<li> 74.1546 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 74.9866 </li>
<li> 76.0333 </li>
<li> 75.7917 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 75.8991 </li>
<li> 75.6039 </li>
<li> 75.8991 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 1)
<li> WRN16-1 </li>
<ul>
<li> 78.0127 </li>
<li> 73.9108 </li>
<li> 74.4713 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 70.7261 </li>
<li> 69.6306 </li>
<li> 73.8344 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 73.6306 </li>
<li> 72.7898 </li>
<li> 69.2994 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 66.3439 </li>
<li> 76.1783 </li>
<li> 76.1274 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 2)
<li> WRN16-1 </li>
<ul>
<li> 94.9074 </li>
<li> 92.5154 </li>
<li> 94.4444 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 91.3194 </li>
<li> 93.6728 </li>
<li> 94.7917 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 93.8272 </li>
<li> 94.0972 </li>
<li> 94.0972 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 93.6728 </li>
<li> 93.5571 </li>
<li> 92.0910 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 3)
<li> WRN16-1 </li>
<ul>
<li> 91.7610 </li>
<li> 90.2234 </li>
<li> 92.0801 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 91.5289 </li>
<li> 92.9214 </li>
<li> 91.6159 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 92.0511 </li>
<li> 90.8616 </li>
<li> 89.4691 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 88.3377 </li>
<li> 90.4265 </li>
<li> 88.1926 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 4)
<li> WRN16-1 </li>
<ul>
<li> 74.4649 </li>
<li> 78.8684 </li>
<li> 78.7208 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 87.6753 </li>
<li> 80.6642 </li>
<li> 83.5424 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 87.3555 </li>
<li> 84.0098 </li>
<li> 81.7466 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 70.4059 </li>
<li> 78.6470 </li>
<li> 85.1415 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 5)
<li> WRN16-1 </li>
<ul>
<li> 88.0097 </li>
<li> 85.7833 </li>
<li> 89.5386 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 88.1974 </li>
<li> 87.9560 </li>
<li> 85.7028 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 88.5193 </li>
<li> 88.4657 </li>
<li> 89.2167 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 87.1245 </li>
<li> 88.6266 </li>
<li> 88.4657 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

### 학습 진행 사항 (Test_id : 6)
<li> WRN16-1 </li>
<ul>
<li> 94.2857 </li>
<li> 95.0649 </li>
<li> 95.9885 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 95.8153 </li>
<li> 93.4776 </li>
<li> 94.1991 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 95.2958 </li>
<li> 94.0260 </li>
<li> 95.0072 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 93.7951 </li>
<li> 95.4690 </li>
<li> 95.2958 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 7)
<li> WRN16-1 </li>
<ul>
<li> 64.9015 </li>
<li> 59.1967 </li>
<li> 60.2968 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 66.1294 </li>
<li> 52.0338 </li>
<li> 62.9317 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 59.1711 </li>
<li> 58.1223 </li>
<li> 58.7362 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 72.0389 </li>
<li> 49.7570 </li>
<li> 53.9013 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 8)
<li> WRN16-1 </li>
<ul>
<li> 100.0000 </li>
<li> 100.0000 </li>
<li> 98.9130 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 100.0000 </li>
<li> 98.9130 </li>
<li> 100.0000 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 100.0000 </li>
<li> 98.9130 </li>
<li> 100.0000 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 100.0000 </li>
<li> 100.0000 </li>
<li> 100.0000 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>


## lambda = 0.3
### 학습 진행 사항 (Test_id : 0)
<li> WRN16-1 </li>
<ul>
<li> 75.9528 </li>
<li> 77.1605 </li>
<li> 77.1068 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 75.0939 </li>
<li> 76.2748 </li>
<li> 75.1208 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 75.4697 </li>
<li> 76.3285 </li>
<li> 77.5631 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 76.7848 </li>
<li> 76.3553 </li>
<li> 77.6167 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 1)
<li> WRN16-1 </li>
<ul>
<li> 75.8217 </li>
<li> 74.9809 </li>
<li> 75.6433 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 76.5605 </li>
<li> 77.2229 </li>
<li> 75.0828 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 77.0955 </li>
<li> 74.7516 </li>
<li> 76.9682 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 77.2229 </li>
<li> 72.9172 </li>
<li> 75.1083 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 2)
<li> WRN16-1 </li>
<ul>
<li> 94.2515 </li>
<li> 94.3287 </li>
<li> 93.9815 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 94.6373 </li>
<li> 94.2130 </li>
<li> 94.2130 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 93.5957 </li>
<li> 92.8241 </li>
<li> 95.1003 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 94.5602 </li>
<li> 93.5185 </li>
<li> 94.3287 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 3)
<li> WRN16-1 </li>
<ul>
<li>  </li>
<li> 95.4163 </li>
<li> 94.0528 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 93.5016 </li>
<li> 94.0528 </li>
<li> 90.4265 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 89.7302 </li>
<li> 91.9060 </li>
<li> 92.8343 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 88.9179 </li>
<li> 88.2216 </li>
<li> 91.1807 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 4)
<li> WRN16-1 </li>
<ul>
<li> 82.4354 </li>
<li> 84.0344 </li>
<li> 84.9200 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 83.3702 </li>
<li> 83.4440 </li>
<li> 90.3321 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 79.4342 </li>
<li> 70.0615 </li>
<li> 79.6802 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 82.4354 </li>
<li> 84.0344 </li>
<li> 78.2534 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 5)
<li> WRN16-1 </li>
<ul>
<li> 90.8262 </li>
<li> 87.8487 </li>
<li> 89.5655 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 89.4313 </li>
<li> 91.7918 </li>
<li> 88.6534 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 89.1094 </li>
<li> 91.1749 </li>
<li> 90.3165 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 89.3240 </li>
<li> 90.5043 </li>
<li> 91.7650??? </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

### 학습 진행 사항 (Test_id : 6)
<li> WRN16-1 </li>
<ul>
<li> 94.7763 </li>
<li> 94.9784 </li>
<li> 96.1328 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 94.1991 </li>
<li> 94.5166 </li>
<li> 95.4113 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 93.8240 </li>
<li> 94.6609 </li>
<li> 95.8730 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 96.4791 </li>
<li> 95.1227 </li>
<li> 96.0750???? </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 7)
<li> WRN16-1 </li>
<ul>
<li> 59.4014 </li>
<li> 61.0386 </li>
<li> 61.8573 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 66.1806 </li>
<li> 60.8851 </li>
<li> 63.1875 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 51.3942 </li>
<li> 56.1013 </li>
<li> 65.0550 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 64.4922 </li>
<li> 64.1596 </li>
<li> 58.7362??? </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

### 학습 진행 사항 (Test_id : 8)
<li> WRN16-1 </li>
<ul>
<li> 100.0000 </li>
<li> 98.9130 </li>
<li> 98.9130 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 100.0000 </li>
<li> 100.0000 </li>
<li> 100.0000 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 100.0000 </li>
<li> 100.0000 </li>
<li> 98.9130 </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 100.0000 </li>
<li> 100.0000 </li>
<li> 98.9130 ??? </li>
<li> 평균 :  </li>
<li> 표준편차 : </li>
</ul>


## Teacher 단일 최고 평균

| test_id  | 0       | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 평균   | 표준편차  |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|----------|
| wrn16-1  | 80.9447 | 73.3248 | 79.6682 | 79.4604 | 80.4674 | 81.0622 | 84.9928 | 80.6856 | 92.3913 | 81.4442 | 4.8001   |
| wrn16-3  | 81.1863 | 72.4586 | 80.1698 | 81.6942 | 81.5744 | 81.2232 | 86.9841 | 80.7623 | 94.5652 | 82.2909 | 5.5720   |
| wrn28-1  | 83.1186 | 73.6051 | 79.4367 | 78.3000 | 81.0332 | 80.4989 | 86.3492 | 80.2763 | 94.5652 | 81.9092 | 5.5264   |
| wrn28-3  | 82.4745 | 78.2930 | 80.9414 | 81.6652 | 81.1316 | 80.0161 | 85.5988 | 81.1205 | 95.6522 | 82.9881 | 4.8443   |



## lambda = 0.1 최고 평균

| test_id  | 0       | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 평균   | 표준편차  |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|----------|
| wrn16-1  | 75.9796 | 78.0127 | 94.9074 | 92.0801 | 78.8684 | 89.5386 | 95.9885 | 64.9015 | 100.000 | 85.5863 | 10.9710  |
| wrn16-3  | 75.5770 | 73.8344 | 94.7917 | 92.9214 | 87.6753 | 89.2972 | 95.8153 | 66.1294 | 100.000 | 86.2269 | 10.9658  |
| wrn28-1  | 76.0333 | 73.6406 | 94.0972 | 92.0511 | 87.3555 | 89.2167 | 95.2958 | 59.1711 | 100.000 | 85.2068 | 12.3063  |
| wrn28-3  | 75.8991 | 76.1783 | 93.6728 | 90.4265 | 85.1415 | 88.6266 | 95.4690 | 72.0389 | 100.000 | 86.3836 | 9.2126   |

## lambda = 0.3 최고 평균

| test_id  | 0       | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 평균   | 표준편차  |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|----------|
| wrn16-1  | 77.1605 | 75.8217 | 94.3287 | 95.4163 | 84.9200 | 90.8262 | 96.1328 | 61.8573 | 100.000 | 86.2737 | 11.7620  |
| wrn16-3  | 76.2748 | 77.2229 | 94.6373 | 94.0528 | 90.3321 | 91.7918 | 95.4113 | 66.1806 | 100.000 | 87.3226 | 10.6720  |
| wrn28-1  | 77.5631 | 77.0955 | 95.1003 | 92.8343 | 79.6802 | 91.1749 | 95.8730 | 65.0550 | 100.000 | 86.0418 | 10.9487  |
| wrn28-3  | 77.6167 | 77.2229 | 94.5602 | 91.1807 | 84.0344 | 91.7650 | 96.4791 | 64.4922 | 100.000 | 86.3724 | 10.8099  |




## Trainning Environment
<ul>
<li> Dataset = GENE(life_log), PAMAP(이것도 HAR 데이터) </li> 
<li> python = 3.8.20 </li>
<li> pytorch = 2.4.1, CUDA 11.8 </li>
<li> GPU = NVIDIA GeForce RTX 4090 (서버) </li>
<li> CPU = ?? </li>
<li> epoch = 200 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.05 - 0.0001 (Adjust Learning Rate) </li>
<li> optimizer = Momentum + SGD </li>
</ul>