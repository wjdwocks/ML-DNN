## 이번주 한 것.
<li> PAMAP2 3 Teacher 에서 최적의 alpha값 조합 선정 및 ann, annsp 결과 확인 </li>
<li> GENE Activ 데이터셋 EBKD 적용해서 결과 확인함. </li>
<li> CTPD 논문 읽어보기 </li>

## PAMAP2 3Teahcer에서 Alpha값 찾기.
- 학습 진행을 했는데, 사실상 규칙성같은게 안보여서 뭘 선택할지 고민입니다..
- 일단 wrn-163, wrn-281 에서 top4개 뽑았을 때 중복으로 있는게 [0.3 : 0.2 : 0.5] , [0.4 : 0.3 : 0.3] 둘이었어서 [3:2:5]를 학습중이긴 한데, GAF, PI, Sig 중 더 높은 가중치를 줄 것을 찾고싶은데 어떻게 해야할지..

## 학습 진행 상황
- 계속 쭉 진행중...
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/6월/25.6.19/PAMAP.png" alt="PAMAP" width="700">

- GENEActiv에 EBKD를 적용한 결과 (오늘 저녁에 14cls 학습 끝날 것 같아서 끝나고 추가하겠습니다.)
- EBKD는 Teacher들의 logits 분포를 확인하고, 그것을 통해 Entropy(출력 분포의 불확실성)을 측정한다.
- Entropy가 낮을수록 Teahcer의 출력이 확신이 있다는 의미이고, Entropy가 클 수록 출력이 불확실하다는 것이므로 가중치를 낮게 설정하는 식임.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/6월/25.6.19/GENEActiv.png" alt="GENEActiv" width="700">


## CTPD (Cross-Modal Temporal Pattern Discovery)
- vital sign같은 Time Series 데이터와 Clinic Report같은 free-text 데이터를 함께 사용하면 clinical outcome prediction의 성능을 올릴 수 있을것같은데 어떻게 하면 좋을까
- 이런 Health관련 데이터를 EHR 데이터라고 하나봄.
- 두 모달리티에서 학습된 패턴(정보)를 잘 합치기 위해서 TP-NCE(Temporal Pattern Noise Contrastive Estimation) loss를 도입함.
- 이 TP-NCE Loss를 통해 두 Modality의 표현을 하나의 동일한 표현 방식으로 맞춰주고
- Auxiliary Reconstruction Loss를 통해 각 Modality의 Embedding 표현이 원본의 정보를 최대한 잘 유지하도록 한다.
- 최종적으로 두 Modality의 Embedding 표현을 잘 합쳐서, Ground Truth와 Prediction을 비교하여 Prediction Loss를 얻음.

### Introduction
- 현재까지 존재하던 방법은 우선 불규칙한 데이터를 처리하고, 멀티 모달리티 데이터를 합치는 방법을 사용함.
- 하지만 이런 방식은 환자의 서로다른 case를 반영하지 못함.
- 기존의 방법들은 서로 다른 granuarities(시간 스케일) 간의 차이점을 효과적으로 포착하지 못함.
    - 예를 들어 산호 포화도나 심박수의 갑작스러운 변화는 급성 건강 위기
    - 고혈압의 지속이나 호흡 기능이 서서히 저하되는 경우는 장기적인 추세로 봐야함.
- 이 논문의 방법
    - CTPD는 다중 Modality EHR 데이터로부터 의미있는 시간적 패턴을 추출하도록 설계됨.
    - TP-NCE Loss를 도입하여 두 모달리티에서 추출한 시간적 pattern 표현을 같은 의미 공간에 정렬시킨다.
    - Auxiliary Reconstruction Loss를 도입하여 학습된 Temporal Pattern이 원래의 데이터에서 핵심 정보(Core Information)을 유지하도록 함.

### Related Work
- 이전에 EHR데이터를 이용해서 Clinical Task에 사용한 예시가 있음.
- RNN이나 LSTM을 이용해서 의료 관련 time series 데이터를 분석하였는데, 이는 고정된 time step을 가지는 데이터셋이 필요하므로 결과가 좋지 않았음.
- 그래서 이걸 해결하고자, Graph Neural Network를 사용해서 각 time step에서 환자의 표현을 업데이트하던가, time-aware embedding을 사용해 시간 정보를 통합하려 했는데, 결과가 좋지 않았나 봄.
- 최근에 멀티모달 의료 데이터를 통합하고자 하는 시도가 있었음.
- 이때 Late Fusion 방식을 주로 사용했는데, 각 modality에서 Feature를 뽑고, concat이나 krnecker product로 합쳤음.
    - 이 방식은 Modality간 복잡한 상호작용을 제대로 반영하지 못하고, 표현력이 떨어지는 문제가 있었음.
- 또한, cross-modal Transformer 구조를 이용해 Modality간 관계를 모델링하는 시도가 있었음.
    - 이 방식은 Modality 간의 관계를 잘 포착했지만, 각 데이터로부터 고수준의 시간적 의미(temporal semantics)를 잘 추출하지 못했다.

### Proposed Method
- 멀티모달 EHR 데이터는 두 가지 주요 타입으로 구성됨
    1. MITS(Multivariate Irregular Time Series) : 생체 신호, 검사 수치 등의 시계열 정보.
    2. Free-text Clinical Notes : 의사 소견, 진료 기록 등 비정형 텍스트 데이터
- 각각의 Modality를 어떻게 같은 벡터 임베딩 형태로 표현할것인가?
    1. MITS 임베딩 생성 
        - 입력 : 시계열 데이터 x
        - 1D Conv를 세 가지 Scale로 적용하여 다중 시간 Scale 표현을 생성함.
        - 그것을 시간 차원을 따라 평균(Pooling) 후 Concat하여 최종 Embedding을 생성함. 
    2. Text 임베딩 생성
        - 입력 : 그냥 텍스트 데이터
        - BERT를 이용하여 각 note를 임베딩하여 시간 축을 가진 Sequence 형태로 표현함.
    3. Shared Prototype과의 Attention
        - 학습 가능한 shared temporal prototype P를 정의하고, 이를 Query로 하여 각 Modality의 embedding과 Attention을 수행함.
        - 이를 통해 각 Prototype내의 벡터들이 각 Modality 임베딩의 어떤 부분을 주목해야 하는지 결정한다.
    4. Attention 결과를 이용해서 Prototype에 대응하는 값을 갱신함.
        - Attention 결과를 이용해서 각 Modality의 Embedding을 Prototype에 대응하는 값으로 업데이트.
    5. GRU를 통과시켜 prototype들 간 순차적/의존적 관계를 학습할 수 있게 함.
        - 4.번에서 Prototype과 Attention한 결과를 이용해서 각 Modality를 Prototype에 대응하는 값으로 만든 뒤에 GRU를 또 통과시킴. (보통 3회 반복3)
        - 이렇게 하면 Prototype 내의 상호작용과 순차적/의존적 관계를 더 잘 표현할 수 있다고 함.
    6. TP-NCE Loss 계산
        - 최종적으로 나온 두 Modality의 Embedding 표현을 cosine similarity로 비교하여 loss항 구성.
    - 즉, TP-NCE Loss는 이 Prototype이 MITS와 Text 사이에서 의미가 비슷하게 정렬되어야 한다는 목적을 가지고, 학습이 된다.
    - 하지만, 이 프로토타입이 원래 데이터의 정보를 잘 담고 있는지도 중요하다.
- Auxiliary Reconstruction (보조 재구성 손실)
    - 이 Prototype에서 원래 시계열/텍스트를 복원하게 함으로써, 정보 손실이 적은 Prototype을 만드는 것이 목표임.
    - 위에서 본 GRU까지 통과한 각 Modality의 Embedding 을 Transformer 기반 Decoder에 통과시켜 원본을 얼마나 잘 재구성했는지에 대한 Loss를 구성하게 됨.
- 이를 통해 Prototype은 각 Modality 간의 의미적 유사성을 보장해주고, 원본 정보까지 잘 유지하도록 학습된다.
- 그럼 이제 이렇게 각 Modality에서 Embedding을 얻었는데 이걸로 어떻게 Predict를 하나?
    - 각 Modality마다 두 가지 level의 정보가 생성되도록 설계가 된다고 함.
    - Prototype-level representation : 고수준의 개념을 요약한 벡터
    - Timestamp-level embeddings : 시간 단위로 변화를 표현한 정보.
    - 각 Modality에서 이 둘을 Attention Weighted Sum으로 합친다. (어떨 때는 고수준의 정보가 필요하고, 어떨 때는 시간 단위 정보가 필요하기 때문.)
    - 각 Modality 표현을 Concatenation하여 하나로 결합한다.
    - 그 다음 MLP -> Softmax를 통해 예측을 낸다.


## 해야 할 남은것들
<li> 교수님이 보라고 하신 논문 읽어보기 </li>
<li> https://arxiv.org/abs/2305.15775 - Concept-Centric Transformer (아직) </li>
<li> https://arxiv.org/pdf/2502.11418 - TimeCAP (아직) </li>
<li> KD baseline 찾기 </li>
<li> Teacher 특이조합에 대해서 실험 진행 </li>
<li> 영어논문 쓰기 시작 </li>
<li> 영어공부 </li>