## 이번주 하려고 하는 것.
<li> PAMAP2 3 Teacher 에서 최적의 alpha값 조합 찾기 </li>
<li> EBKD 이해 (모르고 쓸 순 없으니...) </li>
<li> U-Net 기반 Stable Diffusion을 통한 원하는 데이터 학습. (Pretrain) </li>
<li> 이후, Pretrain된 모델을 가지고, 원하는 도메인의 이미지를 추가 학습한 후, Prompt Embedding을 추가한 후 직접 이미지를 출력해보는 실습을 해보려고 함. </li>

## PAMAP2 3Teahcer에서 Alpha값 찾기.
- GENEActiv때랑 똑같은 조합들에 대해서 (226, 235, 325, 334, 333) 에 대해서 할것임.

## 학습 진행 상황
- 계속 쭉 진행중...
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.6.6/PAMAP.png" alt="PAMAP" width="700">

## 생성형 AI쪽 공부
- Stable Diffusion 공부 및 MNIST 실습 해보려고 함
- 그 다음에 Text Embedding까지 넣는 pretrained 모델에 적용해보려고 함.
- Kaggle에 애니메이션 캐릭터 이미지 데이터셋이 있어서 생성형 AI 모델 학습 해보는중.
- 각 애니메이션 제목-데이터들 이 있어서, 위에서 본 MNIST-Diffusion(Unet) 모델에, Text_emb을 추가하여 학습을 하는 모델을 만듦.
- CLIPTokenizer와 CLIPTextModel을 이용해서, Text Embedding을 U-Net에 넘겨줬다.
- 해보려고 하는것은 내가 Sampling을 할 때 Text로 특정 애니메이션 제목을 같이 넣어주면 그 그림채로 이미지가 생성되게 하는것.
- 또한, 추가적인 데이터를 직접 넣은 뒤 원하는 이미지를 뽑아보는거?
- 근데, 학습이 너무 오래걸려서 언제가 될지는 모르겠습니다..
- 자세한 정리는 시험 끝나고 하겠습니다..


https://github.com/wjdwocks/ML-DNN/tree/main/ML/pytorch/auto_encoder