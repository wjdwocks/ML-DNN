1. codebook → z, mu, sigma, l, t : Attribute Decoder를 통해서 나눠주는 역할만임.
2. hugging face text embedding을 사용해서 각자 decoder를 둬서 뒤에서 합쳐도 됨.
3. LLM을 통해서 time-series를 text로 출력할 수도 있음. text라는게 sequence vector로 표현할 수도 있음.
4. 각 text Tokenizer가 서로 다름 ( , 포함/비포함)
5. LSA paper? 에서도 이렇게 했는데, CrossAttention이 이것 또한 해소가 된다.
6. 왜 cross modality가 잘 되냐? 
      - 둘을 사용해서 codebook을 만들어도, 하나만 사용하더라도 잘 동작할것임.
7. parallel하게 signal을 위한 loss쪽 하나, text쪽 loss하나로 둬서 
      - 같은 Token으로 출발하는데, 말이 안됨.
      - 그러려면, Text embedding 따로(hugging face) → 샘플마다 PI 만들어놓듯이, Time-series Encoder 따로 두고 각자의 token을 통한 loss를 구현하고, 뒤에서 하나의 token으로 맞추는 느낌으로 함.
8. Text는 Tokenizer를 통해서 굳이 mu, sigma, t, l을 할 필요 없으니, z만 가진다고 생각하면 됨.
      - 이거로, 중앙에 Codebook을 업데이트하는 Operation을 포함하게 함.
      - Tokenizer Reverse를 통해서 다시 Time-series로 돌린 다음에, Recon Loss를 얻으면 된다.
9. Cross Attention을 통해서 다른 Modality 차이를 해소해줄 수 있다 + 같은 time-series로부터 출발했다는 것 이것에 집중해서 이번주 공부를 해야할듯.
10. 좋은 논문이 되기 위함이란? → 방법론까지는 거의 다 똑같음. 그렇지만 여기에 어떤 재미난 것을 더 추가할 수 있을 것인가? 어떻게 말을 표현할 수 있을 것인가?
11. toy model : GLW에 codebook 바꾸고, pi를 text로 바꾸는거. 
      - loss부분은?
      - 아마 Codebook 부분 바꾸는게 어려울듯.??
      - Problem : 어떻게 Time-series데이터를 interpretable 하게, subsequence로 분할할 수 있을까? → 이것을 time-series만으로는 할 수 없기 때문에, Text Modality를 가져오게 되었다.
→ 어떻게 Text를 넣을건데? : huggingface tokenizer를 통해서 같은 shape의 token으로 만듦.

GLW 논문, LLM Guided semantic augmentation, Frequency-Semantic Enhanced Variational Autoencoder for zeroshot skeleton based action ... 이런얘들 읽어봐야함.
   - Skeleton : Motivation이 되어야 할 논문. 
      - LLM을 어떻게 Text에 사용할지. → Prompt engineering : 어떻게 더 자세히 text를 잘 뽑아낼 수 있을까.


## GLW코드와 VQShape 코드를 돌려보면서, 어떻게 위의 일을 할 수 있을 지 생각해봐야할듯.
### VQShape 코드 따라가보기. (Main함수부터 쭉)
- 

## LSA 논문 읽어보기.
### Introduction
### Proposed Method
### 그외
- 