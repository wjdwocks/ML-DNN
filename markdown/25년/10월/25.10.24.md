### VQShape쪽 공부해가야 할 것.
1. 일단, Text Guidance는 Label을 이용해서 얻은 Sub-Actions에 대한 Vector들만 들어감.
2. 그렇다는 것은, Text Guidance는 단지, 이 Time-series에는 Action1, Action2, Action3 ... 의 Sub-Action이 들어간다는 정보만 줄 수 있음.
3. 원본 Signal에서는 이 부분 SubSequence가 어떤 Sub-Action인지는 당연히 모름. Text-Guidance에서도 이 Time-series에 이런 Sub-Action이 포함될 거라고 알려주기만 함.
4. 어떻게 이 Sub-Sequence가 어떤 Sub-Action인지 매핑이 가능할까? → 아직 모르겠다.
5. Attribute Decoder에서 Sub-Action을 추출하기 전에 어떤 행위를 더 해주면 이게 가능하기는 한 것일까?


### VQShape 공부하고있음...
1. Signal Input으로 Time-series Encoder를 통해 Signal Embedding z_s를 얻음. (B, 64, D1)
2. 그 Input의 Label을 이용해서 이 Sample에 어떤 Sub-Action이 있는지를 얻고, 그것들을 각각 Text Encoder에 넣어서 (B, 5, D2)의 형태로 z_t를 얻음. 
3. 둘을 Cross Attention을 해주기 위해서 Projection Layer에 넣어서 \tilde z_s (B, 64, D)와 \tilde z_t (B, 5, D)를 얻음. 

4. Fusion Layer에서 Cross Attention 및 Residual Connection을 해줘서 z_s만 보고도 이 샘플 내에 어떤 Sub-Action이 들어있을 것인가까지에 대한 정보가 포함될 수 있도록 Contrastive Loss로 학습시킨다. 
    - Text와 Signal을 같은 의미 공간에 매치해줌(LSA Loss를 통해서) → Fusion Layer의 Cross Attention을 한 결과의 Attention Weight가 각 Signal Patch가 어떤 Sub-Action과 연관이 있는지도 의미하게 됨. (어느정도 학습이 된 후에는)
    - Time-series Encoder의 출력(z_s)만으로도 이 Signal에 어떤 Sub Actions들이 포함될 지도 알려줌.

5. 


5. \tilde z_s 혹은 그냥 z_s를 Tokenizer의 Input으로 넣어서 64개의 Token을 얻음. 
6. 각 Token을 Query, 5개의 Action Vector(\tilde z_t가 되려나?)를 Key/Value로 하여 Cross Attention을 수행하여 각 Token이 어떤 Sub-Action과 연관이 있는지 가중치를 얻는다. 
7. (Teacher-Student구조는 어디갔지?) CrossEntropy Loss와 같은 것으로 하나의 Token이 하나의 Sub-Action에만 많은 가중치를 두도록 유도한다.





- 어떻게 Time-series Token하나에 Sub Action하나를 매핑시킬 수 있냐??
- Label을 이용한 Text Encoder를 사용하면 그 Text Guidance에서는 모든 Label이 합쳐져서 정보가 생김.
    - 그렇다는 것은 우리가 Label을 이용한 Sub Actions백터들에 
- 어떤 특정 Loss를 통해서 하나의 Token에 하나의 Sub Action이 되게 해야 함.
- Text Guidance는 Sub Actions를 줄여주는 역할
- Text 를 이용해서 Time-series Codebook을 만들면, Time-series만 사용한 VQShape과 Code의 모양이 다를 것이고 이것이 Novelty가 될 수 있다.

            이 둘에 대해서 자세히 생각해보자.
- Sub Action에 대한 유니크한 Representation으로 하는 것이 좀 더 명확히. (Sub Actions들을 구성할 때 뭔가 더 필요해보임)
- Token(Code)에 하나하나씩 Sub-Action이 어떻게 매핑이 잘 될 것인가?
- 근거를 좀 더 명확히 미리 준비해가자. (reference)
- 좀 더 문과적인 마인드로 설명을 하자.



### 3Teacher 논문 작성 및 실험 (이번주는 이거 다 그리기만 해도 성공한것임.)
    - WRN 다른 조합 2Teacher 그림 Robustness쪽 논문 참고해서 히스토그램으로 처리. ## 어떻게 그릴 수 있을지 걱정이 됩니다

    - Tolerance Noise : 모든 Teacher에 대해서 다 그려보기 # Teacher의 크기가 달라도 되고, 같더라도 다른 모델로
    - Confusion Matrix : 다른 Student로 더 좋은게 있나 보기 # 다른 Model이면 F1-score가 달라질 수 있으니까 이걸 노리고.
    - 실험 중 학습하는 / 학습한 SP Maps들 시각화 및 비교 : 2Teacher꺼들 지워서도 그려보고 KD(TS)가 없던가 그랬음. # 이건 어차피 지우기만해도 되서 나중에

    - Hyper parameter : 3Teacher만 표로 Alpha 비교해서 한다. # 하나 고정 나머지 변화 이런식으로 3개 Section으로 표를 구성하면 좋을듯.
    - Parametric Plot : 하던대로 하는데, SPKD포함되어서 그려보면 좋을듯.



### 오늘 할 일
- VQShape 생각만 정리.
- 캡디 보고서 4,5,6 써보기.
- 발표자료 약간 수정 및 추후계획 작성.