## 생각한 방법. (25.10.27)
### 공통
- 각 Class별로 약 5개의 Sub-Action 후보를 LLM 등을 활용해 추출한다.
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/subactions.png" alt="results" width="650">
- 전체 데이터셋에 대해, 각 Class에서 추출된 Sub-Action들을 Similarity 기반으로 중복 제거하여 최종 약 12개의 Sub-Action 집합을 구성한다. (개수의미 x)
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/subactions2.png" alt="results" width="650">
- 입력 시계열 샘플 x가 (1, C, 512) 형태라면, 이를 Signal Encoder → (1, C, 64, 8) → Signal Tokenizer → (1, C, 32, 256) 형태로 변환한다.
- 각 Class의 Sub-Action 텍스트는 Text Encoder (예: LLM 기반) 를 통해 (1, 5, 256) 형태의 임베딩으로 변환하며, Text Encoder는 Freeze한다.
- 두 모달리티의 차원을 일치시키기 위해 필요 시 Projection Layer를 적용한다.
- LSA와 유사하게 Signal Token을 Query로 하는 Cross-Attention과 Text Token을 Query로 하는 Cross-Attention을 각각 한 번씩 수행하여, 두 모달리티의 semantic space를 align시킨다.
    - 이 과정을 통해 Signal Encoder와 Tokenizer만으로도 샘플 내 포함된 Sub-Action의 의미를 부분적으로 추론할 수 있게 된다.
    - 또한 Signal을 Query로 한 Cross-Attention의 Attention Weight은 각 Token이 어떤 Sub-Action에 주목하는지를 나타내는 확률 분포(Soft Label) 로 활용할 수 있다.
- 한 샘플에서 얻은 5개의 Sub-Action 확률 분포를 전체 Sub-Action 집합(예: 12개)에 맞춰 확장하고, 나머지 7개 항목은 0으로 채워 전체적인 확률 분포 형태로 구성한다.
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/method0.png" alt="results" width="700">


### 1번 방식 : Attribute Decoder에 Action Head를 추가.
- 기존 Attribute Decoder에 Action Head를 추가하여 전체 Sub-Action에 대한 확률 분포를 직접 학습한다.
- Action Head는 KL-Divergence Loss를 통해 Attention Weight 기반의 soft target을 모방하도록 학습한다.
- KL Loss를 사용하는 이유: 유사한 Sub-Action 간의 semantic 관계를 유지하면서 soft한 분포를 학습하기 위함이다.
- 장점 : Downstream Task에서 각 Token의 Attribute representation을 Sub-Action 정보와 함께 전달할 수 있어, Classification 등 후속 작업의 성능 향상을 기대할 수 있다. (Token-level semantic richness 강화)
- 단점 : Main Motivation인 “각 Code를 통해 Shape과 Sub-Action을 함께 이해하는 구조”에는 부합하지 않는다. Action Head는 Token 단위로 학습되므로, Token간의 관계정보까지 포함해서 Action을 예측할것이라서, Codebook의 각 Code가 어떤 Sub-Action과 대응되는지 직접적으로 알 수 없다. 따라서 Code–SubAction 매핑을 위해 각 코드가 선택되었을 때 어떤 Sub-Action으로 선택되었는지 누적해서 계산하는 등의 별도의 후처리가 필요할 것 같다.
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/method11.png" alt="results" width="700">

### 2번 방식.
- Token에서 Quantization을 통해 얻은 Code z를 기존 Shape Decoder에 입력하여 shape reconstruction을 수행하는 동시에, Action Decoder를 추가하여 Sub-Action 분포를 예측하게 한다.
- Action Decoder 또한 KL-Divergence Loss로 학습하며, Attention Weight 기반 확률 분포를 target으로 사용한다.
- 장점 : Codebook이 Shape 정보 + Sub-Action semantic 정보를 동시에 학습하게 된다.
    - Shape Decoder로부터의 reconstruction loss (shape-level supervision)
    - Action Decoder로부터의 Sub-Action alignment loss (semantic supervision)를 동시에 받으며, Codebook embedding이 더욱 풍부한 의미 공간을 형성한다.
    - 완성된 Codebook을 사용하면, 각 Code를 Shape Decoder에 통과시켜 “어떤 모양인지”를 알 수 있을 뿐 아니라, Action Decoder를 통해 “어떤 Sub-Action에 해당하는지”까지 즉시 파악할 수 있다.
- 단점 : Codebook이 두 가지 목적(Shape & Semantic)을 동시에 학습해야 하므로, 두 손실 간의 경쟁(trade-off) 가능성이 있다
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/method2.png" alt="results" width="700">


## 3Teacher 논문 쓰기 Experiments쪽
### SP_Maps 그림 바꿈. 
- 좀 더 3Teacher를 사용했을 때 전체 Stage에 대한 Similarity Map이 밝아져서 Sample간의 상관성을 더 잘 포착한다는 느낌을 살리기 위함.
- 기존 : <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.31/sp_map_df.png" alt="results" width="700">
- 바뀐거 : <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.31/SP_maps.png" alt="results" width="700">

### Corruption 실험 그림 세로로 바꿈.
- 반페이지로 들어가게 하는게 좀 더 화질도 좋고, 공간쓰는게 좋을 것 같아서.
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.31/Noise2.png" alt="results" width="700">

### 대충 그린 히스토그램
- Teacher간에 서로 다른 WRN을 사용한 경우를 표에서 그림으로 대체 어떻게 더 볼품있게 수정하면 좋을지 내일 물어보자.
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.31/different_architecture.png" alt="results" width="700">

### 3Teacher Alpha하이퍼파라미터 표
- 이거는 진짜 조잡해서 어떻게 수정하면 좋일지 확실하게 정해야 할 것 같다.
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.31/alpha.png" alt="results" width="700">

### 아직 남은 부분
- Processing Time 추가
- Discussion, Conclusion 추가.
- 일단 다 어느정도 초안을 쓰고, 앞에서부터 다시 보면서 고치고 reference도 달려고 합니다.


- SP_maps 를 Stage 3만 해서 Table로 각 Teacher들 (Merged도 포함)의 SP_Maps와 Student들의 SP_Maps를 MSE로 비교한 점수를 보여주며 설명하기.
- 3Teacher 다른 WRN조합 GENE랑 PAMAP2 병렬로 합쳐서 보여주기
- VQShape그거 Testing쪽 Classification 어디에 CE Loss를 붙여줄지 위냐 아레냐 둘다냐
- 그림 다시 확인 띄어쓰기나 그런거 폰트도