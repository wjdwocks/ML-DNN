## 생각한 방법.
### 공통
- 각 Class별로 약 5개의 Sub-Action 후보를 LLM 등을 활용해 추출한다.
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/subactions.png" alt="results" width="650">
- 전체 데이터셋에 대해, 각 Class에서 추출된 Sub-Action들을 Similarity 기반으로 중복 제거하여 최종 약 12개의 Sub-Action 집합을 구성한다. (개수의미 x)
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/subactions2.png" alt="results" width="650">
- 입력 시계열 샘플 x가 (1, C, 512) 형태라면, 이를 Signal Encoder → (1, C, 64, 8) → Signal Tokenizer → (1, C, 32, 256) 형태로 변환한다.
- 각 Class의 Sub-Action 텍스트는 Text Encoder (예: LLM 기반) 를 통해 (1, 5, 256) 형태의 임베딩으로 변환하며, Text Encoder는 Freeze한다.
- 두 모달리티의 차원을 일치시키기 위해 필요 시 Projection Layer를 적용한다.
- LSA와 유사하게 Signal Token을 Query로 하는 Cross-Attention과 Text Token을 Query로 하는 Cross-Attention을 각각 한 번씩 수행하여, 두 모달리티의 semantic space를 align시킨다.
    - 이 과정을 통해 Signal Encoder와 Tokenizer만으로도 샘플 내 포함된 Sub-Action의 의미를 부분적으로 추론할 수 있게 된다.
    - 또한 Signal을 Query로 한 Cross-Attention의 Attention Weight은 각 Token이 어떤 Sub-Action에 주목하는지를 나타내는 확률 분포(Soft Label) 로 활용할 수 있다.
- 한 샘플에서 얻은 5개의 Sub-Action 확률 분포를 전체 Sub-Action 집합(예: 12개)에 맞춰 확장하고, 나머지 7개 항목은 0으로 채워 전체적인 확률 분포 형태로 구성한다.
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/method0.png" alt="results" width="700">


### 1번 방식 : Attribute Decoder에 Action Head를 추가.
- 기존 Attribute Decoder에 Action Head를 추가하여 전체 Sub-Action에 대한 확률 분포를 직접 학습한다.
- Action Head는 KL-Divergence Loss를 통해 Attention Weight 기반의 soft target을 모방하도록 학습한다.
- KL Loss를 사용하는 이유: 유사한 Sub-Action 간의 semantic 관계를 유지하면서 soft한 분포를 학습하기 위함이다.
- 장점 : Downstream Task에서 각 Token의 Attribute representation을 Sub-Action 정보와 함께 전달할 수 있어, Classification 등 후속 작업의 성능 향상을 기대할 수 있다. (Token-level semantic richness 강화)
- 단점 : Main Motivation인 “각 Code를 통해 Shape과 Sub-Action을 함께 이해하는 구조”에는 부합하지 않는다. Action Head는 Token 단위로 학습되므로, Token간의 관계정보까지 포함해서 Action을 예측할것이라서, Codebook의 각 Code가 어떤 Sub-Action과 대응되는지 직접적으로 알 수 없다. 따라서 Code–SubAction 매핑을 위해 각 코드가 선택되었을 때 어떤 Sub-Action으로 선택되었는지 누적해서 계산하는 등의 별도의 후처리가 필요할 것 같다.
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/method1.png" alt="results" width="700">

### 2번 방식.
- Token에서 Quantization을 통해 얻은 Code z를 기존 Shape Decoder에 입력하여 shape reconstruction을 수행하는 동시에, Action Decoder를 추가하여 Sub-Action 분포를 예측하게 한다.
- Action Decoder 또한 KL-Divergence Loss로 학습하며, Attention Weight 기반 확률 분포를 target으로 사용한다.
- 장점 : Codebook이 Shape 정보 + Sub-Action semantic 정보를 동시에 학습하게 된다.
    - Shape Decoder로부터의 reconstruction loss (shape-level supervision)
    - Action Decoder로부터의 Sub-Action alignment loss (semantic supervision)를 동시에 받으며, Codebook embedding이 더욱 풍부한 의미 공간을 형성한다.
    - 완성된 Codebook을 사용하면, 각 Code를 Shape Decoder에 통과시켜 “어떤 모양인지”를 알 수 있을 뿐 아니라, Action Decoder를 통해 “어떤 Sub-Action에 해당하는지”까지 즉시 파악할 수 있다.
- 단점 : Codebook이 두 가지 목적(Shape & Semantic)을 동시에 학습해야 하므로, 두 손실 간의 경쟁(trade-off) 가능성이 있다. 
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/10월/25.10.24/method2.png" alt="results" width="700">