## 집중해서 봐야할 것.
- How) 어떻게 slot마다 다 다르게 알아서 맞춰서 가게 될까?
    - → K(Slot)에 대해서 Softmax를 해서 서로 경쟁적으로 Feature Embedding을 가져가기 때문에, 하나의 Time-series의 Feature Embedding에서, 각 Slot이 서로 다른 부분에 집중해서 Slot에 반영하게 됨.(Slot Attention)

- VQShape의 어느 부분에서 MultiModal을 넣을 때 모듈화할 수 있을지.??
    - 코드에서 Codebook이 어떻게 활용되고, 얘가 뭔지?
    - 3.1 Shape-level representation에서, Image(Text)를 어떤 Attribute tuple로 나눌 수 있을지, 어떻게 Time-series와 Alignment할 수 있을지? Cross Attention?
    - 그래서 어떻게 Objective Loss를 설계할 수 있을지?
    - Attribute를 어떻게 할건데? 

Code Book에 Text Modality를 포함할 수 있을까?
그렇다면 어떻게 Attribute를 쪼갤 수 있을까?


## 내 생각
- 똑같이 Embedding을 통해서 Alignment할 순 없을까?
- 둘 이상의 모달리티(Sig + Txt or Image)를 통해서 Signal의 Interpretability를 더 늘릴 수 있을까? 를 VQShape에 적용할 수 있을만한 방법론까지.
