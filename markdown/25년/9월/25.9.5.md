## Abstracted Shapes as Tokens- A Generalizable and Interpretable Model for Time-series Classification 논문 읽기
### Introduction
- Times series는 sampling ratio, window length, noise 등의 문제로 단일 모델로 여러 데이터셋에 공용으로 사용하는게 어려움.
- 이로 인해 현재의 다수 TS 사전학습 모델은 트랜스포머 백본으로 마스크/다음 구간 예측을 하지만, 표현은 대체로 블랙박스이며 LLM처럼 “이산 토큰” 개념이 빈약하다는 문제가 있다.
- 즉, 한 모델이 성인의 행동과 어린 아이의 행동 모두에 적용되기가 어렵다고 예시를 들었다.
- 기존의 방법 1
    - Shapelet
        - 방식 : 시계열에서 분류에 유용한 여러 개의 대표 부분구간(shapelet)을 학습하고, 각 입력 시계열과 모든 shapelet 사이의 최소거리(혹은 존재 확률)을 계산해 특징 벡터로 만든 뒤 일반 분류기에 넣어 예측을 수행한다.
        - 장점 : 해석 가능하고, 사람이 이해할 수 있는 패턴 단위로 설명 가능함.
        - 단점 : 고정된 길이의 shapelet에 맞춰 최적화 되므로 데이터셋 특화가 되기 쉽고, 같은 동작이라도 성인/아동처럼 오프셋, 스케일, 지속시간이 다른 경우 여러 shapelet이 따로 필요하다.
- 기존의 방법 2
    - VQ-VAE 토크나이저 계열 (TOTEM)
        - 방식 : 원시 시계열을 CNN 등 인코더로 latent space(token, code)로 바꾼 뒤, VQ(벡터 양자화)로 이산 코드북을 만들어 토큰처럼 사용하여 self-supervised(masked, 재구성 등) 목표로 사전학습 한다.
        - 장점 : 다양한 도메인에 공용으로 쓸 수 있는 이산 코드북(discreted codebook)을 제공하고, 표현력이 높아 downstream task에서도 성능이 좋다.
        - 단점 : latent space가 잠재 벡터일 뿐 물리적/형상적 의미가 없어 사람이 해석하기에 어렵다. black box모델임.
- 이 논문의 목적
    - 목표 : 위 두 방식의 장점을 결합해 "해석 가능하면서도 데이터-불변성(전이성)과 표현력"을 모두 갖춘 토큰화를 제안함. 이를 위해 시계열 부분구간을 "추상화된 모양 코드(이산 코드북)" 과 "속성(offset μ, scale σ, 시작 지점 t, 길이 l)"로 분해하고, VQ로 학습한 공용 코드북을 통해 여러 도메인을 하나의 모양 어휘로 기술함.
    - 효과 : 성인/아동 처럼 길이, 스케일, 오프셋이 달라도 "같은 모양 코드(코드북) + 다른 속성"으로 설명이 가능해 interpretable과 generalization을 동시에 확보함.

### Proposed Method
- 아키텍처 설명
- 1. Instance Noramlization
    - 하는 일 : 한 시계열 내의 오프셋/스케일 편차를 줄여 patch embedding이 모양(형상)에 집중되게 하는 전처리.
    - 출력 모양 : (1, 512). → 하나당 512 길이를 가진다고 가정.
- 2. Patching
    - 하는 일 : 길이 512의 시계열을 K=64개의 비중첩 고정 길이의 패치(d_patch, 각 패치 길이)로 분할.
    - 출력 모양 : (1, 64, 8).
- 3. Linear Encoding
    - 하는 일 : 각 패치를 임베딩 차원으로 linear projection함. (learnable한 linear encoder를 이용.)
    - 출력 모양 : (1, 64, 512).
- 4. Positional Embedding
    - 하는 일 : 토큰의 순서 정보를 더한다.
    - 출력 모양 : (1, 64, 512). → 각 patch마다 순서 정보만 더할 뿐 출력 형태는 바뀌지 않음.
- 5. Time-series Encoder (Transformer 기반)
    - 하는 일 : self-attention으로 패치들 간 정보를 섞어 K개의 '문맥화된' 잠재 embedding을 생성. 각 k번째(1, k, 512) 값은 k번째 패치뿐 아니라, 전체 패치 정보가 들어있다.
    - 출력 모양 : (1, 64, 512). → 각 패치들이 서로 간의 정보를 반영한 형태로 변환될 뿐 출력 형태는 같다. 최종 : ĥ_k (0 <= k < 64)
- --------------------------------------여기까지는 ViT와 매우 유사함.----------------------------------
- 6. Attribute Decoder
    - 하는 일 : 64개의 ĥ_k에서 속성 튜플 τ̂_k = (ẑ_k, μ_k, σ_k, t_k, l_k)을 "예측" 하는 모듈. 
        - 즉, 각각 다른 MLP 헤드가 5개 존재하고, 각각을 "예측"하기 위한 MLP에 입력 (1, 64, 512)을 넣어서 출력으로 얻는다.
        - 아래의 각 속성을 출력하는 layer들은 모델과 같이 학습이 진행되고, 각 속성들을 조합해서, 원본 시계열을 복원할 수도 있고, 이를 통해 부분 구간/전체 구간 재구성 손실을 구성함.
        - ẑ_k : 양자화 후의 z_k로, "추상화된 모양" 자체를 담는 잠재 벡터임. 코드북 Z의 한 코드를 의미하며, Shape Decoder S(뒤에 나옴.)가 이 벡터만 보고 offset, scale, length가 제거된 순수한 파형을 복원할 수 있어야 함. 이후 σ·μ를 다시 입혀서 실제 구현을 재현하는 방식. (왜 재현해야 하는가? Reconstruction loss를 사용하나?). 또한, 양자화 자체는 VQ-VAE 방식을 사용하고, 이 때 code book을 8차원 벡터로 구성했기 때문에 8차원의 값을 사용했다는 듯.
        - μ_k : offset(평균)을 의미하는 scalar 값. (512 → h → 1)로 Hidden layer가 하나 존재하는 MLP로 구성.
        - σ_k : scale(표준편차)를 의미하는 scalar 값. softplus를 사용해서 양수로 출력되게 함.
        - t_k : 시작 위치를 의미하는 scalar 값.
        - l_k : 잘라낼 구간의 길이를 의미하는 scalar 값. 
    - 출력 형태 : (1, 64, 12) 12 = 8+1+1+1+1
- 7. 각 loss 구성 및 설명
    - L_s = subsequence 복원 loss로, t_k, l_k로 원 신호에서 구간을 잘라 s_k(target)를 만들고, z_k로 decoding한 모양 S(z_k)에 σ_k·μ_k를 입혀서 s_k를 만든 뒤, 이 둘을 비교하여 얻는 loss.
    - L_x = 양자화된 모든 τ_k 들을 선형사상한 후, decoder로 x̂ 를 복원한 후, 원본 시계열과 비교. (마지막까지 다 수행되는 것.)
    - L_vq = 기존의 ẑ_k 를 z_k로 양자화하여 이산 코드로 만드는데, 이것을 코드북 Z에서 가장 가까운 코드를 뽑아서 z_k로 치환하는 방식임. 이 때 L_vq는 ẑ_k가 선택된 코드 z_k에 커밋되게 하고, 코드북도 ẑ_k 쪽으로 업데이트되도록 만드는 loss라는데, 잘 이해는 안감.
    - L_div = 각 τ̂_k들의 t, l이 특정 위치/길이 에만 몰리지 않도록 다양성 정규화를 위한 loss. 원본 시계열에서 다양한 위치, 길이를 고르게 쓰게 만들어주기 위한 loss임.

<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/8월/25.8.7/GENE_7cls_table.png" alt="results" width="700">

## Langaugae in a Bottle : Language Model Guided Concept Bottlenecks for Interpretable Image Classification 논문 읽어보기
### Introduction + Proposed Method
- 기존의 interpretable model은 대부분 post-hoc(사후설명) 방식으로, 모델의 실제 추론과 다른 경우도 있었음.
- CBM(Concept Bottleneck Models)는 intermediate layer를 사람이 이해할 수 있는 개념으로 강제하여 본질적으로 해석 가능하지만 문제점이 있음.
    - 도메인 전문가의 도움이 필요하다.
    - black box model보다 성능이 떨어짐.
- 그래서 널리 사용되지 못했다.
- 이 논문의 저자는 LaBo라는 프레임워크를 제안함.
- 그 전에 CBM에 대해서 대충이라도 알아보자.
    - CBM은 도메인 전문가의 도움을 받아, 각 학습용 이미지마다, N개의 Feature (ground truth)를 추가로 만들어둔다. (이것을 공통 개념 집합 이라고 함.)
    - 즉, 각 이미지는 이 이미지가 어떤 class인지를 맞추는 것 외에도 각 Feature(존재 여부/정도)의 값도 맞출 값이 생기는 것임. ex) 깃털색, 부리여부, 등등등...
    - 즉, 특정 이미지가 '새' 였다면, '새'를 맞추는 것 외에도, '깃털색(rgb), 부리 있음, 발이 작음' 등의 feature들의 값도 맞춰야 함.
    - 예를 들면, Input Image를 입력으로 받으면, 개념 예측기를 먼저 통과시킨 후, 개념 벡터를 얻어서 각 개념(feature)들의 값을 먼저 맞춰보며 개념 손실(loss)을 얻는다.
    - 그 다음에 그것들을 다시 분류기에 넣어서 최종 클래스 예측을 수행함. (분류 손실)
    - 이렇게가 CBM의 기본 과정이라고 한다.

- LaBo : LLM을 이용하여 위의 과정을 자동화하자는 것이 목표인 듯.
    1. GPT3(이 논문)를 사용하여 각 Class에 대한 설명을 Text로 뽑아달라고 함.
        - ex) '새'에 대한 묘사를 해줘. → '새'는 하늘을 날고, 털에 덮여 있습니다.
    2. T5를 이용하여 LLM이 생성한 문장을 '개념 구(phrase)'의 형태로 변환함. (개념 구 : Sy)
        - ex) 하늘을 난다; 털이 있다.
    3. 각 클래스의 후보 집합 Sy에서 판별력 discriminative 과 커버리지 𝜙를 동시에 크게 만드는 단조 서브모듈러 점수 F를 최대화하여 k개를 고른다.(그리디 방식)
        - 모든 클래스마다 k개만 남기도록 하고, 판별력(다른 클래스와 잘 구분되어야 하고), 커버리지(클래스 내의 많은 것들을 포괄해야 함.)
        - ex) '새' 안에는 닭 같이 하늘을 못 나는 새도 있는데, 이런것도 잘 포괄할 수 있으면서, '고양이'와 같이 네발 달린 동물과 잘 구분이 되어야 한다는 의미인듯.
    4. 개념 임베딩 행렬 Ec 구성.
        - 선택된 모든 개념 구를 CLIP 텍스트 인코더 T(⋅)로 임베딩하여 개념 공간을 구성한다.
        - 즉, 각 concept(개념)마다 같은 고정된 크기를 갖는 vector로 만들어주기 위해 CLIP 텍스트 인코더를 사용한다는 의미인듯.
        - 그래서, 개념 임베딩 Ec는 클래스 수 N, 개념 수 k, CLIP 임베딩 차원 d라고 했을 때 (NK x d)의 행렬이 됨. 각각 K x d를 N개 concat한거임.
    5. 입력으로 들어온 이미지 x를 CLIP 이미지 인코더로 임베딩한 뒤, 내적 g(x, Ec)로 각 개념의 점수를 얻는다.
        - 똑같은 CLIP을 사용했기 때문에, 비슷한 것에 대해서 비슷하다고 나타날 것이라서 이렇게 해서 점수를 얻는 것 같음.
        - x = (1, d)의 형태이고, Ec = (NK, d)의 형태라서 xEc.T 를 하면 (1, NK)라서, 각 개념에 대한 점수가 됨.
        - 이 때 g는 그냥 내적을 할 뿐 학습되지 않는다.
    6. 얻어진 각 개념들마다의 점수를 이용하여 개념 → label 선형 분류기 f를 학습함.
        - 5번에서 각 개념마다의 점수를 얻었는데 그것들을 선형 분류기에 넣어서 개념마다의 점수를 예측하게 함.
        - 이렇게 얻어진 예측된 점수와 클래스 개념을 비교하여 개념 loss를 얻음.
    7. 마지막으로 분류 loss를 얻음.
    