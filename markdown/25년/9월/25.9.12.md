## 해야 할 것
- 논문 세개 읽고, 분석하기
- 논문 쓰던거 계속 쓰려고 노력하기
- 




## CCT 논문 다시 정리
### introduction
- 1. AI는 여러 분야에 대해서 눈에 띄는 성과를 보여왔지만, medical, health care, infrastructure safety 등의 약간의 실수조차 용납되지 않는 분야에서는, AI 특유의 블랙박스 특성(왜 그런 선택을 한 것인가?)이 문제가 되고, interpretable AI가 주목받는 계기가 됨.
- 2. interpretable AI 중 가장 유명한 방법은 post-hoc 방식이다. 이 방식은, 모델이 학습된 후, 계산된 파라미터 값 등을 역추적해 어떤 feature가 prediction 과정에 큰 영향을 미쳤는지 확인하는 방식이다. 이 방식의 단점은 post-hoc 방식이 대체적으로 low-level features에 집중을 한다는 것임.
- 3. intrinsically interpretable model 방식도 있는데, 이것은 애초에 모델이 사람이 이해할 수 있는 'concepts'에 기반하여 의사결정을 수행하는 모델이다. 이 방식의 단점은 몸값이 비싸신 domain expert의 도움을 받아서 데이터셋을 재구성하던가 해야함.
- ------여기까지가 빌드업-------
- 4. 이상적으로는, intrinsically interpretable model은 개별적인 의미있는 modules를 가지고 있으며, 모듈형 설명은 인간의 이해 향상 및 AI 개발에 지속적인 영감을 줄 수 있음.
- 5. 그래서, 우리는 interpretable model의 모듈성(modularity) 개선을 위해서, SGW(shared global workspace)의 개념을 이용하여 CCT 프레임워크를 제안한다.
- 6. CCT를 이용해서 훈련된 모델은 concept에 대한 ground-truth explanations의 guidance 가 있든 말든 semantic comcepts(의미 개념)을 추출할 수 있는 모듈화된 구조를 가질 수 있다.

### 그래서 CCT가 어떻게 동작하는지
- Input x → backbone 을 통해 Feature Vector 추출 → CSA 모듈에 입력 후 Slot Attention을 이용한 Slot Update → CA 모듈에 입력(feature vectors) 후 Updated Slot(SGW)와의 Cross Attention을 이용한 최종 prediction. # 이렇게 동작함.
- 1. Input x (batch 단위의 이미지들이 들어갈 것임.)가 backbone (ViT나, CNN)에 입력으로 들어가서 Feature Vectors를 출력함.
- 2. 이 Feature Vectors를 CSA모듈에 입력으로 넣는다. 
- 3.  [CSA 모듈]CSA 모듈은 SGW의 역할을 하는 Concept Slots을 Query, Feature Vectors를 Key/Value로 하여, Slot Attention을 수행한다. (Concept Slot들을 이번 입력 Feature Vectors를 이용한 표현으로 바꾸기.)
- 4.  [CSA 모듈]이 때, 모든 Feature Vectors에 대해 각 Slot들이, 합이 1이 되도록 attention weights를 부여한다. (각 Feature Vector l_i 마다 가중치의 합이 1)
- 5.  [CSA 모듈]이 것의 의미는, 기존의 Concept 들로 이번에 들어온 Feature Vector들을 얼마나 잘 설명할 수 있는지와 이 Feature Vector들을 더 잘 설명할 수 있는 concept으로 업데이트하기 위함임.
- 6.  [CSA 모듈]Concept Slot은, Feature Vector들(Value)에 attention 가중치를 곱해서 얻어진 벡터를 입력으로, 기존의 initial concept slots을 기존 state로 하여 GRU를 통해 업데이트된다.
- 7.   [CA 모듈]CA모듈은, Backbone을 통해 얻어진 Feature Vector들을 다시 Concept 단위로 해석하기 위한 모듈이다.
- 8.   [CA 모듈]Query는 Input Features, Key/Value는 Concept Slot Vectors로, Input Features를 Concept Slot Vectors에 기반한 값으로 변환하기 위함.
- 9.   [CA 모듈]각 Feature Vector는 모든 Slot Vector와 Attention을 수행하고, Slot Vector와의 가중합을 통해 Slot Vector를 이용한 값으로 표현됨.
- 10.   [최종 클래스 예측]input x에 대해 여러 가지 feature vectors가 나오게 되고, 이것들을 입력으로 받은 CA모듈은 여러 개의 벡터들을 출력할 것임. 
- 11.   [최종 클래스 예측]그럼 이 벡터들을 마지막 classification을 위한 Linear Layer에 통과시켜서 최종 클래스 예측을 수행하고, Cross-Entropy Loss를 얻음.
- 3.  [CSA 모듈]CSA 모듈은 SGW의 역할을 하는 Concept Slots을 Query, Feature Vectors를 Key/Value로 하여, Slot Attention을 수행한다. (Concept Slot들을 이번 입력 Feature Vectors를 이용한 표현으로 바꾸기.)
- 4.  [CSA 모듈]이 때, 모든 Feature Vectors에 대해 각 Slot들이, 합이 1이 되도록 attention weights를 부여한다. (각 Feature Vector l_i 마다 가중치의 합이 1)
- 5.  [CSA 모듈]이 것의 의미는, 기존의 Concept 들로 이번에 들어온 Feature Vector들을 얼마나 잘 설명할 수 있는지와 이 Feature Vector들을 더 잘 설명할 수 있는 concept으로 업데이트하기 위함임.
- 6.  [CSA 모듈]Concept Slot은, Feature Vector들(Value)에 attention 가중치를 곱해서 얻어진 벡터를 입력으로, 기존의 initial concept slots을 기존 state로 하여 GRU를 통해 업데이트된다.
- 7.   [CA 모듈]CA모듈은, Backbone을 통해 얻어진 Feature Vector들을 다시 Concept 단위로 해석하기 위한 모듈이다.
- 8.   [CA 모듈]Query는 Input Features, Key/Value는 Concept Slot Vectors로, Input Features를 Concept Slot Vectors에 기반한 값으로 변환하기 위함.
- 9.   [CA 모듈]각 Feature Vector는 모든 Slot Vector와 Attention을 수행하고, Slot Vector와의 가중합을 통해 Slot Vector를 이용한 값으로 표현됨.
- 10.   [최종 클래스 예측]input x에 대해 여러 가지 feature vectors가 나오게 되고, 이것들을 입력으로 받은 CA모듈은 여러 개의 벡터들을 출력할 것임. 
- 11.   [최종 클래스 예측]그럼 이 벡터들을 마지막 classification을 위한 Linear Layer에 통과시켜서 최종 클래스 예측을 수행하고, Cross-Entropy Loss를 얻음.

### Loss 설계
- CE loss : 예측한 class와 실제 class와의 차이.
- Explanation Loss : interpretable한 특성을 학습 objective function에 직접 넣자는 의미임.
    - 사람이 봤을 때 설명이 납득 가능한가? 라는 것을 해결하기 위한 loss
    - 핵심 아이디어 : Attention Head가 어디를 볼지를 명시적으로 supervise 하는 것. domain 지식을 활용하여, 정확한 Prediction을 위해 중요한 부분 쪽으로 모델의 Attention이 모이도록 유도한다.
    - 실제로 사람이 제공한 Attention Distribution와 CCT의 Cross-Attention에서 실제로 나온 Attention 가중치를 MSE로 비교하여 loss에 추가함.
- Sparsity Loss based on entropy : 각 Feature Vector가 CA 모듈을 통해 Concept기반 표현이 될 때 그 가중치가 하나에 집중할 수 있게 하는 loss
    - 특정 Feature Vector가 여러 concept을 가질 이유는 거의 없다.(아주 일부분의 정보만 가질 테니.)
    - 그렇기 때문에, 각 Feature Vector가 여러 Concept 모두에 큰 가중치를 가진다는건 학습이 잘 안되었다는 의미.
    - 이것을 loss에 넣어서, 여러 concept에 고루 높은 weight를 가지면 loss를 크게 하는 방식으로, 한 concept에 치우칠 수 있도록 유도함.




## LaBo 논문 다시 자세히 읽어보기
### Introduction
- 딥 러닝 시스템은 계속 발전하고 있는데, black box라는 특성이 critical domain에는 적용이 어렵다. (explainable AI의 필요성)
- 기존에는 이것을 해결하기 위해 post-hoc 방식을 사용함. → 모델의 계산에 관련해있기 때문에 불완전/불충분함 (기존 방식의 문제점)
- 또한, inherently interpretable한 모델도 있음. → 결국 black box 모델보다 성능이 낮아서 채택되지 못함. (기존 방식의 문제점 2)
- -------이 논문이 제안 할 방법-------
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/9월/25.9.12/CBM vs LaBo.png" alt="results" width="700">
- 이 논문에서는, Language Model과 Language-Vision Model 을 결합하여 고성능의 interpretable classifier를 설계함.
- 우리는 CBM(Concept Bottleneck Model)이라는 개념에 기반해서 설계하였고, CBM은 human-designed concept에 선형 결합을 활용하여 예측한다.
- CBM에서, domain expert는 새를 분류하기 전의 중간 목표로, "nape color(목덜미 색)"과 같은 concpet을 맞추도록 할 수 있다. → 그래서 사람들이 모델의 오류를 이해하거나, 개입하는 데 사용할 수 있는 추상화(abstraction)를 제공하여 모델의 신뢰도롤 높인다.
- CBM은, domain expert의 annotation이 필요한데, 비용이 비싸고, 자주 black box 모델보다 성능이 떨어진다는 두 문제점을 해결하기 위해서 CBMs를 자동으로 생성하는 시스템을 제안함.
- ------이 논문이 제안하는 방법(구체화)------
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/9월/25.9.12/LaBo architecture.png" alt="results" width="700">
- 위 그림은, 개념 주석(제공된 annotation)없이, 임의 분류 문제에 대해 고성능의 CBMs를 자동으로 구성할 수 있도록 하는 LaBo의 Architecture임.
- Concepts을 생성 및 k개만 선택하는 부분에 LLM을 이용하여 자동화 및 공식화 하고, 클래스 간의 discriminative와 performance를 maximize한다.

### Proposed Method
- <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/9월/25.9.12/LaBo obj.png" alt="results" width="700">
    - 목적은 이것이고, x는 CLIP Image Embedding이고, Ec는 Clip Text Embedding임.
    - 각 embedding vector를 g라는 서브모듈러 함수에 넣어서, k개의 대표 concept을 얻고
    - 얻어진 대표 concept을 f라는 분류기를 통해 final prediction을 얻은 후, y와 비교해서 CE loss를 얻음.
    - F(C, D)는 아직 모름.
- 어떻게 동작하는지에 대한 간단한 overview?
    - CLIP은 Text도 받을 수 있고, Image도 받을 수 있는 multimodal model임.
    - 그래서, Text를 받든, Image를 받든 그 둘을 공통된 차원으로 align 해줄 수 있다.
    - 또한, 그 둘을 dot product 하면, 두 modality의 alignmnet score를 표현할 수 있음
    - 이 논문에서는, 데이터셋 D = {(x, y)}의 모든 이미지에서 feature를 추출함. (CLIP으로 embedding vector를 만든다는 거겠지?)
    - 

1. LLM을 통한 CBMs수집 방법(Generate Concepts):
    1. prompt : "describe what the [class name] looks like" 와 같이 LLM에 입력한다
    2. LLM : "The [class name] limbs are delicate, and the tail is long and thin." 과 같이 출력을 받음. → 500개의 문장을 얻었다고 함.
    3. 필터링 및 간략화 : LLM이 준 문장들에서 클래스 이름 제거 + 짧은 표현으로 변환함. (길이 제한, 중복/모호 표현 제거) → T5를 이용해서, 자동으로 각 문장을 짧은 concepts들로 나눔.
    4. 이렇게 얻어진 Concepts들이, 각 class의 Candidate concepts들이 되는거다.
2. CLIP을 이용한 Submodular Concept Selection:
    1. 위에서 500개의 문장을 얻었다고 하는데, 이걸 모두 다 사용할 순 없다.
    2. 그래서, discriminability와 coverage라는 두 항목을 가중합한 점수를 가장 큰 순서대로 k개를 선택한다.
        - <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/9월/25.9.12/dis_cov.png" alt="results" width="700">
    3. discriminability : concept c가 소수의 클래스에만 강하게 결합되길 원하는 값.
        - 한 클래스에서 500개의 concepts들을 얻었다고 했다.
        - 각 c에 대해서 D(c)를 계산할 거고, 이게 클 수록 좋은거임.
        - 그 전에, Similarity를 계산하고, 이것을 이용한 negative entropy를 이용해서 D(c)를 계산함.
        - Similarity는 각 class y에 대해서, 그 class에 포함되는 모든 이미지들의 Clip embedding x와 text embedding T(c)의 dot product의 평균으로 계산된다.
        - 즉, 아레처럼, 각 클래스마다 그 클래스에 포함된 모든 이미지들에 대해서 clip으로 embedding vector를 얻고, 그것과 한 concept T(c)와의 similarity를 dot product로 계산함.
        - 여기서 dot product를 하는 것은, 어차피 둘 다 clip을 이용해서 얻어진 embedding vector이므로, 의미하는 바가 같다면, 비슷한 값의 vector일 것이라서, dot product의 값이 클 수록, 이 concept이 그 클래스의 이미지들을 잘 표현한다는 것임.
        - 그 다음, 이 concept c와 모든 클래스와의 similarity를 이용한 negative entropy를 통해서 D(c)를 얻음. 여기서 D(c)가 크다면, concept c가 한 클래스에 대해서는 높은 Discriminability를 얻었지만, 다른 클래스들에 대해서는 낮은 Discriminability를 얻은 것이므로 우리가 원하는 다른 클래스와의 구분력을 잘 나타낸 concept이기 때문에 k개의 concept에 채택될 확률이 높아지는것임.
        - <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/9월/25.9.12/dis_sim.png" alt="results" width="700">
        - <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/9월/25.9.12/dis_CE.png" alt="results" width="700">
    4. coverage : 선택된 소수의 k개의 concept들이 선택되지 않은 나머지 concepts 들을 잘 표현할 수 있어야 함.
        - 같은 클래스에서 얻어진 서로 다른 두 concept이 유사한지를 알기 위해서 우리는 cosine similarity를 이용함. (cos(Tc1, Tc2)) → 각도 차이가 0일 때 1이니까 클 수록 비슷
        - 이 때 coverage 항을 보면, 전체 500개의 concepts들을 하나씩 순회하며, 선택된 k개의 concept의 집합 내의 concept들과 cosine similarity를 계산하는데, 그 중 가장 높은 값들만 선택해서 더한다.
        - 이것의 의미는, 선택된 k개의 concepts들은 500개의 concepts들과 가장 유사한 것들이라는 것이고, 이 전체 concepts들을 대표할 수 있다는 것임.
        - 이 converage 항을 최대화하는 k개의 concepts 집합을 찾는 것이 목적임.
    - 





## mGLW 논문 공부.
### Introduction 뜯어보기.
- Wearable Sensor를 통한 AI가 건강 관련 분야에서 큰 성공을 이뤘다.
- wearable sensor는 sensor noise, 불규칙적인 sampling rates, individual difference(개인차)와 같은 문제가 있음.
- 그래서, 우리는 Sensor Data를 PI로 변환하는 TDA를 사용하려고 함.
- 그런데, 센서로부터 PI를 얻는 데에 큰 computational cost가 발생해서, wearable sensor device와 같이 경량화 모델에서는 쉽지 않다.
- 그래서, KD를 사용한다. multiple teacher가 각각 다른 modality를 사용하는 경우, student는 다양한 feature 정보를 습득할 수 있게 됨.
- 하지만, 그 경우에도 multimodal data의 feature dimensions가 다르다는 문제와, 서로 다른 Teacher 들 간에 knowledge가 conflict 할 수 있다는 문제가 있음.
- 이것들을 모두 해결하기 위해서, multimodal Global Latent Workspace-based Knowledge Distillation(mGLW-KD) 프레임워크를 제안한다. - 이것 또한 Global Workspace Theory에 영향을 받음.
- mGLW-KD는, working memory module을 통합하여, 여러 교사 모델의 다양한 지식을 shared latent workspace로 통합하고, 이를 통해 student로 효율적인 지식 전달을 수행함.
- topological insights와 cognitive principles를 통합하여 wearable sensor로 인한 문제를 해결하고, student는 추론 과정에서 time-series만 가지고도 탁월한 성능을 냄.
- 또한, Teacher와 Student 간의 Gap을 해소하기 위해서, feature correlations에 따른 inter-class, intra-class를 활용하고, annealing strategy를 활용한다.

### Proposed Method
- multimodal data로부터 얻어진 Features는 다양한 지식을 포함하고, 풍부한 정보를 가지고 있어 모델 성능을 향상시켜줄 수 있다.
- 하지만, 서로 다른 modality로 얻어진 features를 direct로 합치는 것은 heterogeneous dimension size를 갖고, 두 정보의 alignment에 어려움이 있을 수 있다.
- 그래서, mGLW 모듈을 도입한다. 
- mGLW는, multimodal 지식 추출 및 전달을 위한 핵심 component로, in our framework에서, embedding representation을 학습하여 제공된다.
- knowledge slots을 통합한 이 모듈(mGLW)은 두 개의 하위 구성 요소로 구성된다.
    1. 두 teacher 모델에서 knowledge importance score를 계산하고, 두 모델에서 aggregated(집계?)된 지식을 학습함.
    2. 교사 모델에서 추출된 지식을 학생 모델로 효과적으로 전달하는 프로세스
- 실제로 mGLW moduleㅡ이 전체적인 아키텍처는 다음과 같음. 
    <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/9월/25.9.12/mGLW.png" alt="results" width="700">

- III. B(1) : preprocessing 단계
    - 왼쪽의 세 블록은 각각 T1, T2, S의 last stage block의 출력 Feature Map(Embedding)
    - 그림만 보더라도, 각 model의 architecture 및 Feature Dimension에 따라서, 각 input embeddings?(feature embeddings?)의 shape이 다르다.
    - 그래서 효율적인 knowledge extraction 및 transfer를 위해서, 이 dimension을 standardization 해주어야함.
    - 어떻게 Standardization을 했냐면, Lt1, Lt2, Ls 중 가장 작은 token size를 식별하고, 그 중 가장 작은 L값을 표준 토큰 크기 L로 지정함. (L은 Token size ← Window Length?)
    - 그 후, 다양한 토큰 크기를 가진 embedding에 간단한 projection layer를 적용하여 표준 크기 L로 변환함. (근데, 어차피 Student가 애초에 작은 모델이라 Ls가 자주 선택됨)
    - Token Size와 마찬가지로, standard embedding dimension D 또한, Dt1, Dt2, Ds 중 가장 작은 dimension에 맞춰주기 위해서 Linear Projection을 수행하였다. (D는 dimension ← channel)
    - 이 결과, 모든 Teachers, Student 모델에서 얻어진 Last Stage Block의 Feature가 같은 Dimension으로 맞춰지게 됨. → Et1, Et2, Es

- III. B(2) : Knowledge Binding and Refinement module (CCT의 CSA와 동일) Θ
    - 얻어진 Input embeddings를 가지고, Global Latent Workspace를 업데이트 하는 모듈임.
    - Global Latent Workspace (Knowledge Slots) ζ이 존재한다. → 이것을 학습 가능한 linear projection을 통해 Query(ζ)로 변환.
    - 각 Teacher로 부터 얻어진 Input Embeddings(Et1, Et2)를 각각 학습 가능한 Linear Projection을 통해 Key(Et1, Et2), Value(Et1, Et2)로 변환한다.
    - 얻어진 Query와 Key를 통해서, Knowledge Importance Score를 계산한다.(Attention을 통해서)
    - Query가 Knowledge Slot이고, Key/Value가 Input Embeddings이기 때문에, 각 input embedding의 token하나마다, 어떤 슬롯에 속할지를 확률적으로 배정 하는 식의 Score가 매겨지고, 이것이 Attention Weight임.
    - <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/9월/25.9.12/Attention.png" alt="results" width="700">
    - 이번에는 얻어진 KIS(Attention weight)를 다시 token l마다 Knowledge Slot(ζ)으로의 정규화(합이 1)를 하여, 각 슬롯이 각 input embedding token을 얼마나 가질 지에 대한 분포로 변환한다.
    - 이것을 각 Teacher에 개별적으로 수행을 하고, (가중치 x Value)를 각 Teacher마다 수행.
    - Hyperparameter \beta를 이용해서 각 Teacher에 대해 가중합을 수행. → 이 값을 Input, initial State는 기존의 Slot으로 하여, GRU로 업데이트를 한다.

- III. B(3) : Knowledge Transfer Module Ω (CCT의 CA와 비슷)
    - 업데이트된 Knowledge Slot을 이용하여, Student의 Input Embedding(Feature)표현을 Slot을 이용한 표현과 원본 표현의 합(Residual connection)으로 표현한 뒤, 최종 class 예측에 사용한다.
    - 업데이트된 Knowledge Slot(ζ)을 각각 Linear Projection하여 Key(ζ), Value(ζ)를 얻고, Student의 Input Embedding(Es)을 Linear Projection하여 Query(Es)를 얻음.
    - 이번에는 KTS(Knowledge Transfer Score)를 얻을건데, 똑같이 Query(Es)와 Key(ζ)를 Attention하여 가중치를 얻는 방식으로 얻음. (물론 Softmax를 해서 합이 1이 되도록.)
        - KTS는 (L x D)의 Es와 (K x D)인 knowledge slot ζ 를 곱해서 얻기 때문에, (L x K)의 형태로 나옴. (ζ에 Transpose)
    - KIS는 Slot을 업데이트하기 위해서, Knowledge Slot을 Input Embedding의 표현으로 나타낸 것이라면, KTS는 반대로 Student의 Input Embedding을 Knowledge Slot에 기반한 표현으로 만들기 위해 얻어진 Score(weight)임.
    - 그래서 얻어진 KTS와 Value(ζ)를 곱해서 student의 input embedding을 knowledge slot을 이용해 나타낸 표현으로 만든다.
        - 그러면 weight는 (L x K)이고, value(ζ)는 (K x D)이므로, 최종 shape은 (L x D)임.
    - 마지막으로 최종 분류를 위해서 입력으로 넣기 전에, 기존의 Es를 Residual Connection과 같은 느낌으로 더해준다. Es도 (L x D)형태라서 그냥 더해짐.
    - 그러면 Student의 마지막 Feature Embedding과 이것의 Slot표현을 모두 포함한 정보를 분류기에 넣음으로써, Prediction에 유리할 수 있다는 것 같다.

- [그냥 궁금증] III. B(2)에서 KIS를 얻을 때 왜 바로 L에 대해서 Softmax를 하지 않고, K에 대해 Softmax를 한 뒤, 다시 L에 대해 정규화했을까?
    - K에 대해서 Softmax를 하는 것의 의미 : Input Embedding의 한 Token을 슬롯 k들 사이에 경쟁적(합이 1)으로 배정하는 역할.
        - 한 토큰에 대해서 여러 슬롯이 높은 score를 가질 수 없게 함.
        - 이 토큰이 어떤 knowledge slot에 포함될 수 있는지를 특정하기 위함임.
    - L에 대해서 정규화하는 것의 의미 : Knowledge Slot이 맡은 토큰들을(score) 행 합으로 나누어주는 역할.
        - Slot 입장에서, 자신이 맡은 Input Embedding Token들이 어느정도 되는지를 다시 합이 1이 되도록 배정하는 역할.
        - 슬롯 별로 input embedding token의 가중 평균을 만들 때 scale을 맞춰주어 안정적일 수 있게 하기 위함임.
    - 즉, 바로 L에 대해서 softmax를 수행한다면, 한 Input embedding token이 여러 Knowledge Slot에 높은 점수를 받을 수도 있기 때문에, 이 일을 하는 효과가 미미해질 수 있다?
        - 슬롯의 전문화 약화?

### Loss 설계
- Batch-specific Dynamic Coefficients: 배치마다 두 Teacher의 비중을 자동으로 조절하는 가중치를 설계하는 부분.
    - student의 KTS(Student가 현재 집중하는 Knowledge Slot의 Score)와 각 Teacher의 KIS(교사가 관점에서 이 토큰은 어떤 knowledge Slot에 속할지의 score)를 비교해서, 더 비슷한 Teacher에 더 큰 가중치를 주기 위함임.
    - KIS와 KTS는 둘 다 각 Input Embedding의 Token이 각 slot에 대해 어느 정도의 가중치를 줬는지에 대한 Score이므로, 서로 대응이 되는 분포값임.
    - 이렇게 해서, Student의 KTS와 T1의 KIS 차이를 A, Student와 T2의 차이를 B라고 했을 때 alpha = B / (A+B) 라고 했을 때 1-alpha = A / (A+B) 이므로, 정확히 합이 1인 가중치가 된다.
    - 근데, 수식을 보면 alpha는 살짝 다른데, δ와 γ를 둬서, γ라는 최소치를 정해두게 되고, 한 Teacher에만 너무 커지지 않게 하기 위해서 δ와 alpha 중 더 작은 값을 사용한다.
- Logits from Different Teachers: logits-based loss
    - 위에서 얻어진 가중치 alpha를 이용해서 logits기반의 loss를 설계
    - L_Km과 L_Kc 두개가 있는데, L_Km은 내가 아는 logits-based loss 그대로.
    - L_Kc는 intra-class feature relationship에 대한 loss임. 같은 sample에 대해서, Teacher와 Student가 예측한 각 class의 logits을 Pearson correlation으로 가중합하여 loss를 얻음.
        - Pearson correlation은 +1에 가까울 수록 강한 양의 상관관계, -1에 가까울 수록 강한 음의 상관관계를 가지므로, 비슷할 수록 loss가 0에 수렴함.
- Similarities for Different Teachers : 각 Teacher와 Student의 layer pairs에서 얻은 Similarity Map에 대한 MSE loss임. 
    - 내가 아는 SP loss가 맞는데, batch^2으로 나누어주는게 좀 다른듯?
- Regularizer by the Multi-GLW module : 아까 본 alpha가 효과적이려면, student와 두 teacher 간의 distance가 최소가 되어야 함.
    - 단순히 alpha를 결정하는 수식에 있던, Student의 KTS와 각 Teacher의 KIS의 차이를 줄여주는 MSE loss를 각각 더한 것이다.


## 내가 생각하는 각 논문의 방법론 차이점/공통 
### CCT
- Image에 대해서 수행함.
- ViT나 CNN과 같은 Backbone을 통해 Feature를 추출하고, 그것을 이용하여 Slot 업데이트(CSA)와 Slot에 대한 표현(CA)으로 변환함.
- 단일 모델에서 사용되는 프레임워크이기 때문에, 이 모델이 추출한 Feature를 이용해서 Slot을 업데이트하고, 업데이트된 Slot을 이용해서 다시 이 모델의 Feature를 Slot에 대한 표현으로 변환한 후 최종 클래스 예측에 사용.

### mGLW
- Time-series에 대해서 수행.
- Multimodal KD 라는 프레임워크 내에서 작동시키려다 보니, 전처리 과정이 추가됨. (각 data shape과, architecture 간의 차이 극복)
- 각 Network의 마지막 Block의 output Feature들의 Shape을 맞춰주고(Embedding input, e) Teacher들의 정보(eT1, eT2)로만 Knowledge Slot을 업데이트함.
- Teacher들의 정보로 업데이트된 Knowledge Slot을 이용해서, Student의 정보(eS)를 Knowledge Slot에 대한 표현으로 변환한 후, 최종 클래스 예측에 사용.

### LaBo