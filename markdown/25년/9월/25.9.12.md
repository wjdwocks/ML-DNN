## CCT 논문 다시 정리
### introduction
- 1. AI는 여러 분야에 대해서 눈에 띄는 성과를 보여왔지만, medical, health care, infrastructure safety 등의 약간의 실수조차 용납되지 않는 분야에서는, AI 특유의 블랙박스 특성(왜 그런 선택을 한 것인가?)이 문제가 되고, interpretable AI가 주목받는 계기가 됨.
- 2. interpretable AI 중 가장 유명한 방법은 post-hoc 방식이다. 이 방식은, 모델이 학습된 후, 계산된 파라미터 값 등을 역추적해 어떤 feature가 prediction 과정에 큰 영향을 미쳤는지 확인하는 방식이다. 이 방식의 단점은 post-hoc 방식이 대체적으로 low-level features에 집중을 한다는 것임.
- 3. intrinsically interpretable model 방식도 있는데, 이것은 애초에 모델이 사람이 이해할 수 있는 'concepts'에 기반하여 의사결정을 수행하는 모델이다. 이 방식의 단점은 몸값이 비싸신 domain expert의 도움을 받아서 데이터셋을 재구성하던가 해야함.
- ------여기까지가 빌드업-------
- 4. 이상적으로는, intrinsically interpretable model은 개별적인 의미있는 modules를 가지고 있으며, 모듈형 설명은 인간의 이해 향상 및 AI 개발에 지속적인 영감을 줄 수 있음.
- 5. 그래서, 우리는 interpretable model의 모듈성(modularity) 개선을 위해서, SGW(shared global workspace)의 개념을 이용하여 CCT 프레임워크를 제안한다.
- 6. CCT를 이용해서 훈련된 모델은 concept에 대한 ground-truth explanations의 guidance 가 있든 말든 semantic comcepts(의미 개념)을 추출할 수 있는 모듈화된 구조를 가질 수 있다.

### 그래서 CCT가 어떻게 동작하는지
- Input x → backbone 을 통핸 Feature Vector 추출 → CSA 모듈에 입력 후 Slot Attention을 이용한 Slot Update → CA 모듈에 입력(feature vectors) 후 Updated Slot(SGW)와의 Cross Attention을 이용한 최종 prediction. # 이렇게 동작함.
- 1. Input x (batch 단위의 이미지들이 들어갈 것임.)가 backbone (ViT나, CNN)에 입력으로 들어가서 Feature Vectors를 출력함.
- 2. 이 Feature Vectors를 CSA모듈에 입력으로 넣는다. 
- 3. [CSA 모듈]CSA 모듈은 SGW의 역할을 하는 Concept Slots을 Query, Feature Vectors를 Key/Value로 하여, Slot Attention을 수행한다. (Concept Slot들을 이번 입력 Feature Vectors를 이용한 표현으로 바꾸기.)
- 4. [CSA 모듈]이 때, 모든 Feature Vectors에 대해 각 Slot들이, 합이 1이 되도록 attention weights를 부여한다. (각 Feature Vector l_i 마다 가중치의 합이 1)
- 5. [CSA 모듈]이 것의 의미는, 기존의 Concept 들로 이번에 들어온 Feature Vector들을 얼마나 잘 설명할 수 있는지와 이 Feature Vector들을 더 잘 설명할 수 있는 concept으로 업데이트하기 위함임.
- 6. [CSA 모듈]Concept Slot은, Feature Vector들(Value)에 attention 가중치를 곱해서 얻어진 벡터를 입력으로, 기존의 initial concept slots을 기존 state로 하여 GRU를 통해 업데이트된다.
- 7. [CA 모듈]CA모듈은, Backbone을 통해 얻어진 Feature Vector들을 다시 Concept 단위로 해석하기 위한 모듈이다.
- 8. [CA 모듈]Query는 Input Features, Key/Value는 Concept Slot Vectors로, Input Features를 Concept Slot Vectors에 기반한 값으로 변환하기 위함.
- 9. [CA 모듈]각 Feature Vector는 모든 Slot Vector와 Attention을 수행하고, Slot Vector와의 가중합을 통해 Slot Vector를 이용한 값으로 표현됨.
- 10. [최종 클래스 예측]input x에 대해 여러 가지 feature vectors가 나오게 되고, 이것들을 입력으로 받은 CA모듈은 여러 개의 벡터들을 출력할 것임. 
- 11. [최종 클래스 예측]그럼 이 벡터들을 마지막 classification을 위한 Linear Layer에 통과시켜서 최종 클래스 예측을 수행하고, Cross-Entropy Loss를 얻음.

### Loss 설계
- CE loss : 예측한 class와 실제 class와의 차이.
- Explanation Loss : interpretable한 특성을 학습 objective function에 직접 넣자는 의미임.
    - 사람이 봤을 때 설명이 납득 가능한가? 라는 것을 해결하기 위한 loss
    - 핵심 아이디어 : Attention Head가 어디를 볼지를 명시적으로 supervise 하는 것. domain 지식을 활용하여, 정확한 Prediction을 위해 중요한 부분 쪽으로 모델의 Attention이 모이도록 유도한다.
    - 실제로 사람이 제공한 Attention Distribution와 CCT의 Cross-Attention에서 실제로 나온 Attention 가중치를 MSE로 비교하여 loss에 추가함.
- Sparsity Loss based on entropy : 각 Feature Vector가 CA 모듈을 통해 Concept기반 표현이 될 때 그 가중치가 하나에 집중할 수 있게 하는 loss
    - 특정 Feature Vector가 여러 concept을 가질 이유는 거의 없다.(아주 일부분의 정보만 가질 테니.)
    - 그렇기 때문에, 각 Feature Vector가 여러 Concept 모두에 큰 가중치를 가진다는건 학습이 잘 안되었다는 의미.
    - 이것을 loss에 넣어서, 여러 concept에 고루 높은 weight를 가지면 loss를 크게 하는 방식으로, 한 concept에 치우칠 수 있도록 유도함.

## LaBo 논문 다시 자세히 읽어보기

## mGLW 논문 공부.
