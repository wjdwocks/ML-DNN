## 해야 할 것
- 논문 세개 읽고, 분석하기
- 논문 쓰던거 계속 쓰려고 노력하기
- 




## CCT 논문 다시 정리
### introduction
- 1. AI는 여러 분야에 대해서 눈에 띄는 성과를 보여왔지만, medical, health care, infrastructure safety 등의 약간의 실수조차 용납되지 않는 분야에서는, AI 특유의 블랙박스 특성(왜 그런 선택을 한 것인가?)이 문제가 되고, interpretable AI가 주목받는 계기가 됨.
- 2. interpretable AI 중 가장 유명한 방법은 post-hoc 방식이다. 이 방식은, 모델이 학습된 후, 계산된 파라미터 값 등을 역추적해 어떤 feature가 prediction 과정에 큰 영향을 미쳤는지 확인하는 방식이다. 이 방식의 단점은 post-hoc 방식이 대체적으로 low-level features에 집중을 한다는 것임.
- 3. intrinsically interpretable model 방식도 있는데, 이것은 애초에 모델이 사람이 이해할 수 있는 'concepts'에 기반하여 의사결정을 수행하는 모델이다. 이 방식의 단점은 몸값이 비싸신 domain expert의 도움을 받아서 데이터셋을 재구성하던가 해야함.
- ------여기까지가 빌드업-------
- 4. 이상적으로는, intrinsically interpretable model은 개별적인 의미있는 modules를 가지고 있으며, 모듈형 설명은 인간의 이해 향상 및 AI 개발에 지속적인 영감을 줄 수 있음.
- 5. 그래서, 우리는 interpretable model의 모듈성(modularity) 개선을 위해서, SGW(shared global workspace)의 개념을 이용하여 CCT 프레임워크를 제안한다.
- 6. CCT를 이용해서 훈련된 모델은 concept에 대한 ground-truth explanations의 guidance 가 있든 말든 semantic comcepts(의미 개념)을 추출할 수 있는 모듈화된 구조를 가질 수 있다.

### 그래서 CCT가 어떻게 동작하는지
- Input x → backbone 을 통해 Feature Vector 추출 → CSA 모듈에 입력 후 Slot Attention을 이용한 Slot Update → CA 모듈에 입력(feature vectors) 후 Updated Slot(SGW)와의 Cross Attention을 이용한 최종 prediction. # 이렇게 동작함.
- 1. Input x (batch 단위의 이미지들이 들어갈 것임.)가 backbone (ViT나, CNN)에 입력으로 들어가서 Feature Vectors를 출력함.
- 2. 이 Feature Vectors를 CSA모듈에 입력으로 넣는다. 
- 3.  [CSA 모듈]CSA 모듈은 SGW의 역할을 하는 Concept Slots을 Query, Feature Vectors를 Key/Value로 하여, Slot Attention을 수행한다. (Concept Slot들을 이번 입력 Feature Vectors를 이용한 표현으로 바꾸기.)
- 4.  [CSA 모듈]이 때, 모든 Feature Vectors에 대해 각 Slot들이, 합이 1이 되도록 attention weights를 부여한다. (각 Feature Vector l_i 마다 가중치의 합이 1)
- 5.  [CSA 모듈]이 것의 의미는, 기존의 Concept 들로 이번에 들어온 Feature Vector들을 얼마나 잘 설명할 수 있는지와 이 Feature Vector들을 더 잘 설명할 수 있는 concept으로 업데이트하기 위함임.
- 6.  [CSA 모듈]Concept Slot은, Feature Vector들(Value)에 attention 가중치를 곱해서 얻어진 벡터를 입력으로, 기존의 initial concept slots을 기존 state로 하여 GRU를 통해 업데이트된다.
- 7.   [CA 모듈]CA모듈은, Backbone을 통해 얻어진 Feature Vector들을 다시 Concept 단위로 해석하기 위한 모듈이다.
- 8.   [CA 모듈]Query는 Input Features, Key/Value는 Concept Slot Vectors로, Input Features를 Concept Slot Vectors에 기반한 값으로 변환하기 위함.
- 9.   [CA 모듈]각 Feature Vector는 모든 Slot Vector와 Attention을 수행하고, Slot Vector와의 가중합을 통해 Slot Vector를 이용한 값으로 표현됨.
- 10.   [최종 클래스 예측]input x에 대해 여러 가지 feature vectors가 나오게 되고, 이것들을 입력으로 받은 CA모듈은 여러 개의 벡터들을 출력할 것임. 
- 11.   [최종 클래스 예측]그럼 이 벡터들을 마지막 classification을 위한 Linear Layer에 통과시켜서 최종 클래스 예측을 수행하고, Cross-Entropy Loss를 얻음.

### Loss 설계
- CE loss : 예측한 class와 실제 class와의 차이.
- Explanation Loss : interpretable한 특성을 학습 objective function에 직접 넣자는 의미임.
    - 사람이 봤을 때 설명이 납득 가능한가? 라는 것을 해결하기 위한 loss
    - 핵심 아이디어 : Attention Head가 어디를 볼지를 명시적으로 supervise 하는 것. domain 지식을 활용하여, 정확한 Prediction을 위해 중요한 부분 쪽으로 모델의 Attention이 모이도록 유도한다.
    - 실제로 사람이 제공한 Attention Distribution와 CCT의 Cross-Attention에서 실제로 나온 Attention 가중치를 MSE로 비교하여 loss에 추가함.
- Sparsity Loss based on entropy : 각 Feature Vector가 CA 모듈을 통해 Concept기반 표현이 될 때 그 가중치가 하나에 집중할 수 있게 하는 loss
    - 특정 Feature Vector가 여러 concept을 가질 이유는 거의 없다.(아주 일부분의 정보만 가질 테니.)
    - 그렇기 때문에, 각 Feature Vector가 여러 Concept 모두에 큰 가중치를 가진다는건 학습이 잘 안되었다는 의미.
    - 이것을 loss에 넣어서, 여러 concept에 고루 높은 weight를 가지면 loss를 크게 하는 방식으로, 한 concept에 치우칠 수 있도록 유도함.




## LaBo 논문 다시 자세히 읽어보기
### Introduction
- 

### Proposed Method
- 













## mGLW 논문 공부.
### Introduction 뜯어보기.
- Wearable Sensor를 통한 AI가 건강 관련 분야에서 큰 성공을 이뤘다.
- wearable sensor는 sensor noise, 불규칙적인 sampling rates, individual difference(개인차)와 같은 문제가 있음.
- 그래서, 우리는 Sensor Data를 PI로 변환하는 TDA를 사용하려고 함.
- 그런데, 센서로부터 PI를 얻는 데에 큰 computational cost가 발생해서, wearable sensor device와 같이 경량화 모델에서는 쉽지 않다.
- 그래서, KD를 사용한다. multiple teacher가 각각 다른 modality를 사용하는 경우, student는 다양한 feature 정보를 습득할 수 있게 됨.
- 하지만, 그 경우에도 multimodal data의 feature dimensions가 다르다는 문제와, 서로 다른 Teacher 들 간에 knowledge가 conflict 할 수 있다는 문제가 있음.
- 이것들을 모두 해결하기 위해서, multimodal Global Latent Workspace-based Knowledge Distillation(mGLW-KD) 프레임워크를 제안한다. - 이것 또한 Global Workspace Theory에 영향을 받음.
- mGLW-KD는, working memory module을 통합하여, 여러 교사 모델의 다양한 지식을 shared latent workspace로 통합하고, 이를 통해 student로 효율적인 지식 전달을 수행함.
- topological insights와 cognitive principles를 통합하여 wearable sensor로 인한 문제를 해결하고, student는 추론 과정에서 time-series만 가지고도 탁월한 성능을 냄.
- 또한, Teacher와 Student 간의 Gap을 해소하기 위해서, feature correlations에 따른 inter-class, intra-class를 활용하고, annealing strategy를 활용한다.

### Proposed Method
- multimodal data로부터 얻어진 Features는 다양한 지식을 포함하고, 풍부한 정보를 가지고 있어 모델 성능을 향상시켜줄 수 있다.
- 하지만, 서로 다른 modality로 얻어진 features를 direct로 합치는 것은 heterogeneous dimension size를 갖고, 두 정보의 alignment에 어려움이 있을 수 있다.
- 그래서, mGLW 모듈을 도입한다. 
- mGLW는, multimodal 지식 추출 및 전달을 위한 핵심 component로, in our framework에서, embedding representation을 학습하여 제공된다.
- knowledge slots을 통합한 이 모듈(mGLW)은 두 개의 하위 구성 요소로 구성된다.
    1. 두 teacher 모델에서 knowledge importance score를 계산하고, 두 모델에서 aggregated(집계?)된 지식을 학습함.
    2. 교사 모델에서 추출된 지식을 학생 모델로 효과적으로 전달하는 프로세스
- 실제로 mGLW moduleㅡ이 전체적인 아키텍처는 다음과 같음. 
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/9월/25.9.12/mGLW.png" alt="results" width="700">

- III. B(1) : preprocessing 단계
    - 왼쪽의 세 블록은 각각 T1, T2, S의 last stage block임. (Block을 말하는건가? 마지막 블록의 출력 Feature를 말하는건가? - 당연히 블록 자체를 지칭할 리가 없겠지 바보야)
    - 그림만 보더라도, 각 model의 architecture 및 Feature Dimension에 따라서, 각 input embeddings?(feature embeddings?)의 shape이 다르다.
    - 그래서 효율적인 knowledge extraction 및 transfer를 위해서, 이 dimension을 standardization 해주어야함.
    - 






## 내가 생각하는 각 논문의 방법론 차이점/공통점