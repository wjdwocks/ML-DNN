- embedding 차원이 좀 general하게 될  수 있게 작성해보자. -> Projection에서의 Channel 처리와 같은 부분 어떻게 할 것인가?
- Signal에서 각 Channel에 대한 그림을 다시 그림.
- Methodology쪽에 기존 VQShape에서 안한 부분들을 스토리텔링적으로 잘 생각해봐야 함.
- Text를 왜 넣는가? 에 대한 Method적으로도 설명 및 잘 되는지에 대한 것.

- Sub-Action : Comminity Detection? 
- bag of words : paper라도 읽어보고 하자.
- 전제 : Label끼리 Share하는 Sub-Action이 있고, 아닌 Sub-Action이 있다는 것. + 보장되는 Class마다의 고유 Sub-Action의 portion비율도 어떻게 보장할지.
- 일단은 심플하게, motion에 대해서 간단한 단어 10개씩 출력해서 보자.

- 1. Word 어떻게 출력되었는지 Sh/USh(5/5) # Discord로 공유
- 2. 그림 수정해서. # 이후에
- 3. 3Channel을 1Channel로 AVG Pooling을 해서 사용한다? → 이거는 나중에 생각하자. 쉽게 될 것 같음.
- 4. 500 window는 뒤에 12 step에서 feeding을 해서 처리? (0을 추가해서 512로 맞춰줘도 된다는 의미)
    - 근데, 그냥 500window 유지하고, patch_len을 10, patch_num을 50으로 유지해도 될 듯.
