### 이번주 하려고 하는 것.
<li> 1 Teacher에 대해서 PAMAP 데이터 학습을 해보고, 결과를 보자. </li>
<li> YOLOv8n으로 CoCo 데이터셋 돌려보고 결과 보기. </li>
<li> NIPA과제 제안서 작성. </li>


### SPKD(Similarity Map을 비교하여 KD에 이용함.)
1. Teacher 네트워크와 Student 네트워크에서 생성된 Similarity Map을 서로 비교하여 KD에 사용하는 방법론.
2. SPKD에서 정의하는 특징 행렬 f = B x (W x H x C). (batch, width, height, channel) 임.
3. Similarity Map = f x f.T 로 표현하는데, 이를 통해서 Similarity Map의 Shape = (Batch x Batch) 이 된다.
4. Similarity Map의 형태가 Batch x Batch로 된다는 것은 내가 지금 하고 있듯이, Multi Modal Data의 경우(Teacher와 Student의 네트워크나, 데이터 형태가 다른 경우)에도 KD에 접목시킬 수 있게 된다.
5. 한번 시각화 해보자.
6. YOLO에 대해서도 SPKD를 사용할 수 있는지 궁금하다. 그 데이터가 어떻게 생겼는지와, 사용할 수 있을 지를 보자.


# YOLOv8을 통해 coco Dataset 학습 돌려보기.
## 데이터 준비
- pip install ultralytics
- ultralytics 라이브러리를 통해 yolo 모델을 쉽게 불러오거나, 저장할 수 있다.
- COCO 데이터셋 저장.
- 아레의 명령어를 이용하여 원격으로 서버에 zip 파일을 저장하고, 압축을 해제하여 사용할 수 있다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/coco_download.png" alt="coco_download" width="500">

## 데이터 전처리
- 위에서 저장한 데이터 파일들은 train(.jpg), val(.jpg), annotation(.json) 이렇게 세 가지로 이루어져 있다.
- annotation은 captions, instances, person_keypoints에 대해 각각 train, val이 있다.
- caption은 이미지의 설명이 들어가고, 
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/caption.png" alt="caption" width="800">
- person_keypoints에는 사람의 keypoint 데이터가 들어가고,
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/person_keypoint.png" alt="person_keypoint" width="800">
- instances에는 실제로 yolo가 학습에 사용 할 bounding box, 이미지의 label값, 이미지의 id 등이 들어간다.
- 또한 instances에는 images, annotations, categories의 세 부분으로 나누어지는데, 학습에 필요한 정보는, annotations부분의 bounding box, class_id등의 정보이다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/instances.png" alt="instances" width="500">
- YOLO를 학습하기 위해서는 각 이미지 파일에 대해 대응하는 txt파일로 label을 만들어 주어야 하기에 변환을 해주어야 함.
- 그래서 아레의 코드를 실행하여 coco/labels/ 위치에 label들을 저장해주어야 한다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/data_reshape.png" alt="data_reshape" width="500">
- 그렇게 하면 아레와 같이 image_id가 파일의 이름인 labels(image_id).txt로 label이 잘 만들어 진다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.20/labels.png" alt="labels" width="500">


## 학습 시작.
- 우선, 처음에 데이터 전처리를 잘못해서 모델이 labels의 위치를 못찾는 문제가 계속 발생했었음.
    - 경로를 잘못 설정했었다. (coco.yaml에 data를 coco/train2017 로 두었는데, labels를 coco/labels/train2017로 두었었음.)
    - coco/train2017/images/.jpg로 train_data를 사용하고, coco/train2017/labels/.txt 로 train_labels를 사용하도록 해야 정상적으로 작동한다.
- coco 학습 코드. (기본 예제 코드이다.)
    - 일단, YOLO를 사용하기 전에는 ultralytics 라이브러리를 설치하고, import해야 한다.
    - 그리고, model = ultralytics.YOLO('yolov8n.pt)를 사용하여 YOLOv8의 경량화 버전을 있으면 사용하고, 없다면 다운받아 사용하게 한다.
    - model.info()로 간단한 정보를 파악함.
    - torchinfo.summary()를 통해서 각 layer마다 input shape, output shape, num_param 을 쉽게 볼 수 있다. (하지만 모델자체가 복잡해서 어렵다.)
    - model.train()을 통해서 args.yaml 에 각종 hyper parameter (정말 많다. lr, cutmix 등...)를 넘겨주어 쉽게 학습을 수행할 수 있다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/Study/coco_train.png" alt="coco 학습코드" width="500">


## 학습 결과.
### 학습 하면서 출력되는 여러 지표들 분석.
- YOLOv8n을 사용했을 때 출력되는 손실 함수
    - box_loss : Bounding Box 손실, CIoU, GIoU, DIoU 등을 사용하여 계산된 loss 값을 의미함. (적을 수록 Ground Truth와 가까운 Bounding Box를 예측함.)
    - cls_loss : 클래스 분류 손실, Sigmoid + BCE Loss를 사용하여 다중 클래스 분류가 가능해짐.
    - dfl_loss : Bounding Box 좌표를 더 정밀하게 조정하는 역할. YOLOv8에서는 좌표(x, y, w, h)를 확률 분포로 예측하여 더 정밀한 위치 조정이 가능해졌다.
- YOLOv8n을 Validation 할 때 출력되는 평가 지표
    - Box(P) : Precision, 예측한 Bounding Box 중에서 실제로 맞은 박스의 비율. (False Positive를 방지함.)
        - 증가할 수록 불필요한 False Positive를 줄이며, 더 정확한 객체 탐지를 수행한다.
    - Box(R) : Recall, 실제 Ground Truth객체 중에서 모델이 제대로 탐지한 비율. (False Negative를 방지함.)
        - 증가할 수록 모델이 놓치는 객체(False Negative)를 줄이며, 더 많은 객체를 탐지할 수 있다.
    - Box(P, R)은 둘 다 높은게 좋지만, 하나가 높아지면 다른 하나는 줄어드는 Trade-off 관계라서 균형을 잘 가져가는게 중요하다.
    - mAP50 : IoU = 0.5일 때의 (50%정도만 GT와 Box가 겹쳐도 맞다고 쳐준다.) 성능평가 지표.
    - mAP50-95 : IoU = 0.5 ~ 0.95(0.05 간격) 에서 평균 mAP를 계산함. mAP50보다 엄격한 Box 평가 지표. (더 일반적인 평가 지표이다.)

### 학습 결과 분석.
- Yolo는 알아서 학습 결과에 대한 정보를 제공해준다. .csv랑 그래프랑 그려줘서. 이건 편하다.
- epoch 100을 기준으로 학습을 수행함. (YOLOv8 nano.)
- map50-95가 36 ~ 37정도로 나타나는 것으로 보아 제대로 잘 학습이 진행이 된 것 같다.
- 물론 마지막부분에서도 계속 올라가는 것으로 보아 epoch을 늘리면 더 높은 성능을 기대할 수 있을 것 같지만, 일단 인터넷에서 보던 YOLOv8 nano의 coco결과와 비슷한 것으로 보아 제대로 잘 학습이 진행된 것으로 보인다.

<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.27/coco_results.png" alt="results" width="700">

## NIPA 과제 제안서 작성.
### IV 세부 추진내용 작성
1. 목표 디지털 안전 모델
- 디지털 안전 모델 구성 및 개념 : 우리가 이 과제를 통해 하고자하는 일과, As-Is → To-Be에 대한 서술 (현재의 방식 vs 우리가 제안하는 방식). End To End 프로세스에 대한 설명과 도식화 작성. 마지막으로 이 기술의 도입에 따른 기대 효과 작성.
- 디지털 적용기술 개요 : 이 디지털 모델을 만들 때 들어가는 기술들과 그 기술을 어떻게 구현할 것인지에 대한 서술, 어떤 방식으로 이 기술을 구현할 것인지에 대한 작성. (일반인 수준에 맞춰 작성함.)


2. 디지털 안전 모델 내용
- 디지털 안전 모델 정의 및 범위 : 어떤 기술이 들어가는지
- 디지털 안전 모델 내용 : 위에서 기술한 기술들의 자세한 내용 및 실증할 것들.
- 유사 디지털 안전 모델과의 차별성 : 타사 기술과 특허에 대한 분석 및 우리 기술의 차별성 서술.


# PAMAP2 데이터셋 결과 보고.
## Teacher 단일 최고 평균

| test_id  | 0       | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 평균   | 표준편차  |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|----------|
| wrn16-1  | 80.9447 | 73.3248 | 79.6682 | 79.4604 | 80.4674 | 81.0622 | 84.9928 | 80.6856 | 92.3913 | 81.4442 | 0.9414   |
| wrn16-3  | 81.1863 | 72.4586 | 80.1698 | 81.6942 | 81.5744 | 81.2232 | 86.9841 | 80.7623 | 94.5652 | 82.2909 | 1.0928   |
| wrn28-1  | 83.1186 | 73.6051 | 79.4367 | 78.3000 | 81.0332 | 80.4989 | 86.3492 | 80.2763 | 94.5652 | 81.9092 | 1.0838   |
| wrn28-3  | 82.4745 | 78.2930 | 80.9414 | 81.6652 | 81.1316 | 80.0161 | 85.5988 | 81.1205 | 95.6522 | 82.9881 | 0.9501   |



## lambda = 0.1 최고 평균

| test_id  | 0       | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 평균   | 표준편차  |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|----------|
| wrn16-1  | 75.9796 | 78.0127 | 94.9074 | 92.0801 | 78.8684 | 89.5386 | 95.9885 | 64.9015 | 100.000 | 85.5863 | 2.1516  |
| wrn16-3  | 75.5770 | 73.8344 | 94.7917 | 92.9214 | 87.6753 | 89.2972 | 95.8153 | 66.1294 | 100.000 | 86.2269 | 2.1506  |
| wrn28-1  | 76.0333 | 73.6406 | 94.0972 | 92.0511 | 87.3555 | 89.2167 | 95.2958 | 59.1711 | 100.000 | 85.2068 | 2.4135  |
| wrn28-3  | 75.8991 | 76.1783 | 93.6728 | 90.4265 | 85.1415 | 88.6266 | 95.4690 | 72.0389 | 100.000 | 86.3836 | 1.8067   |

## lambda = 0.3 최고 평균

| test_id  | 0       | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 평균   | 표준편차  |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|----------|
| wrn16-1  | 77.1605 | 75.8217 | 94.3287 | 95.4163 | 84.9200 | 90.8262 | 96.1328 | 61.8573 | 100.000 | 86.2737 | 2.3067  |
| wrn16-3  | 76.2748 | 77.2229 | 94.6373 | 94.0528 | 90.3321 | 91.7918 | 95.4113 | 66.1806 | 100.000 | 87.3226 | 2.0929  |
| wrn28-1  | 77.5631 | 77.0955 | 95.1003 | 92.8343 | 79.6802 | 91.1749 | 95.8730 | 65.0550 | 100.000 | 86.0418 | 2.1472  |
| wrn28-3  | 77.6167 | 77.2229 | 94.5602 | 91.1807 | 84.0344 | 91.7650 | 96.4791 | 64.4922 | 100.000 | 86.3724 | 2.1200  |

## lambda = 0.5 최고 평균

| test_id  | 0       | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 평균   | 표준편차  |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|----------|
| wrn16-1  |  |  |  |  |  |  |  |  |  |  |   |
| wrn16-3  |  |  |  |  |  |  |  |  |  |  |   |
| wrn28-1  |  |  |  |  |  |  |  |  |  |  |   |
| wrn28-3  |  |  |  |  |  |  |  |  |  |  |   |

## lambda = 0.7 최고 평균

| test_id  | 0       | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 평균   | 표준편차  |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|----------|
| wrn16-1  | 82.4477 | 81.2229 | 94.2901 | 94.5170 | 89.4957 | 93.3476 | 95.7576 | 68.0993 | 100.000 |  |   |
| wrn16-3  | 77.4289 | 79.8726 | 94.3287 | 93.2695 | 85.9533 | 91.9528 | 95.3824 | 66.7178 |  |  |   |
| wrn28-1  | 80.4079 | 79.4395 | 94.5988 | 92.2831 | 85.5105 | 93.4281 | 96.4791 | 63.2387 |  |  |   |
| wrn28-3  | 79.8175 | 79.3885 | 94.2515 | 93.0954 | 84.9692 | 92.3283 | 95.7287 | 68.7132 |  |  |   |

## lambda = 0.9 최고 평균

| test_id  | 0       | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 평균   | 표준편차  |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|----------|
| wrn16-1  | 83.4407 | 82.5223 | 92.9784 | 95.6194 | 90.4551(?) | 92.1674 | 96.1616(?) | 64.7224 | 97.8261 | 88.4326 | 1.9175 |
| wrn16-3  | 81.5083 | 76.7898 | 94.7531 | 93.6176 | 86.6421 | 92.5429(?) | 95.4978 | 67.2806 | 100.000 | 87.6258 | 1.9565 |
| wrn28-1  | 78.6634 | 80.2038 | 94.1358 | 91.3548 | 86.9619 | 93.3745 | 95.5844 | 62.6247 | 100.000 | 86.9893 | 2.1314 |
| wrn28-3  | 81.2131 | 81.4268 | 94.3673 | 91.6449 | 83.2718 | 92.4088 | 95.9596 | 67.7667 | 100.000 | 87.5621 | 1.8489 |


## Trainning Environment
<ul>
<li> Dataset = GENE(life_log), PAMAP(이것도 HAR 데이터) </li> 
<li> python = 3.8.20 </li>
<li> pytorch = 2.4.1, CUDA 11.8 </li>
<li> GPU = NVIDIA GeForce RTX 4090 (서버) </li>
<li> CPU = ?? </li>
<li> epoch = 200 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.05 - 0.0001 (Adjust Learning Rate) </li>
<li> optimizer = Momentum + SGD </li>
</ul>