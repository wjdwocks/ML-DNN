## 이번주 한 것.



## 돌려야 할 것들
<li> PAMAP2 baseline으로 사용할 Role of Projection, MTKD_RL (gpu 남으면 돌리면 될듯) </li>
<li> PAMAP2 내꺼 3 Teacher annsp, ann 좀 더 돌려서 더 좋은 결과로 </li>
<li> GENE MobileNet GAF Teacher 학습 해놓고, 완전다른 Ablation 학습 코드 짜놓기 </li>

## 돌아가고 있는 것들
    - 0 : GENE 2Teacher Ablation (annsp), 
    - 1 : PAMAP2 3Teacher Ablation (base)
    - 2 : PAMAP2 3Teacher Ablation (base)
    - 3 : PAMAP2 3Teacher Ablation (ann)


## CCT 및 Latent Workspace with Multimodal Knowledge Distillation 이 논문 읽어보고 공부.
## Concept-Centric Transformers (CCT)
### Interpretable AI 
    - 설명 가능한 인공지능 : AI가 내리는 결정 과정을 사람이 이해할 수 있도록 설명할 수 있는 AI를 의미함.
        - 기존 딥러닝 모델은 Black-Box 라고 불림(왜 그런 결론을 내렸는지 설명할 수 없다.)
        - 기존 딥러닝 모델은 Pixel, Feature Map, Vector 수준에서 작동하기 때문에 사람이 직관적으로 이해하기 어려움.
        - Interpretable AI의 주요 접근법
            - Post-Hoc Explanation (사후적 설명)
                - 이미 학습된 블랙박스 모델을 해석하는 방석
                - LIME : 입력 데이터를 랜덤하게 조금씩 변경하면서 어떤 Feature가 결과에 얼마나 영향을 주는지 설명
                - SHAP : 게임이론 기반으로, 각 Feature가 결과에 미친 기여도를 계산함.
                - Grad-CAM : CNN기반 모델에서 어느 영역을 보고 판단했는지 시각화하는거 (논문에서 본 적 있는것 같다.)
            - Intrinsic Interpretability (내재적 설명 가능성)
                - 모델을 설계할 때부터 해석 가능하도록 구조를 설계하는것.
                - Decision Tree : 각 Feature에 대해 결정 경로가 명확하게 보인다.
                - Linear Model : 각 Feature의 가중치를 그대로 해석이 가능함.
                - Concept-based Model : 사람이 이해할 수 있는 개념 단위로 의사결정을 수행한다.
    - Concept : 사람이 직관적으로 이해할 수 있는 의미 단위를 의미함.
    - Concept based Model : 모델이 사람이 이해할 수 있는 개념 단위로 정보를 처리하거나, 설명을 유도하는 것을 의미함.
        - 기존 모델에서는 [1. 이미지 입력 → 2. Conv / Transformer를 통한 입력의 벡터연산 → 3. 결과 예측] 이런 순서대로 학습을 진행함.
        - Concept based Method는 [1. 이미지 입력 → 2. concept 단위 정보 처리 (부리:있음, 날개:큼, 다리:길다) → 3. 결과:독수리] 이런식으로 예측의 이유가 설명이 됨.
    

## 해야 할 남은것들
<li> 교수님이 보라고 하신 논문 읽어보기 (CCT 및 그거관련 아레 얘들 다 관련 있다고 함.) </li>
<li> https://arxiv.org/abs/2305.15775 - Concept-Centric Transformer (아직) </li>
<li> https://arxiv.org/pdf/2502.11418 - TimeCAP (아직) </li>
<li> Improved Knowledge Distillation Based on Global Latent Workspace with MultiModal Knowledge Fusion for Understanding Topological Guidance on Wearable Sensor Data </li>
<li> CTPD (Cross-Modal Temporal Pattern Discovery) </li>
<li> 논문 어떻게 작성할지에 대한 초안 작성 </li>
<li> 영어공부(심심할 때 틈틈히) </li>

---

### Teacher 특이조합에 대해서 실험 진행 (GENE_Activ, PAMAP 둘다 적용) ! 코드작업 선행 필요. (아마 오래 걸릴 것.)
- 특이조합에 대해서는 Wide Resnet 기준 2Teacher(GAF+Sig, PI+Sig) 특이조합과 3Teacher(GAF+PI+Sig) 특이조합에 대해서 실험해야함. (Student는 wrn161 고정.)
- 각 조합에 대해서 Base와 annsp로 실험. (alpha나 lambda는 이미 찾은 값으로.)
- 2Teacher (Image + Signal)
    * Depth-wise - (wrn281 + wrn161), (wrn161 + wrn281)
    * Width-wise - (wrn163 + wrn161), (wrn161 + wrn163)
    * D+W-wise - (wrn281 + wrn163), (wrn163 + wrn281)
- 3Teacher (GAF + PI + Sig)
    * Depth-wise - (wrn281 + wrn161 + wrn161), (wrn161 + wrn281 + wrn161), (wrn161 + wrn161 + wrn281)
    * Width-wise - (wrn163 + wrn161 + wrn161), (wrn161 + wrn163 + wrn161), (wrn161 + wrn161 + wrn163)
    * D+W-wise - (wrn281 + wrn163 + wrn161), (wrn163 + wrn281 + wrn161)

### Teacher - Student 특이조합(모델 구조 완전변형)
- 완전특이조합 Mobile net이나, Resnet, VGG를 이용한 특이조합에 대한 추가 실험
- 여기는 Teacher끼리는 같은 모델을 사용한다.
- 아레의 조합에 대해서 찾아야 할 값 
    - Student의 성능.
    - Sig → Sig의 성능 (1Teacher)
    - Pi+Sig → Sig의 성능 (2Teacher, base, ann)
    - GAF+Sig → Sig의 성능 (2Teacher, base, ann)
    - GAF+Pi+Sig → Sig의 성능 (3Teacher, base, ann, annsp)
```
    - T : wrn-163 → S : RN8
    - T : wrn-281 → S : RN20, vgg8
    - T : RN44 → S : vgg8, wrn-161
    - T : MN.V2 → S : RN8
```