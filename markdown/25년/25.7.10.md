## 이번주 할 것.
- CCT 논문 읽고 완전히 이해하기
- CTPD 논문 읽어보기 
- 논문쓸거 초안 작성해보기 (하면서 추가적으로 뭘 보여주면 좋을지?) 
- https://github.com/wjdwocks/ML-DNN/blob/main/markdown/my_study/%EB%85%BC%EB%AC%B8%EC%B4%88%EC%95%88.md (초안)
- 학습 계속 돌리기


## 돌려야 할 것들
<li> PAMAP2 내꺼 3 Teacher annsp, ann 혹은 base도? 좀 더 돌려서 더 좋은 결과로 </li>
<li> PAMAP2 WideResnet 다른조합 돌리는중 </li>
<li> PAMAP2 Another 다른조합 돌려야함(GAF Teacher 만드는것부터.) </li>


## 돌아가고 있는 것들
- 0 : PAMAP2 3Teacher MTKD (baseline), PAMAP2 Albation base 잘못돌린거 다시 돌리는중
- 1 : PAMAP2 3Teacher Ablation (annsp) - 1
- 2 : PAMAP2 3Teacher 433 추가실험
- 3 : PAMAP2 3Teacher Ablation (ann) - 2


## CCT 및 Latent Workspace with Multimodal Knowledge Distillation 이 논문 읽어보고 공부.
## Concept-Centric Transformers (CCT)
### Interpretable AI 
- 설명 가능한 인공지능 : AI가 내리는 결정 과정을 사람이 이해할 수 있도록 설명할 수 있는 AI를 의미함.
    - 기존 딥러닝 모델은 Black-Box 라고 불림(왜 그런 결론을 내렸는지 설명할 수 없다.)
    - 기존 딥러닝 모델은 Pixel, Feature Map, Vector 수준에서 작동하기 때문에 사람이 직관적으로 이해하기 어려움.
    - Interpretable AI의 주요 접근법
        - Post-Hoc Explanation (사후적 설명)
            - 이미 학습된 블랙박스 모델을 해석하는 방석
            - LIME : 입력 데이터를 랜덤하게 조금씩 변경하면서 어떤 Feature가 결과에 얼마나 영향을 주는지 설명
            - SHAP : 게임이론 기반으로, 각 Feature가 결과에 미친 기여도를 계산함.
            - Grad-CAM : CNN기반 모델에서 어느 영역을 보고 판단했는지 시각화하는거 (논문에서 본 적 있는것 같다.)
        - Intrinsic Interpretability (내재적 설명 가능성)
            - 모델을 설계할 때부터 해석 가능하도록 구조를 설계하는것.
            - Decision Tree : 각 Feature에 대해 결정 경로가 명확하게 보인다.
            - Linear Model : 각 Feature의 가중치를 그대로 해석이 가능함.
            - Concept-based Model : 사람이 이해할 수 있는 개념 단위로 의사결정을 수행한다.
- Concept : 사람이 직관적으로 이해할 수 있는 의미 단위를 의미함.
- Concept based Model : 모델이 사람이 이해할 수 있는 개념 단위로 정보를 처리하거나, 설명을 유도하는 것을 의미함.
    - 기존 모델에서는 [1. 이미지 입력 → 2. Conv / Transformer를 통한 입력의 벡터연산 → 3. 결과 예측] 이런 순서대로 학습을 진행함.
    - Concept based Method는 [1. 이미지 입력 → 2. concept 단위 정보 처리 (부리:있음, 날개:큼, 다리:길다) → 3. 결과:독수리] 이런식으로 예측의 이유가 설명이 됨.

### Introduction
- Interpretable Model은 각 부분이 명확한 의미를 가진 모듈들로 구성된 설명을 생성해야 한다. 
    - Concept-Centroc Transformer라는 구조를 제안한다. 
    - CCT는 Shard Global Workspace(SGW)이론에서 영감을 받았으며, 여러 개의 특화된 모듈들이 공유 메모리에 경쟁적으로 접근하도록 설계되어 모듈화를 자연스럽게 유도함.
    - 이 CCT 라는 구조를 통해 모델은 단순하고, 모듈화된 구조로 사람이 이해 가능한 개념을 추출할 수 있게 된다.
- CCT는 세 가지 주요 구성 요소로 설계된다.
    - 1. Concept-Slot-Attention(CSA) 모듈
        - Backbone에서 나온 이미지 embedding을 입력으로 받음. (여기서 백본은 ViT, CNN 같은 모델을 쓴다고 했으니, Patch Embedding → Transformer Encoder → Latent Feature 이므로, 이 정제된 Latent Vector를 입력해준다는 거임.)
        - Input Feature와 Slot 간의 Slot Attention을 수행하여 task-specific한 Slot이 되도록 GRU를 통해 업데이트됨. (사람이 해석 가능한 개념에 대응하는 벡터)
        - 여기서 Slot은 interpretable한 Concept을 의미하고, 이 Slot을 더 Task-Specific하게 업데이트하기 위해서 Slot Attention을 수행한다. (Slot Attention은 Related Work에서 설명)
    - 2. Cross-Attention(CA) 모듈
        - CSA 모듈이 Task-Specific한 Slots(Concept Embedding)과 Input Feature(백본의 Latent Feature(Feature Map)) 간의 Cross-Attention을 수행한다.
        - Query : Input Feature (백본의 Feature)
        - Key/Value : Concept Embedding (CSA모듈로 얻은 Concept Embedding)
        - Cross-Attention 결과 : 각 백본의 Feature가 어떤 Concept과 관련이 있는지 가중합된 Vector가 생성됨. (어떤 Concept에 주로 의존했는가)
        - 이 가중합된 Vector가 최종 Classification Head로 들어가서 클래스 예측을 수행한다.
        - 즉, 이제 Task-Specific한 Slot(Concept Embedding)과 Input Feature를 다시 Cross-Attention하여, 각 입력 Feature가 어떤 Concept에 관련이 있는지 각 Slot마다의 가중치를 알게 되고, 모든 Feature에 대해 Slot value x Weight 를 수행한다.
        - 그 다음으로, 그 Feature들에 대한 Feature Set의 정보를 모아서 Classfication을 수행한다.
    - 3. Loss 설계
        - Explanation Loss(설명 손실) : 도메인 지식을 활용하여 올바른 개념에 집중하도록 유도함.
            - 목적: 모델이 도메인 전문가(Ground Truth)가 중요하다고 생각하는 개념에 집중하도록 유도.
            - 데이터셋에 '이 이미지에서 중요한 개념은 무엇이다' 라는 Ground Truth Concept Annotation이 존재함.
            - 모델이 예측한 Attention 가중치가 Ground Truth Concept Annotation과 얼마나 일치하는지 비교함.
            - Cross-Entropy 또는 Distance Loss로 이 차이를 줄이도록 학습함.
        - Sparsity Loss(희소성 손실) : Attention이 정말 중요한 Feature에 집중하도록, 희소하게 분포하도록 강제함.
            - 목적 : 모델이 모든 Concept에 골고루 Attention 하지 말고, 정말 중요한 Concept에만 집중하도록 강제하는 loss
            - Cross-Attention 가중치의 Entropy를 최소화하도록 학습함
            - Entropy가 작다 → 특정 Concept에 집중 → Sparse한 분포

### Related Work
- SGW(Shared Global Workspace)
    - 여러 모듈이 '공유 메모리'를 통해 정보를 주고받으며, 중요한 정보만 Bottleneck을 통해 공유한다.
    - 기존의 Concept Transformer 논문에서는 개별 image patch만을 기반으로 Concept을 추출하기 때문에, Global Concept을 잘못 학습할 수 있었다.
    - 이 논문에서는 SGW를 통해 서로 다른 모듈간 정보 공유와 Concept 일반화를 동시에 달성하고자 함.

- Slot Attention
    - Slot은 한정된 개수의 Concept을 저장하는 공간이다.
    - CSA에서 Slot Attention을 수행하여 Slot이 더 좋은 Concept Vector표현이 되도록 업데이트됨.
    - 1. 입력
        - 입력 샘플이 Backbone(CNN or ViT)를 통과한 뒤 나온 Feature Vector (N 개)가 입력으로 들어옴.
    - 2. Slot의 상태
        - Slot은 고정된 개수로 존재한다.
        - k개의 slot이 있다면, 모델이 학습할 Concept의 수가 k개이고, 사람이 해석할 수 있는 개념 단위가 k개 있다는거임.
    - 3. 경쟁적 Attention 수행
        - Query : 각 Slot들
        - Key/Value : 입력 Feature Vector들
        - 각 slot이 모든 Feature Vector를 보고, '이 Feature는 날 설명하는 feature야' 라고 Weight를 부여함.
        - Attention Weight는 Softmax를 통해 각 Slot별로 나뉘어진다. (합이 1)
        - 즉, feature가 N개 있을 때 각 feature마다 slot에 가중치로 나뉘어지는거임.
    - 4. Feature Aggregation
        - Attention Weight를 이용해 Slot들은 자신이 바라본 Feature의 Weighted Sum을 가져옴.
        - 즉, 하나의 Input 샘플에서 Feature들이 N개가 생성되고, 각 Feature 조각마다 Slot이 Weight를 부여하고, 이 Feature 조각들 x weight를 해서 각 Slot이 이 Feature 정보를 요약한다. (∑(Feature_i * weight_i))
        - 이 Feature에서 각 Slot(Concept)이 자신에 맞는 정보만을 잘 나누어 가지고 요약한 것이 됨.
    - 5. Slot Update (반복)
        - 각 Slot은 GRU를 통해 자신의 상태를 업데이트함 → 점점 특정 Concept에 맞춰지게 됨.
        - 당연히 GRU의 입력은 위에서 요약한 Weighted sum of Feature임.
        - 이 과정을 여러 번 반복하면 slot이 안정적인 concept embedding으로 수렴하게 된다.
        - (여기서 궁금한점) : 학습은 Batch 단위로 이루어질텐데, batch 내의 여러 샘플이 하나의 공유된 Memory인 Slot을 업데이트하는게 말이 됨?
            - 그래서 이전 상태의 Slot Embedding을 복사해서 각 Sample마다 이번 Batch에서의 Slot 업데이트를 따로 하고, 이를 평균내서 Gradient로 업데이트함.
    - 6. 그래서 이 CSA는 모델인가?
        - CSA는 입력 Feature Vector를 가지고, 최적의 Slot을 만들어내는 모델이다.
        - CSA가 하는 일은 Slot Attention을 반복적으로 수행하는 것임.
        - Slot Attention은 아레의 절차로 진행되고, 여러 번 반복되어 Task Specific한 Slot(Concept)을 만드는 것이 목표이다.
            - 0. 입력 Sample을 Backbone(CNN / ViT)에 넣어 N개의 Feature Vector를 추출함.
            - 1. 입력 Feature에 대해 Slot과의 Attention Weight 계산. (Query : Slot, Key/Value : Feature Vectors)
            - 2. Slot 별 Feature 요약. (입력 Feature Vector들의 가중합)
            - 3. GRU에 Weighted sum of Feature Vector를 각 Slot마다 입력으로 넣어 Slot을 업데이트함. (Slot_t = GRU(input=u_t, hidden=Slot_(t-1)))
            - 4. GRU는 Batch 내의 각 Sample마다 독립적으로 복사된 이전 Slot을 초기 상태로 갖고, Slot을 업데이트한 뒤, Batch 내의 샘플별로 Slot의 업데이트량을 평균내어 최종 업데이트가 된다. (Batch마다 업데이트됨.)
            - 반복. (Batch마다 GRU를 반복하는 횟수는 T로 하이퍼파라미터임.)
        - 즉, CSA 모듈의 최종 Output은 Task-Specific한 Slot이 된다.


### Proposed Method (Preliminary)
- 그럼 이제 중요한게 Shared Global Workspace가 뭐고, 어떻게 작동하며, 어떤 이점이 있다는건가?
- SGW는 인간의 Global Workspace Theory에서 영감을 얻은 개념으로, 모듈들 간의 정보 공유와 협업을 위한 공유 메모리 공간을 의미함.
    - 이 CCT에서는, CSA를 이용하여 Slot을 업데이트하는데, 이 Slot이 공유 메모리 공간이다.
    - CSA가 Slot에 Concept Embedding을 Task-Specific하게 업데이트하고, CA가 이 Slot을 이용하여 Input Feature가 어떤 Concept과 관련있는지 Cross-Attention을 통해 가중치를 얻고, Input Feature들을 Concept들의 가중치로 나타낸 뒤, 그 정보를 종합해서 어떤 Task를 수행함.
    - 즉, CSA가 이 공유 메모리를 업데이트하는 역할을 하고, CA가 이를 사용하여 다음 할 일을 수행하는 방식으로 작동한다.

- 기존 Slot Attention의 한계점
    - Slot Random Initialization Problem : 슬롯이 랜덤 초기화되기 때문에 동일한 객체를 안정적으로 추적하기가 쉽지 않다. (처음엔 부리를 추적하다가, 갑자기 다리를 추적한다던가)
        - SGW에서는 이 Slot 자체가 '공유 자원' 이며, 경쟁(Attention)을 통해 의미 있는 정보만 Write되고, 이후 모든 모듈이 같은 Slot을 바라보며 학습하게 되므로 Slot이 일관적으로 동일한 개념(Concept)을 학습하게 유도된다.
        - 즉, Slot이 각기 다른 Concept을 학습하는 것이 보장되므로 중간에 변하거나 하지 않는다.
    - Hyperparameter Sensitivity Problem : Slot Attention이 하이퍼파라미터에 매우 민감하고, 도메인에 따라 성능 차이가 심하다.
        - Slot Attention을 한정된 파라미터 튜닝 없이, 공유 메모리 기반으로 안정적으로 동작하게 하고, 

### Proposed Method (CCT)
- 최종 CCT의 동작 과정.
    1. 입력 데이터의 처리 (Backbone)
        * 입력 이미지들이 CNN 또는 Vision Transformer(ViT)와 같은 Backbone 모델을 통과하면서 각 이미지마다 다수(L개)의 Feature Vector를 생성한다.
        * 각 이미지에서 생성된 Feature Vector는 개별적인 이미지 특징을 담고 있으며, 그 형태는 \[L, D]이다 (L: Feature의 수, D: 각 Feature의 차원).

    2. Concept-Slot-Attention (CSA) 모듈: Task-specific Concept Embedding 생성
        * CSA 모듈은 모델이 학습 가능한 초기값(Learnable Parameter)을 가진 K개의 Slot(Concept 공간)을 가지고 시작한다.
        * 각 이미지는 L개의 Feature Vector로 나뉘어져 CSA에 입력된다.
        * 이후, 각 Slot과 입력 Feature 간에 경쟁적 Attention을 수행하여 Slot 별 Attention Weight를 얻는다. 이 과정에서 Slot이 Query가 되고, Feature는 Key/Value로 활용된다.
        * Slot 별 Attention Weight를 이용해 Feature를 가중합(weighted sum)하여 각 Slot의 임시 상태를 업데이트할 벡터를 생성한다.
        * 이렇게 얻어진 벡터를 입력, 이전 Slot Vector를 초기 Hidden State로 하여 각 Slot은 GRU 모듈을 통해 상태를 업데이트한다. 이 과정을 T번 반복하여 각 Slot이 점진적으로 특정 Concept을 대표하는 안정적인 벡터로 수렴하게 한다.
        * 최종적으로, CSA 모듈의 출력은 각 이미지별로 \[K, D] 형태의 Concept Slot이다. (K: Slot의 수, D: 각 Slot의 차원)

    3. Cross-Attention (CA) 모듈: Feature를 Concept 단위로 해석
        * CA 모듈에서는 앞서 생성된 Concept Slot들을 사용하여 각 입력 이미지의 Feature들이 어떤 Concept을 얼마나 가지고 있는지 Cross-Attention을 통해 평가한다.
        * 이때 입력 Feature Vector들이 Query가 되고, 앞서 CSA에서 나온 Concept Slot들이 Key와 Value가 된다.
        * Cross-Attention 결과로 얻은 Attention Weight를 사용하여 각 Feature를 Concept 기반의 벡터로 재구성한다. 이 과정의 수식적 표현은 다음과 같다:
        * 각 Feature l에 대해:
            $z_l = A^{CA}_l \cdot v^{CA}(\hat{S}^{concept}) \quad \in \mathbb{R}^{d}$

    4. 클래스 예측 (Classification)
        * 이렇게 생성된 각 Feature의 Concept 기반 벡터(z\_l)를 최종적으로 클래스 분류를 위한 Linear Matrix O와 곱하여 각 클래스에 대한 점수(logits)를 얻는다.

        * 각 Feature l의 클래스 i에 대한 logits는 다음과 같다:
            $logits_{l,i} = z_l \cdot O_{:,i}$
        * 이미지 전체의 최종 logits은 모든 Feature에 대한 logits 값을 평균하여 계산한다:
        $logits_i = \frac{1}{L} \sum_{l=1}^{L} logits_{l,i}$

    5. 최종 분류 및 학습
        * 최종적으로 얻은 logits 값을 Softmax 함수를 통해 클래스 확률값으로 변환하여 예측을 수행한다.
        * 전체 모델 학습은 Classification Loss와 함께 Explanation Loss와 Sparsity Loss를 이용하여, 해석 가능성을 높이고 중요한 Concept에 집중하도록 유도한다.
        * 각 Batch마다 이러한 과정이 반복되며, Slot은 Learnable Parameter로서 역전파를 통해 지속적으로 학습되고 업데이트된다.

    정리하면, CCT는 입력 이미지를 명확히 정의된 Concept 단위로 분해하고, 각 Concept을 효과적으로 조합하여 최종 클래스를 예측하는 구조를 가진 모델이다. 이는 높은 성능과 함께 인간이 이해할 수 있는 설명 가능성을 제공하는 것을 목표로 한다.

<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.7.10/CCT_Architecture.png" alt="CCT 아키텍처 분석" width="700">

### Proposed Method(Loss 함수)
- 모델의 설명 가능성을 더욱 강화하기위 한 특별한 Loss 함수 2개를 사용했다고 한다.
- Plausibility by Construction with Explanation Loss
    - 사람이 이해할 수 있는 설명 제공을 위한 Loss Function이다.
    - 각 이미지의 l번째 Feature가 c번째 Concept에 관련이 있다는 인간의 사전 지식에 기반한 binary 혹은 soft mask이다.
    - 그래서, 실제 l번째 Feature Vector와 Slot들 간의 Attention Weight와 Ground Truth인 H를 비교하여 Loss항을 구성함.
    - $L_expl = |A - H|^2$으로 나타난다. Attention Weights A가 실제 Ground Truth H와 똑같을수록 loss가 작아짐.
    - 데이터에 H(Ground Truth)가 없는 경우 Explanation Loss의 가중치 = 0으로 둠.
    - Cifar100-Super class, CUB-200-2011 데이터셋에는 이 Ground Truth H가 있고, Image Net에서는 없다고 함.
    - 아레 그림은 Cifar-100에서 실제로 CT, CCT 모델을 통해 얻은 Weight Map과 Ground Truth간에 비교를 한 이미지임.

<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.7.10/explanation_map.png" alt="Concept-Explanation" width="700">

- Sparsity Loss based on Entropy
    - 각 Feature Vector가 CA모듈에서 Concept에 대한 표현이 될 때 그 가중치가 하나의 Slot에 집중할 수 있도록 하는 Loss임.
    - $L_sparse = H(A) = - \frac {1} {|A|} \sum_i a_i log(a_i)$
    - $a_i$는 attention map의 각 요소로, 확률 분포로 해석된다.
    - $\sum_i a_i log(a_i)$ 이 값은 a_i가 하나로 뭉치면 0에 가까워지고, 고루 퍼지면 음수로 점점 커진다. ([1, 0, 0, 0] = 0), ([0.25, 0.25, 0.25, 0.25] = -1.386), ([0.5, 0.5, 0, 0] = -0.693)
    - 그래서 앞에 -를 붙여줘서, 고루 퍼질수록 값이 커지기 때문에, 이 값을 작아지게 하기 위한 loss로 사용하는거임.

## Cross-Modal Temporal Pattern Discovery for Enhanced MultiModal Electronic Health Records Analysis (CTPD)
### Abstract 및 Introduction
- EHR(Electronic Health Records)는 수치형 시계열 데이터(심박수, 혈압 등)와 자유 형식의 텍스트 데이터(진료 기록 등)를 포함하는 MultiModal 데이터이다.
- 지금까지의 대부분의 연구의 한계
    - 개별 환자마다의 시간적 상호작용(intra-patient temporal patterns)에만 초점을 맞췄다.
    - 다중 Modality 데이터를 융합할 때 환자 간의 시간 패턴(inter-patient temporal patterns)는 무시했다.
        - 이게 무슨 소리냐면, 지금까지는 그냥 Modality A concat Modality B → FC Layer → Predict 이렇게 했었다.
    - Intra-Patient Temporal Pattern : 하나의 개별 환자 안에서 발생하는 시간의 흐름에 따른 데이터 변화 (예: 어떤 환자의 혈압이 12시간동안 점점 올라감 → 의식 수준이 떨어짐 )
    - Inter-Patient Temporal Pattern : 여러 환자들 사이에서 공통적으로 나타나는 시간적 패턴 (예: 중환자실 환자들 중 대부분이 입원 후 24시간 내 심박수 급상승 → 혈압 하락 → 사망 한다는 공통적인 패턴이 존재함.)
    - 즉, 지금까지의 연구는 개별 환자 내에서의 시간적 패턴만을 학습해왔기에, 환자별로 Bias가 높아서 일반화가 어려웠을 뿐 아니라, 환자마다의 개인차(평균 심박수의 차이 및 혈압의 차이)를 반영하기 어려웠다.
- 이 논문에서는 다음과 같이 해결하고자 한다.
    - 시간 정보가 존재하는 모든 Modality(TS, Text)로부터 Cross-Modal Temporal Pattern을 찾아내고, 다수의 환자들 사이에서 공통적으로 등장하는 의미 있는 시간 패턴(inter-patient)를 정렬하여 학습하고자 함.
    - Shared Temporal Representation : Time Series와 Clinical Note 모두에서 공통적인 시간 패턴 표현을 추출함.
        - 두 데이터는 Shape이 다르지만(numerical vs text) 모두 "시간 흐름에 따른 상태 변화" 라는 정보를 담고 있다.
        - 각 Modal별로 Encoder를 사용하여 공통적인 시간 패턴을 나타낼 수 있는 Shared Representation을 생성한다. (TS → Transformer계열 Encoder, Text → Bert)
    - Cross-Modal Alignment : 시계열 데이터의 시간 패턴과 Text의 시간 표현을 연결한다.
        - Time Series에서 [110 → 125 → 150] 이라는 혈압 수치 상승 패턴이 있고, Text에서 "혈압이 점차 상승하였고, 두통이 동반됨" 이라고 기술되어있다면, 사실상 같은 사건이지만, 형태가 달라서 학습이 어렵다.
        - 이 두 Temporal Pattern을 Align해주기 위해서, TP-NCE Loss를 이용하여 각각의 Modal로부터 얻어진 Temporal Pattern Representation이 유사해지도록 학습한다.
    - Slot Attention + TP-NCE Loss
        - Shared Prototype은 여러 개의 Slot으로 이루어졌다고 생각하면 됨.
        - 각 Slot들을 Query, 각 Modality에서 온 Embedding Vector(여러 Sequence 벡터들)를 Key/Value로 하여 Attention 수행.
        - 그러면 각 Slot들이 여러 Embedding Vector들에 대한 가중치들을 가지게 됨.
        - 그 다음, Attention Weight x Value를 하여, 각 Slot이 Embedding Vector들의 표현으로 나타나게 될 것임.
        - 이 때, Text Embedding Vector를 Key/Value로 하여 변환된 Prototype과, Time Series Embedding Vector를 Key/Value로 하여 변환된 Prototype이 비슷하다면(GRU 포함), Shared Prototype이 잘 학습된 것임. (서로 다른 Modal이지만, 같은 의미를 갖는 데이터에 대해 같은 표현을 완성했기 때문.)
        - 이 둘을 비슷하게 하는게 TP-NCE Loss인거고 (뒤에서 다시 보자.)
        - 이 다음 과정은 Proposed Method에서 보자.




## 학습 결과 정리
- GENE Activ 14cls 결과
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.7.10/GENE_Results.png" alt="Gene-Results">

- PAMAP2 결과
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.7.10/PAMAP2_results.png" alt="PAMAP-Results">


## 해야 할 남은것들
<li> 교수님이 보라고 하신 논문 읽어보기 (CCT 및 그거관련 아레 얘들 다 관련 있다고 함.) </li>
<li> https://arxiv.org/pdf/2502.11418 - TimeCAP (아직) </li>
<li> Improved Knowledge Distillation Based on Global Latent Workspace with MultiModal Knowledge Fusion for Understanding Topological Guidance on Wearable Sensor Data </li>
<li> CTPD (Cross-Modal Temporal Pattern Discovery) </li>
<li> 논문 어떻게 작성할지에 대한 초안 작성 </li>
<li> 영어공부(심심할 때 틈틈히) </li>

---

### Teacher 특이조합에 대해서 실험 진행 (GENE_Activ, PAMAP 둘다 적용) ! 코드작업 선행 필요. (아마 오래 걸릴 것.)
- 특이조합에 대해서는 Wide Resnet 기준 2Teacher(GAF+Sig, PI+Sig) 특이조합과 3Teacher(GAF+PI+Sig) 특이조합에 대해서 실험해야함. (Student는 wrn161 고정.)
- 각 조합에 대해서 Base와 annsp로 실험. (alpha나 lambda는 이미 찾은 값으로.)
- 2Teacher (Image + Signal)
    * Depth-wise - (wrn281 + wrn161), (wrn161 + wrn281)
    * Width-wise - (wrn163 + wrn161), (wrn161 + wrn163)
    * D+W-wise - (wrn281 + wrn163), (wrn163 + wrn281)
- 3Teacher (GAF + PI + Sig)
    * Depth-wise - (wrn281 + wrn161 + wrn161), (wrn161 + wrn281 + wrn161), (wrn161 + wrn161 + wrn281)
    * Width-wise - (wrn163 + wrn161 + wrn161), (wrn161 + wrn163 + wrn161), (wrn161 + wrn161 + wrn163)
    * D+W-wise - (wrn281 + wrn163 + wrn161), (wrn163 + wrn281 + wrn161)

### Teacher - Student 특이조합(모델 구조 완전변형)
- 완전특이조합 Mobile net이나, Resnet, VGG를 이용한 특이조합에 대한 추가 실험
- 여기는 Teacher끼리는 같은 모델을 사용한다.
- 아레의 조합에 대해서 찾아야 할 값 
    - Student의 성능.
    - Sig → Sig의 성능 (1Teacher)
    - Pi+Sig → Sig의 성능 (2Teacher, base, ann)
    - GAF+Sig → Sig의 성능 (2Teacher, base, ann)
    - GAF+Pi+Sig → Sig의 성능 (3Teacher, base, ann, annsp)
```
    - T : wrn-163 → S : RN8
    - T : wrn-281 → S : RN20, vgg8
    - T : RN44 → S : vgg8, wrn-161
    - T : MN.V2 → S : RN8
```