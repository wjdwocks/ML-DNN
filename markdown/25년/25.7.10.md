## 이번주 한 것.



## 돌려야 할 것들
<li> PAMAP2 baseline으로 사용할 Role of Projection, MTKD_RL (gpu 남으면 돌리면 될듯) </li>
<li> PAMAP2 내꺼 3 Teacher annsp, ann 좀 더 돌려서 더 좋은 결과로 </li>
<li> GENE MobileNet GAF Teacher 학습 해놓고, 완전다른 Ablation 학습 코드 짜놓기 </li>

## 돌아가고 있는 것들
    - 0 : GENE 2Teacher Ablation (annsp), 
    - 1 : PAMAP2 3Teacher Ablation (base)
    - 2 : PAMAP2 3Teacher Ablation (base)
    - 3 : PAMAP2 3Teacher Ablation (ann)


## CCT 및 Latent Workspace with Multimodal Knowledge Distillation 이 논문 읽어보고 공부.
## Concept-Centric Transformers (CCT)
### Interpretable AI 
- 설명 가능한 인공지능 : AI가 내리는 결정 과정을 사람이 이해할 수 있도록 설명할 수 있는 AI를 의미함.
    - 기존 딥러닝 모델은 Black-Box 라고 불림(왜 그런 결론을 내렸는지 설명할 수 없다.)
    - 기존 딥러닝 모델은 Pixel, Feature Map, Vector 수준에서 작동하기 때문에 사람이 직관적으로 이해하기 어려움.
    - Interpretable AI의 주요 접근법
        - Post-Hoc Explanation (사후적 설명)
            - 이미 학습된 블랙박스 모델을 해석하는 방석
            - LIME : 입력 데이터를 랜덤하게 조금씩 변경하면서 어떤 Feature가 결과에 얼마나 영향을 주는지 설명
            - SHAP : 게임이론 기반으로, 각 Feature가 결과에 미친 기여도를 계산함.
            - Grad-CAM : CNN기반 모델에서 어느 영역을 보고 판단했는지 시각화하는거 (논문에서 본 적 있는것 같다.)
        - Intrinsic Interpretability (내재적 설명 가능성)
            - 모델을 설계할 때부터 해석 가능하도록 구조를 설계하는것.
            - Decision Tree : 각 Feature에 대해 결정 경로가 명확하게 보인다.
            - Linear Model : 각 Feature의 가중치를 그대로 해석이 가능함.
            - Concept-based Model : 사람이 이해할 수 있는 개념 단위로 의사결정을 수행한다.
- Concept : 사람이 직관적으로 이해할 수 있는 의미 단위를 의미함.
- Concept based Model : 모델이 사람이 이해할 수 있는 개념 단위로 정보를 처리하거나, 설명을 유도하는 것을 의미함.
    - 기존 모델에서는 [1. 이미지 입력 → 2. Conv / Transformer를 통한 입력의 벡터연산 → 3. 결과 예측] 이런 순서대로 학습을 진행함.
    - Concept based Method는 [1. 이미지 입력 → 2. concept 단위 정보 처리 (부리:있음, 날개:큼, 다리:길다) → 3. 결과:독수리] 이런식으로 예측의 이유가 설명이 됨.

### Introduction
- Interpretable Model은 각 부분이 명확한 의미를 가진 모듈들로 구성된 설명을 생성해야 한다. 
    - Concept-Centroc Transformer라는 구조를 제안한다. 
    - CCT는 Shard Global Workspace(SGW)이론에서 영감을 받았으며, 여러 개의 특화된 모듈들이 공유 메모리에 경쟁적으로 접근하도록 설계되어 모듈화를 자연스럽게 유도함.
    - 이 CCT 라는 구조를 통해 모델은 단순하고, 모듈화된 구조로 사람이 이해 가능한 개념을 추출할 수 있게 된다.
- CCT는 세 가지 주요 구성 요소로 설계된다.
    - 1. Concept-Slot-Attention(CSA) 모듈
        - Backbone에서 나온 이미지 embedding을 입력으로 받음. (여기서 백본은 ViT, CNN 같은 모델을 쓴다고 했으니, Patch Embedding → Transformer Encoder → Latent Feature 이므로, 이 정제된 Latent Vector를 입력해준다는 거임.)
        - Input Feature와 Slot 간의 Slot Attention을 수행하여 task-specific한 Slot이 되도록 GRU를 통해 업데이트됨. (사람이 해석 가능한 개념에 대응하는 벡터)
        - 여기서 Slot은 interpretable한 Concept을 의미하고, 이 Slot을 더 Task-Specific하게 업데이트하기 위해서 Slot Attention을 수행한다. (Slot Attention은 Related Work에서 설명)
    - 2. Cross-Attention(CA) 모듈
        - CSA 모듈이 Task-Specific한 Slots(Concept Embedding)과 Input Feature(백본의 Latent Feature(Feature Map)) 간의 Cross-Attention을 수행한다.
        - Query : Input Feature (백본의 Feature)
        - Key/Value : Concept Embedding (CSA모듈로 얻은 Concept Embedding)
        - Cross-Attention 결과 : 각 백본의 Feature가 어떤 Concept과 관련이 있는지 가중합된 Vector가 생성됨. (어떤 Concept에 주로 의존했는가)
        - 이 가중합된 Vector가 최종 Classification Head로 들어가서 클래스 예측을 수행한다.
        - 즉, 이제 Task-Specific한 Slot(Concept Embedding)과 Input Feature를 다시 Cross-Attention하여, 각 입력 Feature가 어떤 Concept에 관련이 있는지 각 Slot마다의 가중치를 알게 되고, 모든 Feature에 대해 Slot value x Weight 를 수행한다.
        - 그 다음으로, 그 Feature들에 대한 Feature Set의 정보를 모아서 Classfication을 수행한다.
    - 3. Loss 설계
        - Explanation Loss(설명 손실) : 도메인 지식을 활용하여 올바른 개념에 집중하도록 유도함.
            - 목적: 모델이 도메인 전문가(Ground Truth)가 중요하다고 생각하는 개념에 집중하도록 유도.
            - 데이터셋에 '이 이미지에서 중요한 개념은 무엇이다' 라는 Ground Truth Concept Annotation이 존재함.
            - 모델이 예측한 Attention 가중치가 Ground Truth Concept Annotation과 얼마나 일치하는지 비교함.
            - Cross-Entropy 또는 Distance Loss로 이 차이를 줄이도록 학습함.
        - Sparsity Loss(희소성 손실) : Attention이 정말 중요한 Feature에 집중하도록, 희소하게 분포하도록 강제함.
            - 목적 : 모델이 모든 Concept에 골고루 Attention 하지 말고, 정말 중요한 Concept에만 집중하도록 강제하는 loss
            - Cross-Attention 가중치의 Entropy를 최소화하도록 학습함
            - Entropy가 작다 → 특정 Concept에 집중 → Sparse한 분포

### Related Work
- SGW(Shared Global Workspace)
    - 여러 모듈이 '공유 메모리'를 통해 정보를 주고받으며, 중요한 정보만 Bottleneck을 통해 공유한다.
    - 기존의 Concept Transformer 논문에서는 개별 image patch만을 기반으로 Concept을 추출하기 때문에, Global Concept을 잘못 학습할 수 있었다.
    - 이 논문에서는 SGW를 통해 서로 다른 모듈간 정보 공유와 Concept 일반화를 동시에 달성하고자 함.

- Slot Attention
    - Slot은 한정된 개수의 Concept을 저장하는 공간이다.
    - CSA에서 Slot Attention을 수행하여 Slot이 더 좋은 Concept Vector표현이 되도록 업데이트됨.
    - 1. 입력
        - Backbone의 Latent Feature가 입력으로 들어옴.
    - 2. Slot의 상태
        - Slot은 고정된 개수로 존재한다.
        - k개의 slot이 있다면, 모델이 학습할 Concept의 수가 k개이고, 사람이 해석할 수 있는 개념 단위가 k개 있다는거임.
    - 3. 경쟁적 Attention 수행
        - Query : 각 Slot들
        - Key/Value : 입력 Feature Vector들
        - 각 slot이 모든 Feature Vector를 보고, '이 Feature는 날 설명하는 feature야' 라고 Weight를 부여함.
        - Attention Weight는 Softmax를 통해 각 Slot별로 나뉘어진다. (합이 1)
        - 즉, feature가 n개 있을 때 각 feature마다 slot에 가중치로 나뉘어지는거임.
    - 4. Feature Aggregation
        - Attention Weight를 이용해 Slot들은 자신이 바라본 Feature의 Weighted Sum을 가져옴.
        - 즉, 한 번의 Input에서 Feature들이 n개로 나뉘어지고, 각 Feature 조각마다 Slot은 Weight를 가지고 있는데, 이 Feature 조각 x weight를 해서 각 Slot이 이 Feature 정보를 요약한다.
        - 이 Feature에서 각 Slot(Concept)이 자신에 맞는 정보만을 잘 나누어 가지고 요약한 것이 됨.
    - 5. Slot Update (반복)
        - 각 Slot은 GRU를 통해 자신의 상태를 업데이트함 → 점점 특정 Concept에 맞춰지게 됨.
        - 이 과정을 여러 번 반복하면 slot이 안정적인 concept embedding으로 수렴하게 된다.
    - 6. 그래서 이 CSA는 모델인가?
        - CSA는 입력 Feature Vector를 가지고, 최적의 Slot을 만들어내는 모델이다.
        - CSA가 하는 일은 Slot Attention을 반복적으로 수행하는 것임.
        - Slot Attention은 아레의 절차로 진행되고, 여러 번 반복되어 Task Specific한 Slot(Concept)을 만드는 것이 목표이다.
            - 1. 입력 Feature에 대해 Attention Weight 계산.
            - 2. Slot 별 Feature 요약. (입력 Feature Vector들의 가중합)
            - 3. GRU로 Slot 상태 업데이트.
            - 반복.
        - 즉, CSA 모듈의 최종 Output은 Task-Specific한 Slot이 된다.


### Proposed Method (Preliminary)
- 그럼 이제 중요한게 Shared Global Workspace가 뭐고, 어떻게 작동하며, 어떤 이점이 있다는건가?
- SGW는 인간의 Global Workspace Theory에서 영감을 얻은 개념으로, 모듈들 간의 정보 공유와 협업을 위한 공유 메모리 공간을 의미함.
    - 이 CCT에서는, CSA를 이용하여 Slot을 업데이트하는데, 이 Slot이 공유 메모리 공간이다.
    - CSA가 Slot에 Concept Embedding을 Task-Specific하게 업데이트하고, CA가 이 Slot을 이용하여 Input Feature가 어떤 Concept과 관련있는지 Cross-Attention을 통해 가중치를 얻고, Input Feature들을 Concept들의 가중치로 나타낸 뒤, 그 정보를 종합해서 어떤 Task를 수행함.
    - 즉, CSA가 이 공유 메모리를 업데이트하는 역할을 하고, CA가 이를 사용하여 다음 할 일을 수행하는 방식으로 작동한다.

- 기존 Slot Attention의 한계점
    - Slot Random Initialization Problem : 슬롯이 랜덤 초기화되기 때문에 동일한 객체를 안정적으로 추적하기가 쉽지 않다. (처음엔 부리를 추적하다가, 갑자기 다리를 추적한다던가)
        - SGW에서는 이 Slot 자체가 '공유 자원' 이며, 경쟁(Attention)을 통해 의미 있는 정보만 Write되고, 이후 모든 모듈이 같은 Slot을 바라보며 학습하게 되므로 Slot이 일관적으로 동일한 개념(Concept)을 학습하게 유도된다.
        - 즉, Slot이 각기 다른 Concept을 학습하는 것이 보장되므로 중간에 변하거나 하지 않는다.
    - Hyperparameter Sensitivity Problem : Slot Attention이 하이퍼파라미터에 매우 민감하고, 도메인에 따라 성능 차이가 심하다.

- 도메인 일반화를 어떻게 해결할거나
    - 모듈 간 협업과 메모리 지속성을 통해 다양한 도메인에서 안정적인 성능을 유지하도록 한다.





## 해야 할 남은것들
<li> 교수님이 보라고 하신 논문 읽어보기 (CCT 및 그거관련 아레 얘들 다 관련 있다고 함.) </li>
<li> https://arxiv.org/abs/2305.15775 - Concept-Centric Transformer (아직) </li>
<li> https://arxiv.org/pdf/2502.11418 - TimeCAP (아직) </li>
<li> Improved Knowledge Distillation Based on Global Latent Workspace with MultiModal Knowledge Fusion for Understanding Topological Guidance on Wearable Sensor Data </li>
<li> CTPD (Cross-Modal Temporal Pattern Discovery) </li>
<li> 논문 어떻게 작성할지에 대한 초안 작성 </li>
<li> 영어공부(심심할 때 틈틈히) </li>

---

### Teacher 특이조합에 대해서 실험 진행 (GENE_Activ, PAMAP 둘다 적용) ! 코드작업 선행 필요. (아마 오래 걸릴 것.)
- 특이조합에 대해서는 Wide Resnet 기준 2Teacher(GAF+Sig, PI+Sig) 특이조합과 3Teacher(GAF+PI+Sig) 특이조합에 대해서 실험해야함. (Student는 wrn161 고정.)
- 각 조합에 대해서 Base와 annsp로 실험. (alpha나 lambda는 이미 찾은 값으로.)
- 2Teacher (Image + Signal)
    * Depth-wise - (wrn281 + wrn161), (wrn161 + wrn281)
    * Width-wise - (wrn163 + wrn161), (wrn161 + wrn163)
    * D+W-wise - (wrn281 + wrn163), (wrn163 + wrn281)
- 3Teacher (GAF + PI + Sig)
    * Depth-wise - (wrn281 + wrn161 + wrn161), (wrn161 + wrn281 + wrn161), (wrn161 + wrn161 + wrn281)
    * Width-wise - (wrn163 + wrn161 + wrn161), (wrn161 + wrn163 + wrn161), (wrn161 + wrn161 + wrn163)
    * D+W-wise - (wrn281 + wrn163 + wrn161), (wrn163 + wrn281 + wrn161)

### Teacher - Student 특이조합(모델 구조 완전변형)
- 완전특이조합 Mobile net이나, Resnet, VGG를 이용한 특이조합에 대한 추가 실험
- 여기는 Teacher끼리는 같은 모델을 사용한다.
- 아레의 조합에 대해서 찾아야 할 값 
    - Student의 성능.
    - Sig → Sig의 성능 (1Teacher)
    - Pi+Sig → Sig의 성능 (2Teacher, base, ann)
    - GAF+Sig → Sig의 성능 (2Teacher, base, ann)
    - GAF+Pi+Sig → Sig의 성능 (3Teacher, base, ann, annsp)
```
    - T : wrn-163 → S : RN8
    - T : wrn-281 → S : RN20, vgg8
    - T : RN44 → S : vgg8, wrn-161
    - T : MN.V2 → S : RN8
```