## 25.1.9 까지 공부할 내용
<li> GAF 코드로 단일 네트워크 학습 돌려보기. (완전한 이해 + 코드 분석) </li>
<li> TPKD (Topological Persistence Guided Knowledge Distillation for Wearable Sensor Data) 논문 다시 읽고 이해. </li>
<li> HAR(인간 행동 분석)에 Deep Learning이 사용된 논문 읽어보기 - Sensor Data를 이용한. </li>
<ol>
<li> Deep Learning for Sensor-based Activity Recognition: A Survey - (큰 도움 안됨.) </li>
<li> Human Activity Recognition Based on Gramian Angular Field and Deep Convolutional Neural Network </li>
<li> Freezing of Gait Detection Using Gramian Angular Fields and Federated Learning from Wearable Sensors </li>
</ol>
<li> 위의 논문들에서 GAF를 이용할 때 GASF를 사용했는지, GADF를 사용했는지 보고, 그 이유와 당위성 체크. </li>

### GAF 코드로 단일 네트워크 학습.
<li> Parser 부분에 gene_gaf로 놓고 학습을 돌리면 train_custum_gaf의 Main에서 GAF로 변환된 데이터 로더를 불러오도록 바꿈. </li>
<li> get_gene_gaf함수를 통해 gene데이터셋을 각 x, y, z축에 대한 GASF이미지를 각각 변환하여, Depth 방향으로 합쳐서 3channel image형태로 변환. </li>
<li> 3channel image의 형태를 띈 데이터가 되므로, 학습 모델은 Cifar-10/PI-img 와 같은 WRN16-1(2d CNN을 이용하는), WRN16-3, WRN28-1, WRN28-3으로 사용함. </li>
<li> 그리고 Validation Accuracy가 가장 높았을 때의 모델 가중치를 pth.tar파일로 저장함. </li>
<li> 이렇게 저장한 가중치로 Teacher를 두고, 다음에 KD를 설계하여 학습할 것이다. </li>
<li> 개선/수정 해야할 것. </li>
<ul>
<li> 왜 GAF이미지의 크기를 64 x 64로 하였는가? : 선행 연구의 PI-IMG가 64 x 64였기 때문. (그렇다면 이 논문에서는 왜 PI-img를 64 x 64로 했나?) - TPKD논문 참조해보자. </li>
<li> 왜 geneActiv 데이터를 각 Accelerometer 축에 대해서 flatten()으로 하지 않고, 각 축마다 GAF를 따로 변환하여 channel로 합쳤는가? - flatten한게 channel이 적어서 더 가벼울텐데 </li>
<li> 왜 Gramian Angular Summation Field를 채택했는가? : Gramian Angular Difference Field와의 차이점과 다른 논문을 참조해보자. </li>
</ul>

### GAF를 이용한 학습 성능 분석.
<ol>

<li> 전체 공통 참고 사항 </li>
<ul>
<li> GAF이미지는 64 x 64로 설정하였다. </li>
<li> gene_dataset은 3channel Accelerometer로 되어있기에 각 축을 따로 나누어서 GASF로 변환한 후, 다시 Channel로 합쳤다. </li>
<li> 각 학습 결과와 parameter는 TeaGAF폴더에 같은 format으로 저장해두었다. </li>
</ul>

<li> WRN16-1의 결과 </li>
<ul>
<li>  </li>
</ul>

<li> WRN16-3의 결과 </li>
<ul>
<li>  </li>
</ul>

<li> WRN28-1의 결과 </li>
<ul>
<li>  </li>
</ul>

<li> WRN28-3의 결과 </li>
<ul>
<li>  </li>
</ul>

<ol>

### 각 채널별로 GASF를 계산한 것과 Flatten으로 이어붙인 후 GASF를 얻은 것의 시각적 비교.
<li> 각 채널별로 GASF를 계산한 결과 </li>

![GAF_img_3ch](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.1.9/GAF_img_3ch.png)
<li> Flatten으로 각 채널을 펼쳐서 합친 후 GASF변환 결과. </li>

![GAF_img_3ch](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.1.9/GAF_img_3ch.png)

## Trainning Environment
<li> Dataset = Cifar10, GENE </li>
<li> python = 3.8.18 </li>
<li> pytorch = 2.3.0 + (cu12.1), CUDA 11.8 </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 100 or 200 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.05 - 0.0001 </li>
<li> optimizer = Adam </li>