### 이번주 하려고 하는 것.
<li> SPKD 논문 + 교수님 코드를 보며 중간 Layer의 Feature Map간의 비교를 통해 학습하는 코드 작성 후 실험 (GENE 7cls, 14cls) </li>
<li> GENE Activ 7cls(500w, 1000w), 14cls에 대해서 Annealing을 적용한 2 Teacher(GAF, Sig)학습. </li>
<li> PAMAP 데이터셋에 대해 Teacher로 사용할 네트워크 학습. (0 ~ 8 OVR로 9번 x 3 trial로 총 27개의 학습) </li>
<li> Object Detection에 대해서 공부해보려고 한다. (Yolo, 어떤 식의 데이터로 어떤 식의 학습이 이루어지는가.) </li>
<li> VAE, WAE에 대해 MNIST로 공부... (어렵구만.) </li>


### SPKD 논문 리뷰



### Object Detection 공부.





### SP를 사용한 학습 설명
1. sp_param이 GENE_Activ에는 700, PAMAP2에는 200으로 설정이 되었는데 이것이 무엇일까?
2. sp_param(β)은 앞의 CE_Loss(Student)와 KD_Loss(T1, T2, S)간의 가중치는 λ로 관리하는데, 그 때 SP_Loss를 몇으로 설정해야 학습이 골고루 잘 될까 하는 하이퍼 파라미터이다.
3. α는 두 Teacher 간 logits loss를 합칠 때의 가중치
4. k는 분할 개수(?) : Feature Representation을 나누는 개수. 이게 4였기 때문에, 우리 코드에서 최종 출력(1), At1(2), At2(3), At3(4)으로 총 4개임.

<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.13/TPKD_sp_param.png" alt="sp_param이 뭐냐" width="500">




## PAMAP2 데이터 분석
### 데이터 형태
1. 83319개의 데이터와 각 데이터는 40개의 Feature를 가지고 있다.
2. 83319개의 데이터는 0 ~ 11에 포함하는 라벨을 각각 가지고 있다.
3. 데이터셋에서 9명의 사람으로부터 83319개의 데이터를 얻은 것이다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP.png" alt="PAMAP shape" width="500">

### 학습할 때 데이터의 사용
1. 9명의 사람은 0 ~ 8의 id로 구분되고, 학습을 할 때 그 중 한명을 Test_id로 지정하여 남은 8명은 Train set으로 학습한다.
2. 이렇기 때문에, 같은 사람의 데이터를 학습하고, 테스트하게 되는 불상사는 일어나지 않음.
3. 같은 사람에서 나온 데이터를 학습하고, 테스트때 사용한다면, Acc가 높게 나올 확률이 높다. (GENE_Active때 겪어본 문제.)

### 데이터의 사용
1. .data 파일의 형식으로 저장되어있다. (GENE_Active랑 다르다.)
2. 이렇게 .data 파일로 되어있는 경우 .npy파일과 다르게 pickle.load를 통하여 데이터를 얻어왔다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP_pickle.png" alt="PAMAP Pickle load" width="500">
3. 근데 cls_id = [24, 1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17] 인데, 원래 PAMAP2에는 24번 label이 없다. 24번은 뭘까
4. 0, 9, 10, 11을 묶어서 24로 놓은건가?
5. 근데 데이터를 로드해와서 np.unique(labels)를 찍어보니, 0 ~ 11로 정렬하게 나와있다. (아마 Encoding된 Label인듯.)
6. 뭐 어쨌든 데이터를 로드해왔다고 치고. (이해가 안감.) 데이터를 어떤식으로 불러와서 load하는지 보자.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP2_data_load.png" alt="PAMAP Data Load" width="500">
7. 데이터를 window크기 100씩으로 불러오는데, 시작 지점은 22씩만 늘어난다. (나머지 78개의 sequence는 계속 겹치면서 data를 로드하고 있다.)
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP2_step_size.png" alt="PAMAP Step Size" width="500">
8. 그 다음, 데이터를 만들고 싶은 크기로 x_train, y_train, x_test, y_test를 np.zeros로 만들어주고, 하나씩 넣어준다.
9. 왜하는가? > (idx, window_length, channel)의 형태를 (idx, batch_size, window_length, channel)의 형태로 바꿔주기 위함임.


### 내가 한 GAF데이터 형성 및 학습
1. test_id(0 ~ 8)을 기준으로 각각 총 9개의 Train, Test 데이터셋을 만듦. (좀 비효율적인듯.)
2. 그러고 나서 np.load를 통해 이 데이터만 가져와서 빠른 데이터 load 후 단일(Teacher로 사용할) 네트워크를 학습함.

### 나중에 KD에 사용할 데이터 로더함수
1. Signal과 GAF Image를 모두 받아오도록 작성해야함. (이미 GENE Activ에서 했던거라 금방 할듯.)
2. Teacher 네트워크들 학습하는데 한세월 걸릴것같아서 천천히 하려고 한다.


## Trainning Environment
<ul>
<li> Dataset = GENE(life_log), PAMAP(이것도 HAR 데이터) </li> 
<li> python = 3.8.18 </li>
<li> pytorch = 2.3.0 + (cu12.1), CUDA 11.8 </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 200 </li>
<li> batch size = 128 </li>
<li> learning rate = 0.05 - 0.0001 (Adjust Learning Rate) </li>
<li> optimizer = Momentum + SGD </li>
</ul>