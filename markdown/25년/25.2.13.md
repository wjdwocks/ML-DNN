### 이번주 하려고 하는 것.
<li> SPKD 논문 + 교수님 코드를 보며 중간 Layer의 Feature Map간의 비교를 통해 학습하는 코드 작성 후 실험 (GENE 7cls, 14cls) </li>
<li> GENE Activ 7cls(500w, 1000w), 14cls에 대해서 Annealing을 적용한 2 Teacher(GAF, Sig)학습. </li>
<li> PAMAP 데이터셋에 대해 Teacher로 사용할 네트워크 학습. (0 ~ 8 OVR로 9번 x 3 trial로 총 27개의 학습) </li>
<li> Object Detection에 대해서 공부해보려고 한다. (Yolo, 어떤 식의 데이터로 어떤 식의 학습이 이루어지는가.) </li>
<li> VAE, WAE에 대해 MNIST로 공부... (어렵구만.) </li>


### SPKD 논문 리뷰
1. SPKD는 Teacher와 Student의 특정 Layer를 지난 output 끼리 서로 MSE로 비교하여 비슷해지도록 학습하는 것을 의미함.
2. 그렇다면 특정 Layer를 지난 출력의 크기나, 깊이가 서로 다르다면? <<< 우리 코드에서는 어떻게 했는지도 보자.
3. 원래라면 크기가 다르다면, Interpolation이나, AvgPool, Upsample, ConvTranspose2d를 사용하여 넘겨줘서 크기를 맞춰준다.
4. 깊이가 다르다면, 1x1 Conv를 사용하여 Channel을 동일하게 변환한다.


### Wide Resnet을 구현하는 우리 코드 - WideResNet_sp
1. WideResNet_sp를 만들어서 얘는 spkd를 사용할 때만 사용하도록 했음.
2. conv1을 생성하고, 처음 Stage에 들어가기 전 out_features를 16개로 늘려줌.
3. Residual Stage를 3개로 구성할 것이므로, 각 Residual Stage에 포함될 Residual Block의 개수 N = (d-4)//6 으로 계산한다. (WRN16-3에서 d = 16, k = 3, strides = [1, 1, 2, 2])
4. 여기서 N = (d - 4) // 6 으로 6으로 나누는 이유는, 각 Stage마다, N개의 Block이 나올텐데, 각 Block마다 2개의 Conv layer를 가지기 때문.
5. 첫 번째 Residual Stage를 들어갈 때에는 모든 Block의 stride = 1로 설정됨 (feature map(입력)의 크기를 줄이지 않기 위해서이다.)
6. 즉, 첫 번째 Residual Stage에서의 모든 Block에서는 stride = 1임. 즉, subsample_input = False로 고정되고, skip connection을 할 때 원본 x의 사이즈를 조절해 줄 필요는 없다.
7. 두 번째 Residual Stage에서는 첫 번째 Block의 stride = 2, 나머지 Block의 stride = 1로 하여, 첫 번째 블록에서 입력 크기를 반으로 줄이고, 깊이를 두배 늘리는 작업을 한다.
8. 즉, 두 번째 Residual Stage부터는 Skip Connection을 할 때 원본 x의 입력 크기도 그에 맞춰 조절해 주어야 한다는 것을 의미함. (첫 번째 블록의 conv_inp()가 그것을 의미함.)
9. 그렇다면 layer에서 Depth를 조절할 때 고려해야할 것은 무엇일까.
10. WRN161과 WRN163의 차이는 첫 번째 Residual Stage에서 output_features를 1배로 고정하는가, 3배로 늘리는가의 차이가 있다.
11. 이에 따라서, 첫 번째 Residual Stage의 Residual Block에서도 입력 크기의 변화는 없지만, 입출력 channel의 차이가 생기므로, skip connection을 할 때 원본 입력에 channel을 조절해 주어야 한다.
12. 이 때에도 위의 입력 크기 문제와 같이 IndividualBlock1에 있는 conv_inp에서 channel의 크기를 맞춰주는 역할을 같이 수행하게 된다.


# WideResNet_sp 모델 구현 및 구조 설명

WideResNet_sp는 SPKD(Similarity-Preserving Knowledge Distillation)에 특화된 모델로, Wide ResNet 구조를 기반으로 한다. 이 모델의 주요 구성 요소와 Depth 계산, Residual Stage에서의 Skip Connection 처리 등을 설명한다.

---

## 1. 모델 개요

- **WideResNet_sp**는 SPKD 적용 시 사용하도록 설계됨.
- 모델은 **초기 Convolution Layer**로 시작하여, 이후 **3개의 Residual Stage**로 구성됨.
- 각 Residual Stage에는 여러 개의 Residual Block이 포함되며, 최종적으로 **Global Average Pooling(GAP)**(1, depth 만 남김.)와 **Fully Connected(FC) Layer**를 통해 분류 결과를 도출함.

---

## 2. 초기 Convolution Layer 및 Feature 확장

- **conv1 레이어**를 통해 입력 이미지를 먼저 처리함.
- conv1 이후, 첫 번째 Residual Stage에 들어가기 전에 **출력 채널 수를 16(또는 k에 따른 16×k)으로 확장**하여 후속 Stage들이 일관된 채널 수를 기반으로 동작할 수 있도록 함.

---

## 3. Residual Stage 구성과 Residual Block 반복 횟수

- 전체 Residual Stage는 **3개**로 구성됨.
- 각 Stage에 포함될 **Residual Block의 개수 N은 (d - 4) / 6 으로 계산됨.**
  - 여기서 **d**는 전체 Depth를 의미함.
  - 예를 들어, **WRN16-3**에서는 d = 16, k = 3, 그리고 strides = [1, 1, 2, 2]로 설정됨.
  - 6으로 나누는 이유는 각 Residual Block 내에 **2개의 Convolution 레이어**가 포함되고, 이 블록이 **3개의 Stage**에 걸쳐 반복되기 때문.

---

## 4. Residual Stage의 특징 및 Skip Connection 처리

### 첫 번째 Residual Stage

- **모든 Residual Block의 stride가 1**로 설정되어, 입력 Feature Map의 크기를 유지함.
- 입력과 출력의 크기가 동일하므로 Skip Connection 시 원본 입력 x를 그대로 더할 수 있음.
- 단, 채널 수가 달라질 경우에는 **1×1 Convolution(conv_inp)**을 통해 채널 수를 맞춰 줌. (WRN16-3 처럼 k값이 1이 아닌 경우.)

### 두 번째 및 세 번째 Residual Stage

- **첫 번째 Block에서는 stride가 2**로 설정되어 입력 Feature Map의 크기를 절반으로 줄임.
- 이때 Skip Connection을 위해 원본 입력 x의 크기와 채널 수가 변경된 출력 x1과 일치해야 하므로, **1×1 Convolution(conv_inp)**을 사용하여 x의 크기(및 채널 수)를 변환함.

---

## 5. Depth 계산에 포함되는 구성 요소

- WideResNet의 Depth d는 **학습 가능한 가중치를 가진 Convolution Layer와 Fully Connected Layer만 포함하여 계산됨.**
- **BatchNorm, ReLU, Pooling** 등은 가중치가 없거나 단순한 연산이므로 Depth 계산에서 제외됨.
- Depth 계산 공식:
  
  d = 1 (conv1) + 6N (Residual Blocks 내 2개의 Conv per Block, 3 Stage) + 1 (FC)
  
  - 예를 들어, WRN16-3에서는 1 + 6N + 1 = 16이 되어야 하며, 첫 번째 Residual Stage에서는 입력 크기가 변하지 않으므로 subsample_input = False가 적용됨. ?????????? 
  - 마지막 Layer의 Pooling, BatchNorm 까지 들어가나?

---

## 6. WRN161 vs. WRN163의 차이 및 첫 번째 Stage 처리

- **WRN161과 WRN163**는 **첫 번째 Residual Stage에서 출력 채널 수를 늘릴지(increase_filters 적용 여부)에 따라 구분됨.**
  - WRN161의 경우, 첫 번째 Stage에서는 채널 수를 그대로 유지하여 increase_filters = False가 될 수 있음.
  - 반면, WRN163는 첫 번째 Stage에서도 채널 수를 확장하여 increase_filters = True가 적용됨.
- 이 차이에 따라 Skip Connection 시 사용되는 1×1 Convolution(conv_inp)의 적용 여부와 방식이 달라지며, 이는 최종 모델의 Depth와 Feature Representation에도 영향을 미침.

---

## 7. Skip Connection과 conv_inp(x)의 필요성

- **Skip Connection (x + x1)을 수행하기 위해서는 x와 x1의 크기와 채널 수가 동일해야 함.**
- Residual Block 내에서 **Downsampling(stride=2)나 채널 증가가 발생하면** x와 x1의 shape가 달라지므로,  
  **1×1 Convolution(conv_inp)**을 사용하여 x를 변환해 두 텐서의 shape를 맞춤.
- 이 과정는 두 가지 상황에서 필요함:
  - **크기(Spatial Dimension)가 다른 경우:**  
    - 예) x의 shape이 (B, C, 32, 32)인데, x1이 (B, C, 16, 16)인 경우
  - **채널 수가 다른 경우:**  
    - 예) x의 채널이 16인데, x1의 채널이 32인 경우

---

## 8. 요약 및 결론

1. **WideResNet_sp**는 SPKD 적용을 위해 설계된 모델로, 초기 Convolution Layer와 3개의 Residual Stage, GAP 및 FC Layer로 구성됨.
2. **Residual Block의 반복 횟수 N**은 (d - 4) / 6 으로 계산되며, 각 Block 내에 2개의 Conv Layer가 포함됨.
3. **첫 번째 Residual Stage**에서는 Feature Map의 크기를 유지하기 위해 stride가 1로 설정되며, 채널 수가 변할 경우에만 1×1 Convolution(conv_inp)를 사용하여 채널을 맞춤.
4. **두 번째 및 세 번째 Residual Stage**에서는 첫 번째 Block에서 stride가 2로 설정되어 다운샘플링을 수행하며, 이때 conv_inp를 사용해 입력 x를 변환하여 Skip Connection을 올바르게 수행함.
5. **Depth 계산**은 학습 가능한 가중치를 가진 Conv Layer와 FC Layer만 포함하며, BatchNorm, ReLU, Pooling 등은 제외됨.
6. **WRN161 vs. WRN163**는 첫 번째 Residual Stage에서 채널 수 확장의 여부에 따라 구분되며, 이로 인해 Skip Connection을 위한 conv_inp의 적용 방식이 달라짐.
7. **Skip Connection (x + x1)을 올바르게 수행하기 위해서는 두 텐서의 shape가 동일해야 하며, conv_inp(x)는 이를 맞추기 위한 핵심 역할을 함.


## Object Detection 공부.
### Object Detection의 기본
- Bounding Box란? : 이미지 안에서 찾고자 하는 Object의 위치를 네모 박스로 표현하는 개념.
  - Object Detection 모델의 목표는 이 Bounding Box를 정확하게 예측하는 것이다.
  - 또한, Bounding Box는 다음과 같은 방식으로 표현된다.
  - (x_min, y_min, x_max, y_max) 또는, (x_center, y_center, width, height). 
  - 하지만, YOLO에서는 (x_center, y_center, width, height)의 방식을 주로 사용한다.


- IoU란? : Intersection over Union으로, Ground Truth와 Predicted Box가 얼마나 겹치는지 계산하는 지표.
  - 값이 1에 가까울수록 예측이 정확함을 의미한다.
  - Ground Truth는 정답 label(Bounding Box)을 의미하고, Predicted Box는 모델이 예측한 Bounding Box를 의미한다.


- NMS란? : Non-Maximum Suppression으로, Object Detection에서 중복된 Bounding Box를 제거하는 알고리즘이다.
  - Object Detection 모델은 일반적으로, 한 이미지에서 Object를 찾을 때, 하나의 객체에 대해 여러 개의 Bounding Box를 예측하는 경우가 많다.
  - 이때, 가장 신뢰도가 높은(Confidence Score가 높은) Bounding Box만 남기고, 나머지는 제거하는 과정을 의미한다.
  - 이것을 NMS가 자동으로 수행해준다.
  - 즉, NMS란, 모델이 최종 예측을 수행할 때 존재하는 Bounding Box들 중 하나를 선택하기 위한 것이다. (학습 때는 진행되지 않는다.)
  - 당연히 학습 때에는 존재하는 모든 Bounding Box들(Parameter)이 GT와 IoU가 높아질 수록 좋기 때문이다.


- Confidence Score : 특정 Bounding Box가 실제로 객체를 포함하는지를 예측하는 점수.
  - Confidence Score = P(Object) x IoU(Pred, GT)
  - P : 이 Grid Cell 안에 객체가 존재할 확률
  - IoU(Pred, GT) : 예측된 Bounding Box와 실제 정답(GT) 박스의 IoU
  - 즉, Confidence Score는 Bounding Box마다 가지는 점수이고, P(자신이 속해 있는 Grid Cell이 객체를 포함할 확률) x IoU(자신과 GT와의 IoU점수) 로 계산이 된다.


- Yolo의 동작 원리 (Prediction)
  1. YOLO는 이미지를 S x S 크기의 겹치지 않는 Grid로 나눈다.
  2. 그 Grid Cell들이 찾고 싶은 Object(객체)의 중심을 가지고 있는지에 대한 확률을 얻고, 가중치 Parameter를 통해 Bounding Box를 생성한다.
  3. 그 확률을 토대로, 각 Bounding Box의 Confidence Score를 계산한다.
  4. 각 Bounding Box의 Confidence Score가 특정 값(Threshold)를 넘는다면 그 Bounding Box는 두고, 아니라면 제거한다. (학습 때는 Threshold를 사용하지 않고 모두 챙겨간다.)
  5. 그렇게 Threshold를 넘는 Bounding Box만 남게 되고, 그 Bounding Box들은 loss 값을 통해 IoU가 높아지는 방향으로 조정이 된다.
  6. 이 때 남은 Bounding Box들은 굳이 Grid Cell 내부로만 한정되지 않기 때문에 여러 개의 Bounding Box가 유지되고, 조정된다.
  7. 학습이 끝난 이후, Validation 단계에서 NMS가 겹치는 여러 Bounding Box들(한 객체에 여러 Bounding Box가 있을 것임) 중 가장 Confidence Score가 높은 Bounding Box하나만을 남겨, 최종 예측 결과를 내놓게 된다.


- Yolo의 동작 원리 (Training)
  1. 각 Epoch마다 YOLO는 이미지를 S x S 크기의 겹치지 않는 Grid로 나눈다.
  2. 그 Grid Cell들이 찾고 싶은 Object(객체)의 중심을 가지고 있는지에 대한 확률(P(Object))을 얻고, 가중치 Parameter를 통해 Bounding Box를 생성한다. (Anchor Box개념의 도입도 공부하자.)
  3. 모든 Bounding Box의 Parameter 가중치와 P(Object)을 예측하는 Parameter들은 loss 값을 통해 업데이트된다.
  4. loss 값에는 Bounding Box의 위치 손실(Localization Loss), 객체 존재 여부 손실(Objectness Loss, P(Object)), 클래스 예측 손실(Classificaion Loss)가 포함된다.



- mAP란? : Mean Average Precision으로, Object Detection 모델의 성능을 평가하는 대표적인 지표.
  - Precision과 Recall 개념을 확장한 것으로, 여러 클래스에 대해 모델의 평균 Acc를 나타낸다.
  - Precision-Recall 곡선 아래의 면적을 계산한 값이 AP인데, 여러 개의 클래스(객체)에서 AP값을 평균 낸 값을 mAP라고 함
  - 이 때 Object Detection에서는 클래스를 예측(0 or 1)하는 것이 아닌, Bounding Box의 IoU를 예측하는 것이므로, Precision과 Recall을 어떻게 구현하는지가 의문임.
  - 그래서 YOLO에서는 mAP@0.5, mAP@0.75와 같이 (IoU가 0.5나 0.75 이상이라면 정답으로 인정)하는 등의 기준을 사용한다.
  - 그렇다면 각 Grid Cell이 가지는 B개의 Bounding Box에서 B도 조절가능한 파라미터일까?
  - B는 하이퍼 파라미터라서, 학습하면서 바뀌지는 않고, Bounding Box의 선택 방식을 조정하게 된다. YOLOv2부터는 Anchor Box 개념을 사용하여 다양한 크기의 객체를 탐지하는데, 특정 데이터셋에서 작은 객체 탐지가 중요한 경우, Anchor Box 크기를 조정하여 Recall을 높일 수 있다고 한다.


- Anchor Box 알고리즘이란?
  - YOLOv1에서는 Grid Cell이 직접 Bounding Box의 위치, 크기를 모두 예측했다.
  - 하지만 이러면 한 이미지 안에 작은 Object와 큰 Object가 모두 있는 경우 특정 크기의 객체만 잘 탐지되고, 다양한 크기의 객체를 잘 탐지하지 못함.
  - YOLOv1에서는 Bounding Box의 크기가 학습 초기에는 랜덤하게 설정되기 때문에, 매우 비효율적이었다.
  - Anchor Box에서는 미리 정해진 크기와 비율의 Anchor Box(기준 박스)를 사용한다.
  - 즉, 기존에는 B = 3이더라도, 완전히 랜덤한 크기를 가진 Bounding Box를 생성했지만, YOLOv2부터는 B = 3이라면, 각 Bounding Box들이 서로 다른 정해진 크기의 Anchor Box(12 x 12, 24 x 24, 36 x 36 이런느낌)로 초기화가 된다.
  - 여기서 각 Anchor Box의 크기는 YOLO모델이 K-Means Clustering으로 자동 설정된다.
  - 또한 이후에 크기에 맞는 객체로 맞춰지는 학습이 진행되게 된다.
  - 또한, 각 Bounding Box들은 처음 초기화된 후 가장 적절한 클래스를 목표로 학습이 진행된다. 즉, 처음 초기화 된 후 Bounding Box는 P(Object), Bounding Box위치, P(Class)를 예측하고 GT와 가장 IoU가 높은 Anchor Box가 해당 객체를 학습한다.
  - 즉, 각 GT는 자신과 가장 IoU가 높은 Anchor Box와 연결되어 해당 Box가 학습하도록 하지만, GT와 연결되지 않은 Bounding Box들은 Confidence Score를 낮추는 방향으로 학습이 진행된다. (Negative loss)



### SP를 사용한 학습 설명
1. sp_param이 GENE_Activ에는 700, PAMAP2에는 200으로 설정이 되었는데 이것이 무엇일까?
2. sp_param(β)은 앞의 CE_Loss(Student)와 KD_Loss(T1, T2, S)간의 가중치는 λ로 관리하는데, 그 때 SP_Loss를 몇으로 설정해야 학습이 골고루 잘 될까 하는 하이퍼 파라미터이다.
3. α는 두 Teacher 간 logits loss를 합칠 때의 가중치
4. k는 분할 개수(?) : Feature Representation을 나누는 개수. 이게 4였기 때문에, 우리 코드에서 최종 출력(1), At1(2), At2(3), At3(4)으로 총 4개임.

<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.13/TPKD_sp_param.png" alt="sp_param이 뭐냐" width="500">




## PAMAP2 데이터 분석
### 데이터 형태
1. 83319개의 데이터와 각 데이터는 40개의 Feature를 가지고 있다.
2. 83319개의 데이터는 0 ~ 11에 포함하는 라벨을 각각 가지고 있다.
3. 데이터셋에서 9명의 사람으로부터 83319개의 데이터를 얻은 것이다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP.png" alt="PAMAP shape" width="500">

### 학습할 때 데이터의 사용
1. 9명의 사람은 0 ~ 8의 id로 구분되고, 학습을 할 때 그 중 한명을 Test_id로 지정하여 남은 8명은 Train set으로 학습한다.
2. 이렇기 때문에, 같은 사람의 데이터를 학습하고, 테스트하게 되는 불상사는 일어나지 않음.
3. 같은 사람에서 나온 데이터를 학습하고, 테스트때 사용한다면, Acc가 높게 나올 확률이 높다. (GENE_Active때 겪어본 문제.)

### 데이터의 사용
1. .data 파일의 형식으로 저장되어있다. (GENE_Active랑 다르다.)
2. 이렇게 .data 파일로 되어있는 경우 .npy파일과 다르게 pickle.load를 통하여 데이터를 얻어왔다.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP_pickle.png" alt="PAMAP Pickle load" width="500">
3. 근데 cls_id = [24, 1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17] 인데, 원래 PAMAP2에는 24번 label이 없다. 24번은 뭘까
4. 0, 9, 10, 11을 묶어서 24로 놓은건가?
5. 근데 데이터를 로드해와서 np.unique(labels)를 찍어보니, 0 ~ 11로 정렬하게 나와있다. (아마 Encoding된 Label인듯.)
6. 뭐 어쨌든 데이터를 로드해왔다고 치고. (이해가 안감.) 데이터를 어떤식으로 불러와서 load하는지 보자.
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP2_data_load.png" alt="PAMAP Data Load" width="500">
7. 데이터를 window크기 100씩으로 불러오는데, 시작 지점은 22씩만 늘어난다. (나머지 78개의 sequence는 계속 겹치면서 data를 로드하고 있다.)
<img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/25.2.6/PAMAP2_step_size.png" alt="PAMAP Step Size" width="500">
8. 그 다음, 데이터를 만들고 싶은 크기로 x_train, y_train, x_test, y_test를 np.zeros로 만들어주고, 하나씩 넣어준다.
9. 왜하는가? > (idx, window_length, channel)의 형태를 (idx, batch_size, window_length, channel)의 형태로 바꿔주기 위함임.


### 내가 한 GAF데이터 형성 및 학습
1. test_id(0 ~ 8)을 기준으로 각각 총 9개의 Train, Test 데이터셋을 만듦. (좀 비효율적인듯.)
2. 그러고 나서 np.load를 통해 이 데이터만 가져와서 빠른 데이터 load 후 단일(Teacher로 사용할) 네트워크를 학습함.

### 나중에 KD에 사용할 데이터 로더함수
1. Signal과 GAF Image를 모두 받아오도록 작성해야함. (이미 GENE Activ에서 했던거라 금방 할듯.)
2. Teacher 네트워크들 학습하는데 한세월 걸릴것같아서 천천히 하려고 한다.





## 이번 주 학습 결과 (GENE_Activ, Ann, Ann + Sp)
### 학습 진행사항 (Annealing을 이용한 결과 - 14cls)
<li> T1 : WRN16-1(GAF), T2 : WRN16-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 70.7241 </li>
<li> 71.0540 </li>
<li> 70.8804 </li>
<li> 평균 : 70.8862 </li>
<li> 표준편차 : 0.1347 </li>
<br>
</ul>

<li> T1 : WRN16-3(GAF), T2 : WRN16-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 71.8875 </li>
<li> 71.6965 </li>
<li> 71.3145 </li>
<li> 평균 : 71.6328 </li>
<li> 표준편차 : 0.2382 </li>
<br>
</ul>


<li> T1 : WRN28-1(GAF), T2 : WRN28-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 70.4810 </li>
<li> 69.7343 </li>
<li> 70.4636 </li>
<li> 평균 : 70.2263 </li>
<li> 표준편차 : 0.3480 </li>
<br>
</ul>


<li> T1 : WRN28-3(GAF), T2 : WRN28-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 70.9845 </li>
<li> 70.0816 </li>
<li> 70.8630 </li>
<li> 평균 : 70.6430 </li>
<li> 표준편차 : 0.4001 </li>
<br>
</ul>



### 학습 진행사항 (Annealing + spKD를 이용한 결과 - 14cls)
<li> T1 : WRN16-1(GAF), T2 : WRN16-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 72.0264 </li>
<li> 71.3666 </li>
<li> 71.6617 </li>
<li> 평균 : 71.6849 </li>
<li> 표준편차 : 0.2699 </li>
<br>
</ul>

<li> T1 : WRN16-3(GAF), T2 : WRN16-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 71.0193 </li>
<li> 70.9325 </li>
<li> 71.0366 </li>
<li> 평균 : 70.9961 </li>
<li> 표준편차 : 0.0455 </li>
<br>
</ul>


<li> T1 : WRN28-1(GAF), T2 : WRN28-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 70.4810 </li>
<li> 70.6546 </li>
<li> 70.0469 </li>
<li> 평균 : 70.3942 </li>
<li> 표준편차 : 0.2556 </li>
<br>
</ul>


<li> T1 : WRN28-3(GAF), T2 : WRN28-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 71.5228 </li>
<li> 71.6270 </li>
<li> 70.0625 </li>
<li> 평균 : 71.0708 </li>
<li> 표준편차 : 0.7142 </li>
<br>
</ul>



### 학습 진행사항 (Annealing을 이용한 결과 - 7cls, 500w)
<li> T1 : WRN16-1(GAF), T2 : WRN16-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 90.6924 </li>
<li> 90.8556 </li>
<li> 90.2678 </li>
<li> 평균 : 90.6053 </li>
<li> 표준편차 : 0.2478 </li>
<br>
</ul>

<li> T1 : WRN16-3(GAF), T2 : WRN16-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 90.4637 </li>
<li> 91.0516 </li>
<li> 90.5291 </li>
<li> 평균 : 90.6815 </li>
<li> 표준편차 : 0.2631 </li>
<br>
</ul>


### 학습 진행사항 (Annealing을 이용한 결과 - 7cls, 1000w)
<li> T1 : WRN16-1(GAF), T2 : WRN16-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 90.0065 </li>
<li> 89.7779 </li>
<li> 90.0718 </li>
<li> 평균 : 89.9521 </li>
<li> 표준편차 : 0.1260 </li>
<br>
</ul>

<li> T1 : WRN16-3(GAF), T2 : WRN16-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 90.7903 </li>
<li> 90.8230 </li>
<li> 90.7250 </li>
<li> 평균 : 90.7794 </li>
<li> 표준편차 : 0.0407 </li>
<br>
</ul>


### 학습 진행사항 (Annealing + spKD를 이용한 결과 - 7cls, 500w)
<li> T1 : WRN16-1(GAF), T2 : WRN16-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 90.3984 </li>
<li> 90.6924 </li>
<li> 90.8230 </li>
<li> 평균 : 90.6379 </li>
<li> 표준편차 : 0.1776 </li>
<br>
</ul>

<li> T1 : WRN16-3(GAF), T2 : WRN16-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 90.1372 </li>
<li> 90.9536 </li>
<li> 90.2025 </li>
<li> 평균 : 90.4311 </li>
<li> 표준편차 : 0.3704 </li>
<br>
</ul>


### 학습 진행사항 (Annealing + spKD를 이용한 결과 - 7cls, 1000w)
<li> T1 : WRN16-1(GAF), T2 : WRN16-1(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 90.2351 </li>
<li> 89.9086 </li>
<li> 90.1045 </li>
<li> 평균 : 90.0827 </li>
<li> 표준편차 : 0.1342 </li>
<br>
</ul>

<li> T1 : WRN16-3(GAF), T2 : WRN16-3(Sig) S : WRN16-1(sig) 결과 </li>
<ul>
<li> 90.6924 </li>
<li> 90.9536 </li>
<li> 90.3658 </li>
<li> 평균 : 90.6706 </li>
<li> 표준편차 : 0.2405 </li>
<br>
</ul>


### 학습 진행사항 (Annealing을 이용한 결과 - 14cls)
| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| T1: WRN16-1(GAF), T2: WRN16-1(Sig), S: WRN16-1(Sig) | 70.7241 | 71.0540 | 70.8804 | **70.8862** | 0.1347 |
| T1: WRN16-3(GAF), T2: WRN16-3(Sig), S: WRN16-1(Sig) | 71.8875 | 71.6965 | 71.3145 | **71.6328** | 0.2382 |
| T1: WRN28-1(GAF), T2: WRN28-1(Sig), S: WRN16-1(Sig) | 70.4810 | 69.7343 | 70.4636 | **70.2263** | 0.3480 |
| T1: WRN28-3(GAF), T2: WRN28-3(Sig), S: WRN16-1(Sig) | 70.9845 | 70.0816 | 70.8630 | **70.6430** | 0.4001 |


### 학습 진행사항 (Annealing + spKD를 이용한 결과 - 14cls)

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| T1: WRN16-1(GAF), T2: WRN16-1(Sig), S: WRN16-1(Sig) | 72.0264 | 71.3666 | 71.6617 | **71.6849** | 0.2699 |
| T1: WRN16-3(GAF), T2: WRN16-3(Sig), S: WRN16-1(Sig) | 71.0193 | 70.9325 | 71.0366 | **70.9961** | 0.0455 |
| T1: WRN28-1(GAF), T2: WRN28-1(Sig), S: WRN16-1(Sig) | 70.4810 | 70.6546 | 70.0469 | **70.3942** | 0.2556 |
| T1: WRN28-3(GAF), T2: WRN28-3(Sig), S: WRN16-1(Sig) | 71.5228 | 71.6270 | 70.0625 | **71.0708** | 0.7142 |

---

### 학습 진행사항 (Annealing을 이용한 결과 - 7cls, 500w)

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| T1: WRN16-1(GAF), T2: WRN16-1(Sig), S: WRN16-1(Sig) | 90.6924 | 90.8556 | 90.2678 | **90.6053** | 0.2478 |
| T1: WRN16-3(GAF), T2: WRN16-3(Sig), S: WRN16-1(Sig) | 90.4637 | 91.0516 | 90.5291 | **90.6815** | 0.2631 |


### 학습 진행사항 (Annealing + spKD를 이용한 결과 - 7cls, 500w)

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| T1: WRN16-1(GAF), T2: WRN16-1(Sig), S: WRN16-1(Sig) | 90.3984 | 90.6924 | 90.8230 | **90.6379** | 0.1776 |
| T1: WRN16-3(GAF), T2: WRN16-3(Sig), S: WRN16-1(Sig) | 90.1372 | 90.9536 | 90.2025 | **90.4311** | 0.3704 |

---

### 학습 진행사항 (Annealing을 이용한 결과 - 7cls, 1000w)

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| T1: WRN16-1(GAF), T2: WRN16-1(Sig), S: WRN16-1(Sig) | 90.0065 | 89.7779 | 90.0718 | **89.9521** | 0.1260 |
| T1: WRN16-3(GAF), T2: WRN16-3(Sig), S: WRN16-1(Sig) | 90.7903 | 90.8230 | 90.7250 | **90.7794** | 0.0407 |

### 학습 진행사항 (Annealing + spKD를 이용한 결과 - 7cls, 1000w)

| Experiment | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| T1: WRN16-1(GAF), T2: WRN16-1(Sig), S: WRN16-1(Sig) | 90.2351 | 89.9086 | 90.1045 | **90.0827** | 0.1342 |
| T1: WRN16-3(GAF), T2: WRN16-3(Sig), S: WRN16-1(Sig) | 90.6924 | 90.9536 | 90.3658 | **90.6706** | 0.2405 |




## 이번 주 학습 결과 (PAMAP2, GAF 표현을 이용한 Teacher 네트워크 학습.)
### 학습 진행 사항 (Test_id : 0)
<li> WRN16-1 </li>
<ul>
<li> 77.8046 </li>
<li> 79.0660 </li>
<li> 80.9447 </li>
<li> 평균 : 79.2718 </li>
<li> 표준편차 : 1.2902 </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 80.9447 </li>
<li> 81.1863 </li>
<li> 80.7032 </li>
<li> 평균 : 80.9447 </li>
<li> 표준편차 : 0.1972 </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 83.1186 </li>
<li> 81.0521 </li>
<li> 81.2131 </li>
<li> 평균 : 81.7946 </li>
<li> 표준편차 : 0.9385 </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 82.3671 </li>
<li> 82.0451 </li>
<li> 82.4745 </li>
<li> 평균 : 82.2956 </li>
<li> 표준편차 : 0.1825 </li>
</ul>

### 학습 진행 사항 (Test_id : 1)
<li> WRN16-1 </li>
<ul>
<li> 70.6752 </li>
<li> 73.3248 </li>
<li> 72.6115 </li>
<li> 평균 : 72.2038 </li>
<li> 표준편차 : 1.1194 </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 72.3822 </li>
<li> 70.8790 </li>
<li> 72.4586 </li>
<li> 평균 : 71.9066 </li>
<li> 표준편차 : 0.7273 </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 70.6242 </li>
<li> 69.9363 </li>
<li> 73.6051 </li>
<li> 평균 : 71.3885 </li>
<li> 표준편차 : 1.5923 </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 75.2866 </li>
<li> 75.8471 </li>
<li> 78.2930 </li>
<li> 평균 : 76.4756 </li>
<li> 표준편차 : 1.3053 </li>
</ul>

### 학습 진행 사항 (Test_id : 2)
<li> WRN16-1 </li>
<ul>
<li> 77.2377 </li>
<li> 78.8580 </li>
<li> 79.6682 </li>
<li> 평균 : 78.5880 </li>
<li> 표준편차 : 1.0105 </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 80.1698 </li>
<li> 77.1991 </li>
<li> 78.8194 </li>
<li> 평균 : 78.7294 </li>
<li> 표준편차 : 1.2145 </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 78.0478 </li>
<li> 79.4367 </li>
<li> 76.8133 </li>
<li> 평균 : 78.0993 </li>
<li> 표준편차 : 1.0716 </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 79.7454 </li>
<li> 79.2824 </li>
<li> 80.9414 </li>
<li> 평균 : 79.9897 </li>
<li> 표준편차 : 0.6990 </li>
</ul>

### 학습 진행 사항 (Test_id : 3)
<li> WRN16-1 </li>
<ul>
<li> 77.4877 </li>
<li> 77.4587 </li>
<li> 79.4604 </li>
<li> 평균 : 78.1356 </li>
<li> 표준편차 : 0.9368 </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 81.6942 </li>
<li> 80.2727 </li>
<li> 78.7932 </li>
<li> 평균 : 80.2534 </li>
<li> 표준편차 : 1.1844 </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 78.1259 </li>
<li> 77.6617 </li>
<li> 78.3000 </li>
<li> 평균 : 78.0292 </li>
<li> 표준편차 : 0.2694 </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 81.6652 </li>
<li> 79.8666 </li>
<li> 80.2147 </li>
<li> 평균 : 80.5822 </li>
<li> 표준편차 : 0.7789 </li>
</ul>

### 학습 진행 사항 (Test_id : 4)
<li> WRN16-1 </li>
<ul>
<li> 79.3850 </li>
<li> 80.0492 </li>
<li> 80.4674 </li>
<li> 평균 : 79.9672 </li>
<li> 표준편차 : 0.4457 </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 81.5744 </li>
<li> 80.5166 </li>
<li> 80.6642 </li>
<li> 평균 : 80.9184 </li>
<li> 표준편차 : 0.4678 </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 80.4674 </li>
<li> 78.5732 </li>
<li> 81.0332 </li>
<li> 평균 : 80.0246 </li>
<li> 표준편차 : 1.0520 </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 80.7380 </li>
<li> 80.5412 </li>
<li> 81.1316 </li>
<li> 평균 : 80.8036 </li>
<li> 표준편차 : 0.2455 </li>
</ul>

### 학습 진행 사항 (Test_id : 5)
<li> WRN16-1 </li>
<ul>
<li> 81.0086 </li>
<li> 78.8627 </li>
<li> 81.0622 </li>
<li> 평균 : 80.3112 </li>
<li> 표준편차 : 1.0245 </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 81.0086 </li>
<li> 79.6064 </li>
<li> 81.2232 </li>
<li> 평균 : 80.6127 </li>
<li> 표준편차 : 0.7170 </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 78.3262 </li>
<li> 80.4989 </li>
<li> 80.4721 </li>
<li> 평균 : 79.7657 </li>
<li> 표준편차 : 1.0180 </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 79.8820 </li>
<li> 79.8552 </li>
<li> 80.0161 </li>
<li> 평균 : 79.9178 </li>
<li> 표준편차 : 0.0704 </li>
</ul>

### 학습 진행 사항 (Test_id : 6)
<li> WRN16-1 </li>
<ul>
<li> 84.9928 </li>
<li> 82.7706 </li>
<li> 84.2713 </li>
<li> 평균 : 84.0116 </li>
<li> 표준편차 : 0.9256 </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 86.3492 </li>
<li> 86.9841 </li>
<li> 84.5310 </li>
<li> 평균 : 85.9548 </li>
<li> 표준편차 : 1.0396 </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 86.3492 </li>
<li> 85.2237 </li>
<li> 85.2237 </li>
<li> 평균 : 85.5989 </li>
<li> 표준편차 : 0.5306 </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 84.0115 </li>
<li> 85.5988 </li>
<li> 83.8672 </li>
<li> 평균 : 84.4925 </li>
<li> 표준편차 : 0.7845 </li>
</ul>

### 학습 진행 사항 (Test_id : 7)
<li> WRN16-1 </li>
<ul>
<li> 80.6856 xxx </li>
<li> 80.6089 </li>
<li> 80.0972 </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 80.0460 </li>
<li> 80.7623 </li>
<li> 78.6646 </li>
<li> 평균 : 79.8243 </li>
<li> 표준편차 : 0.8706 </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 80.2763 </li>
<li> 80.2251 </li>
<li> 79.8414 </li>
<li> 평균 : 80.1143 </li>
<li> 표준편차 : 0.1941 </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 80.1740 </li>
<li> 79.6623 </li>
<li> 81.1205 </li>
<li> 평균 : 80.3189 </li>
<li> 표준편차 : 0.6041 </li>
</ul>

### 학습 진행 사항 (Test_id : 8)
<li> WRN16-1 </li>
<ul>
<li> 92.3913 </li>
<li> 83.6957 </li>
<li> 88.0435 </li>
<li> 평균 : 88.0435 </li>
<li> 표준편차 : 3.5500 </li>
</ul>

<li> WRN16-3 </li>
<ul>
<li> 94.5652 </li>
<li> 85.8696 </li>
<li> 90.2174 xxx </li>
<li> 평균 :  </li>
<li> 표준편차 :  </li>
</ul>

<li> WRN28-1 </li>
<ul>
<li> 94.5652 </li>
<li> 84.7826 </li>
<li> 89.1304 </li>
<li> 평균 : 89.4927 </li>
<li> 표준편차 : 4.0019 </li>
</ul>

<li> WRN28-3 </li>
<ul>
<li> 93.4783 </li>
<li> 83.6957 </li>
<li> 95.6522 </li>
<li> 평균 : 90.9421 </li>
<li> 표준편차 : 5.2002 </li>
</ul>



## 학습 진행 사항 (Test_id : 0)

| Experiment  | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| WRN16-1  | 77.8046 | 79.0660 | 80.9447 | **79.2718** | 1.2902 |
| WRN16-3  | 80.9447 | 81.1863 | 80.7032 | **80.9447** | 0.1972 |
| WRN28-1  | 83.1186 | 81.0521 | 81.2131 | **81.7946** | 0.9385 |
| WRN28-3  | 82.3671 | 82.0451 | 82.4745 | **82.2956** | 0.1825 |

---

## 학습 진행 사항 (Test_id : 1)

| Experiment  | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| WRN16-1  | 70.6752 | 73.3248 | 72.6115 | **72.2038** | 1.1194 |
| WRN16-3  | 72.3822 | 70.8790 | 72.4586 | **71.9066** | 0.7273 |
| WRN28-1  | 70.6242 | 69.9363 | 73.6051 | **71.3885** | 1.5923 |
| WRN28-3  | 75.2866 | 75.8471 | 78.2930 | **76.4756** | 1.3053 |

---

## 학습 진행 사항 (Test_id : 2)

| Experiment  | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| WRN16-1  | 77.2377 | 78.8580 | 79.6682 | **78.5880** | 1.0105 |
| WRN16-3  | 80.1698 | 77.1991 | 78.8194 | **78.7294** | 1.2145 |
| WRN28-1  | 78.0478 | 79.4367 | 76.8133 | **78.0993** | 1.0716 |
| WRN28-3  | 79.7454 | 79.2824 | 80.9414 | **79.9897** | 0.6990 |


## 학습 진행 사항 (Test_id : 3)

| Experiment  | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| WRN16-1  | 77.4877 | 77.4587 | 79.4604 | **78.1356** | 0.9368 |
| WRN16-3  | 81.6942 | 80.2727 | 78.7932 | **80.2534** | 1.1844 |
| WRN28-1  | 78.1259 | 77.6617 | 78.3000 | **78.0292** | 0.2694 |
| WRN28-3  | 81.6652 | 79.8666 | 80.2147 | **80.5822** | 0.7789 |

---

## 학습 진행 사항 (Test_id : 4)

| Experiment  | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| WRN16-1  | 79.3850 | 80.0492 | 80.4674 | **79.9672** | 0.4457 |
| WRN16-3  | 81.5744 | 80.5166 | 80.6642 | **80.9184** | 0.4678 |
| WRN28-1  | 80.4674 | 78.5732 | 81.0332 | **80.0246** | 1.0520 |
| WRN28-3  | 80.7380 | 80.5412 | 81.1316 | **80.8036** | 0.2455 |

---

## 학습 진행 사항 (Test_id : 5)

| Experiment  | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| WRN16-1  | 81.0086 | 78.8627 | 81.0622 | **80.3112** | 1.0245 |
| WRN16-3  | 81.0086 | 79.6064 | 81.2232 | **80.6127** | 0.7170 |
| WRN28-1  | 78.3262 | 80.4989 | 80.4721 | **79.7657** | 1.0180 |
| WRN28-3  | 79.8820 | 79.8552 | 80.0161 | **79.9178** | 0.0704 |

---

## 학습 진행 사항 (Test_id : 6)

| Experiment  | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| WRN16-1  | 84.9928 | 82.7706 | 84.2713 | **84.0116** | 0.9256 |
| WRN16-3  | 86.3492 | 86.9841 | 84.5310 | **85.9548** | 1.0396 |
| WRN28-1  | 86.3492 | 85.2237 | 85.2237 | **85.5989** | 0.5306 |
| WRN28-3  | 84.0115 | 85.5988 | 83.8672 | **84.4925** | 0.7845 |

---

## 학습 진행 사항 (Test_id : 7)

| Experiment  | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| WRN16-1  | 80.6856 | 80.6089 | 80.0972 | **80.4639** | 0.2612 |
| WRN16-3  | 80.0460 | 80.7623 | 78.6646 | **79.8243** | 0.8706 |
| WRN28-1  | 80.2763 | 80.2251 | 79.8414 | **80.1143** | 0.1941 |
| WRN28-3  | 80.1740 | 79.6623 | 81.1205 | **80.3189** | 0.6041 |

---

## 학습 진행 사항 (Test_id : 8)

| Experiment  | Trial 1 | Trial 2 | Trial 3 | Mean | Std |
|------------|---------|---------|---------|---------|---------|
| WRN16-1  | 92.3913 | 83.6957 | 88.0435 | **88.0435** | 3.5500 |
| WRN16-3  | 94.5652 | 85.8696 | 90.2174 | **90.2174** | 3.5500 |
| WRN28-1  | 94.5652 | 84.7826 | 89.1304 | **89.4927** | 4.0019 |
| WRN28-3  | 93.4783 | 83.6957 | 95.6522 | **90.9421** | 5.2002 |



## 모든 Test_id를 평균 낸 결과
| Experiment  | Mean | Std |
|------------|---------|---------|
| WRN16-1  | **80.1107** | 4.3123 |
| WRN16-3  | **81.0402** | 4.9223 |
| WRN28-1  | **80.4786** | 5.0272 |
| WRN28-3  | **81.7575** | 4.2402 |

- 결과에 대한 나의 생각
  - 지금 이전 reference 논문에 의해서 lambda와 t값을 0.99 / 4로 사용하고 있다.
  - 근데, 그것은 그 논문에서 signal로 학습한 결과가 image로 학습한 결과보다 낮았기 때문이라고 생각한다.
  - (86.93, 87.23, 87.45, 87.88)이었음.
  - 그래서 lambda값을 0.1, 0.3, 0.5, 0.7, 0.9로 바꿔가며 최적의 값을 찾아버려 함.


## Trainning Environment
<ul>
<li> Dataset = GENE(life_log), PAMAP(이것도 HAR 데이터) </li> 
<li> python = 3.8.18 </li>
<li> pytorch = 2.3.0 + (cu12.1), CUDA 11.8 </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 200 </li>
<li> batch size = 128 </li>
<li> learning rate = 0.05 - 0.0001 (Adjust Learning Rate) </li>
<li> optimizer = Momentum + SGD </li>
</ul>