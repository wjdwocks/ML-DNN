## 24.11.26 공부할 내용
<li> 첫 번째 논문 : Leveraging Topological Guidance for Improved Knowledge Distillation </li>
<li> 두 번째 논문 : Topological Persistence Guided Knowledge Distillation for Wearable Sensor Data </li>

## 첫 번째 논문
### Abstract 정리
<li> 이전의 KD들은 Embedding Feature간의 점대점 or 쌍 관계를 지식으로 정의하고 이를 전달함. </li>
<li> 하지만, 복잡한 잠재 공간(Latent Space)의 관계를 효율적으로 전달하지 못했다. </li>
<li> 그래서 TopKD라는 방법을 제안한다. </li>
<li> Topological Feature를 PD를 이용해 PI로 근사하여 학습시킴. </li>

### Introduction 정리
<li> Vanilla KD는 Teacher의 soft logit을 Student에게 학습시킴. </li>
<li> Feature-Based KD는 Teacher와 Student의 중간 Layer의 Feature를 일치시키는 방식으로 학습시킴. </li>
<li> Relation-Based KD는 Embedding Features간의 복잡한 관계를 탐지하는데 중점을 둠 (거리와 각도 기반으로 특징 간의 구조를 정의, 학습시킴) </li>
<li> 이 논문에서는 Global Topological Characteristics(전역 위상 특성)을 활용하여 Teacher 모델의 전반적인 구조적 관계를 Student에게 전달한다. </li>

### Method 정리
<li> 이 논문에서 제시하는 Topology-Informed Knowledge Distillation (TopKD) </li>
<li> Teacher 모델의 잠재 공간(Latent Space)에서 지속성 다이어그램(PD)를 활용하여 Global Topology Knowledge를 정의함. </li>
<li> PD는 아레의 세 가지 정보를 요약하고 있다. </li>
<ul>
<li> 데이터 간 유사성 </li>
<li> 데이터 분포 </li>
<li> 데이터 간 상호작용 및 거리 </li>
</ul>
<li> TopKD Loss의 요약 </li>
<ul>
<li> PD를 계산하는 것은 매우 높은 계산 비용이 들기에 RipsNet을 사용하여 PD를 근사한 뒤 PI를 생성한다. </li>
<li> Teacher는 실제 PI(TDA)와 RipsNet으로 근사한 PI가 비슷해지도록 RipsNet을 학습시킴. </li>
<li> RipsNet으로 근사된 Teacher의 PI와 RipsNet으로 근사된 Student의 PI가 비슷해지도록 Student의 loss항을 추가함 </li>
<li> 기존의 KD loss와 이 Topological loss를 더하여 학습함. </li>
</ul>

## 두 번째 논문
### Abstract
<li> TDA는 데이터의 기하학적/위상적 구조를 파악하는데 유용하지만, 높은 계산 비용과 메모리 소모로 인해 제한이 있다. </li>
<li> KD에서 PI를 통해 TDA의 Topological Feature를 time-series Data와 결합해 Student의 성능을 개선시킬 수 있다. </li>
<li> 이 논문에서는 KD에서 원시 시계열 데이터와 TDA기반의 Topological Feature를 함께 사용했을 때 성능을 비교한다. </li>
<li> 여러 Teacher를 활용해서 Time-series Data와 Topological Feature를 융합함으로써 Student 학습 성능을 최적화함. </li>
<li> Topological Feature를 사용하면 Noise에 대한 Robustness와 일반화 가능성(Generalizability)에 좋은 영향이 있었다. </li>
<li> 단일 Teacher(원시 시계열 데이터로 학습)에서의 KD와 다중 Teacher(원시 데이터 + Topological Feature)에서의 KD의 비교가 중심인듯. </li>

### Introduction
<li> 문제 제기 </li>
<ul>
<li> 웨어러블 센서 데이터는 인간의 움직임, 생체 신호 등 다양한 정보를 제공하지만, 고해상도 데이터는 계산 및 저장 비용이 크고 모델 학습이 어렵다. </li>
<li> KD는 복잡한 모델을 단순한 모델로 압축하여 계산 비용을 줄이는 데 효과적이지만, 데이터 변동성이 큰 경우에 적합성을 보장하기 어렵다는 문제가 있다. </li>
</ul>
<li> 연구 배경 </li>
<ul>
<li> 최근 TDA가 Wearable Sensor Data의 복잡한 패턴을 요약하는 데 유용하다는 점이 입증됨. </li>
<li> 특히, TDA의 핵심 기술인 Perisstence Homology는 데이터의 위상적 특성을 분석하여 중요한 구조를 포착하는 데 사용됨. </li>
<li> 그러나 TDA와 KD를 결합한 연구는 제한적이며, 특히 Data Noise에 대한 Robustness에 대한 논의가 부족하다. </li>
</ul>
<li> 연구 목표 </li>
<ul>
<li> 본 연구에서는 Topological Persistence를 활용하여 KD의 Robustness를 강화하는 방법을 제안한다. </li>
<li> TDA기반 Feature Extraction이 KD에서 효과적인가? </li>
<li> Topological Feature가 노이즈나 데이터 변동에 얼마나 Robustness한가? </li>
</ul>
<li> 기여 </li>
<ul>
<li> 웨어러블 센서 데이터의 특성을 반영한 TDA-KD 프레임워크 개발 </li>
<li> 데이터 노이즈에 Robustness한 KD 프로세스를 설계함. </li>
<li> Topological Feature를 활용해 모델 성능을 개선하고, 데이터 효율성을 높인다. </li>
</ul>

### Background - Key Factors in PErformance of Time Series Data Analysis
<li> 데이터 품질 </li>
<ul>
<li> 웨어러블 센서 데이터는 다양한 외부 요인(환경적 변화, 측정 오류)으로 인해 노이즈가 많다. </li>
<li> 노이즈를 적절히 처리하지 않으면 분석 결과가 왜곡될 수 있다. </li>
</ul>
<li> 데이터의 동적 특성 </li>
<ul>
<li> 시간적 상관성 : Time-series data는 시간 축을 따라 상관관계를 가지며, 이전 상태가 현재 상태에 영향을 미친다. 이를 모델링하지 않으면 중요한 패턴을 놓칠 수 있다. </li>
<li> 비정상성 : Wearable Sensor Data는 시간에 따라 분포가 변하는 경우가 많다. 환경 조건이나, 활동 유형이 달라진다. </li>
</ul>
<li> 데이터 표현 </li>
<ul>
<li> 고차원성 : 시계열 데이터는 여러 센서에서 동시에 수집되므로 고차원 데이터를 다뤄야 한다. </li>
<li> 의미 있는 특징 추출 : 원시 데이터에서 유용한 정보를 추출하는 것이 성능을 좌우한다. (TDA) </li>
</ul>
<li> 계산 효율성 </li>
<ul>
<li> 실시간 처리 요구 : Wearable Sensor Data는 종종 실시간 처리가 요구된다. </li>
<li> 복잡한 모델은 정확도는 높지만, 계산 비용이 커서, 경량화된 모델을 설계하는 것이 중요하다. </li>
</ul>

### Method
<li> 1. Leveraging PIs With a Single Teacher </li>
<ul>
<li> 지식 증류 과정에서 단일 Teacher를 활용하여 Topological Knowledge를 Student에게 전이 </li>
<li> Teacher는 time-series 데이터의 원시 데이터를 TDA를 통해 PI로 변환한 후 학습 </li>
<li> 출력 logits을 비교하여 student에 지식을 전이해준다. </li>
</ul>
<li> 2. Leveraging PIs With Multiple Teachers </li>
<ul>
<li> 여러 Teacher를 활용하여 지식을 Student 모델에 전이함. </li>
<li> Teacher모델들은 각각 시계열 데이터와 PI를 독립적으로 학습하고, 그 결과를 단일 Student로 전달함. </li>
<li> 여기서는 두 Teacher에게 모두 KL-Divergence Loss를 각각의 가중치를 두어 더하게 됨. </li>
<li> 그런데, 여기서 Teacher들이 다른 데이터(PI와, time-series)를 학습하면, 스타일이 달라서 지식 간 충돌이 발생할 수 있다. 그래서 3번째 밑에게 나옴. </li>
</ul>
<li> 3. Intermediate Representation and Annealing Strategy </li>
<ul>
<li> Teacher와 Student가 서로 다른 네트워크 구조나, Modality를 가진다면, 지식의 불일치가 발생함. </li>
<li> 이를 위해 Intermediate Representation을 활용하고, Annealing Strategy를 적용함. </li>
<li> Teacher 모델들의 중간 계층의 Activation Map을 가중치 합으로 병합하여 Student에게 전달함. </li>
<li> 그렇게 합쳐진 값과 학생 모델의 Activation Map의 가중치 합을 비교하는 loss항이 추가된다. </li>
</ul>



## Trainning Environment
<li> Dataset = Cifar10, CINIC10, Tiny ImageNet </li>
<li> python = 3.8.18 </li>
<li> pytorch = 2.4.1 + CUDA ??? </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 20 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.0005 </li>
<li> optimizer = Adam </li>



## Evaluation


## Results