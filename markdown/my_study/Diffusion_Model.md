## Diffusion Model
- Diffusion Model이란?
    * 복잡한 데이터를 노이즈로 변환한 뒤, 그 노이즈를 점진적으로 복원하는 방식으로 새로운 데이터를 생성하는 모델임.
    * 즉, 천천히 망가뜨린 뒤, 다시 복원하는 과정을 학습하는 모델이다.

- 왜 Diffusion Model이 고안되었나
    * GAN은 Generator와 Discriminator가 서로 경쟁하는 구조인데, 학습 도중 균형이 무너지면 문제가 생김.
        - Mode Collapse : Generator가 Discriminator를 속이기 위해서 몇 가지 특정한 이미지 패턴만 생성하게 되는 현상
        - 다양성이 없어지고, 모든 z에 대해 비슷한 이미지만 나오게 됨.
        - 전혀 참신하지 않은 생성형 AI인 것임.
    * 또한 GAN은 Latent Space가 구조화되지 않는다.
        - GAN에서는 기본적으로 noise vector z ~ N(0, 1)로 시작을 하는데, 이 z는 단지 랜덤한 입력일 뿐 z1 과 z2가 어떤 차이가 있는지 구조적으로 알 수가 없음.
        - 그래서 z를 잘 학습해서 조절하면 강아지를 그린다거나 하는 기술을 적용하기 어렵다.
    * VAE는 학습할 때 재구성 손실로 MSE나 BCE를 사용함.
        - 그래서 픽셀 단위로 평균적인 이미지를 만드는 경향이 있다.
        - 그렇게 되면 이미지가 전체적으로 blur 처리된 것 처럼 뿌연 느낌이 나타나게 됨.
    * 그래서 Diffusion Model은 GAN과 다르게 참신한 이미지를 만들어낼 수 있고, VAE와 다르게 고품질의 이미지를 만들어낼 수 있도록 하기 위해서 고안되게 되었다.

- Diffusion Model의 작동 방식
    * Forward Process
        - 입력 이미지 x_0에 점점 노이즈를 추가해서 x_1, x_2, ..., x_t로 만든다.
        - 마지막엔 거의 순수한 Gaussian 노이즈로 바뀌게 됨.
        - t는 몇 단계에 걸쳐서 이미지에 노이즈를 추가할 지를 정하는 하이퍼파라미터
        - t가 클 수록 이미지가 더 천천히, 부드럽게 파괴되고, 복원이 쉽다. 하지만, 복원(reverse)도 t번 번에 걸쳐서 진행되기 때문에 생성 속도가 느려진다.
        - 밑의 수식의 Beta는 얼마나 강하게 노이즈를 넣을 지를 의미하고, 당연히 클 수록 노이즈가 빡시게 들어간다.
        <img src="https://github.com/wjdwocks/ML-DNN/raw/main/markdown/25년/Study/Diffusion_Model/Noising.png" alt="no_grad" width="700">
    * Reverse Process
        - x_t ~ N(0, I) 에서 시작해서, 거꾸로 가며 이미지를 복원하는 과정을 학습한다.
        - 사실상 이 과정에서 노이즈된 이미지를 복원하는 것을 학습한다.
        - 실제로 각 단계별로 포함된 노이즈 ϵ을 예측하는 방식으로 학습이 진행된다.

- Diffusion Model의 강점
    * GAN보다 훨씬 세밀하고, 안정적인 이미지를 생성할 수 있다.
    * 판별기가 없어서 더 다양한 이미지를 생성할 수 있다.
    * latent space를 구조적으로 생성하여 다양한 제어 조건 삽입이 가능하다.
    * 영상, 음성, 3D 등 다양한 생성 분야로 확장이 가능하다.