## Baselineìœ¼ë¡œ ì‚¬ìš©í• ë§Œ í•œ ë‹¤ì–‘í•œ Multi Modal KD ê¸°ë²•ë“¤ ì •ë¦¬
### 1. AVER (Averaged KD)

* ì—¬ëŸ¬ Teacherì˜ logit ì¶œë ¥ì„ ë‹¨ìˆœ í‰ê· í•œ í›„, Studentê°€ ì´ë¥¼ í•™ìŠµí•˜ë„ë¡ ìœ ë„
* íŠ¹ì§•: êµ¬í˜„ì´ ë‹¨ìˆœí•˜ê³  baseline ì„±ê²©ì´ ê°•í•¨
* Sig, GAF, PIì˜ Teacher logitì„ í‰ê· í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥

```python
avg_teacher_logits = (logits_sig + logits_gaf + logits_pi) / 3
loss_kd = KL(student_logits, avg_teacher_logits)
```

### 2. ESKD (Early Stopped KD)

* í•™ìŠµì„ í•  ë•Œ Accê¸°ì¤€ìœ¼ë¡œ ì¢‹ì•„ì¡Œì„ ë•Œì˜ ëª¨ë¸ì„ ì €ì¥í•˜ê³ , ê°€ì¥ ì¢‹ì•˜ë˜ ì‹œì ì˜ ëª¨ë¸ì„ ì‚¬ìš©
* Full KDëŠ” í•­ìƒ ì§€ì •í•œ Epochì´ ëë‚œ í›„ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê³¼ì í•© ìƒíƒœê°€ ë  ìˆ˜ ìˆìŒ

### 3. CAMKD (Class Activation Map Knowledge Distillation)

* CNN ê¸°ë°˜ Teacherì™€ Student ê°„ì˜ CAMì„ ë¹„êµí•˜ì—¬, ì‹œê°ì  ê·¼ê±°ë¥¼ Distillationí•´ì¤Œ.
* GAF, PIëŠ” ì´ë¯¸ì§€ ê¸°ë°˜ì´ë¯€ë¡œ CAM ìƒì„± ê°€ëŠ¥
* Studentì˜ ì´ë¯¸ì§€ branchê°€ ì¡´ì¬í•´ì•¼ í•¨
* ì½”ë“œê°€ ìˆëŠ”ì§€ ëª¨ë¥´ê² ë‹¤.

```python
feat_t_gaf = teacher_gaf.get_feature(x_gaf).detach()
feat_s_gaf = student.get_feature_gaf(x_gaf)
cam_t = get_cam(feat_t_gaf, teacher_gaf.fc[y]) # ì—¬ê¸°ì„œ CAMì„ ì–»ì–´ë‚´ê³ 
cam_s = get_cam(feat_s_gaf, student.fc[y])
loss_cam = MSE(cam_t, cam_s) # ì—¬ê¸°ì„œ ë‘˜ì„ MSEë¡œ ë¹„êµí•´ì„œ Loss ê³„ì‚°
```

ì „ì²´ Loss ì˜ˆì‹œ:

```python
loss_total = lambda1 * ce_loss + lambda2 * KD_loss + lambda3 * cam_loss
```

### 4. EBKD (Evidence-Based Knowledge Distillation)

* Teacherì˜ íŒë‹¨ ê·¼ê±° (evidence, CAM ë˜ëŠ” attention map ë“±)ë¥¼ Studentì—ê²Œ ì „ë‹¬
* Cross-modalí•˜ê²Œ evidenceë¥¼ í†µí•©í•˜ì—¬ ë¹„êµí•˜ëŠ” ê²ƒë„ ê°€ëŠ¥

```python
attn_sig = teacher_sig.get_attention(x_sig).detach()
cam_gaf = teacher_gaf.get_cam(x_gaf).detach()
student_attn = student.get_cross_attention(x_sig, x_gaf)
loss_ebkd = MSE(student_attn, fuse(attn_sig, cam_gaf))
```

### 5. Enhancing Time Series Anomaly Detection: A KD Approach (2024)

* ì‹œê³„ì—´ ì´ìƒíƒì§€ ì „ìš© KD ê¸°ë²•
* Logit ëŒ€ì‹  hidden featureë¥¼ ì§ì ‘ Studentì— ì „ë‹¬
* ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ ëª©ì , íŠ¹íˆ Sig branch í•™ìŠµì— ìœ ë¦¬í•¨

```python
loss_feature_kd = MSE(student.hidden_vec, teacher_sig.hidden_vec.detach())
```

### 6. Progressive Cross-modal KD for HAR (2022)

* Human Activity Recognition(HAR) íŠ¹í™” Cross-modal KD
* ì ì§„ì  ì „ì´ êµ¬ì¡°: Sig -> Image, Image -> Sig, ìµœì¢… shared representation í•™ìŠµ
* ê° ë‹¨ê³„ë³„ë¡œ Teacher â†’ Student ê°„ feature ì „ì´

```python
loss_kd_sig2img = MSE(student_img_feature, teacher_sig_feature.detach())
loss_kd_img2sig = MSE(student_sig_feature, teacher_img_feature.detach())
```

### Frequency Attention for Knowledge Distillation, 2024.3.9

---

## ğŸ“˜ ë…¼ë¬¸ ìš”ì•½

- ë³¸ ë…¼ë¬¸ì€ Knowledge Distillation(KD)ì„ ìˆ˜í–‰í•  ë•Œ, **ì£¼íŒŒìˆ˜ ë„ë©”ì¸(Frequency Domain)** ì—ì„œ Attentionì„ ì ìš©í•˜ì—¬ Teacherì˜ ì „ì—­ì ì¸ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ Studentì—ê²Œ ì „ë‹¬í•˜ëŠ” ê¸°ë²•ì„ ì œì•ˆí•œë‹¤.
- íŠ¹íˆ, ê³µê°„ ë„ë©”ì¸(spatial domain)ì´ ì•„ë‹Œ **Fourier ì£¼íŒŒìˆ˜ ë„ë©”ì¸ì—ì„œ Attentionì„ ìˆ˜í–‰**í•˜ì—¬, ë” ë„“ì€ ë¬¸ë§¥ ì •ë³´(ì—£ì§€, íŒ¨í„´, ë°˜ë³µ êµ¬ì¡° ë“±)ë¥¼ í¬ì°©í•˜ëŠ” ê²ƒì´ í•µì‹¬ ì•„ì´ë””ì–´ë‹¤.
- ì´ëŸ¬í•œ ë°©ì‹ì€ ê¸°ì¡´ KDì—ì„œ í”íˆ ì‚¬ìš©ë˜ëŠ” MSE ë˜ëŠ” feature mimic ë°©ì‹ë³´ë‹¤ ë” íš¨ê³¼ì ìœ¼ë¡œ ë™ì‘í•˜ë©°, ë‹¤ì–‘í•œ Teacher/Student êµ¬ì¡°ì— ì ìš© ê°€ëŠ¥í•˜ë‹¤.
- ì—¬ê¸°ì—ì„œ ë‚˜ëŠ” Signal, Imageì˜ ë©€í‹°ëª¨ë‹¬ ë°©ì‹ì´ë¯€ë¡œ, Featureë¥¼ (batch, Channel, Window) -> (batch, Channel, Window, Window) ì—ì„œ, Window í¬ê¸°ë¥¼ Imageì˜ Widthì™€ Heightë¡œ ë§ì¶°ì£¼ë©´ ì ìš©í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.

---
## ê³µê°„ ë„ë©”ì¸ê³¼ ì£¼íŒŒìˆ˜ ë„ë©”ì¸
- ì£¼íŒŒìˆ˜ë€ : ì–´ë–¤ ì‹ í˜¸ì—ì„œ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ê°’ì´ ë°”ë€ŒëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°œë…ì´ë‹¤.
- ëŠë¦° ë³€í™” : ë°°ê²½, í° ë¬¼ì²´ì˜ ìœ¤ê³½ ë“± -> ì €ì£¼íŒŒ
- ë¹ ë¥¸ ë³€í™” : ì—£ì§€, í…ìŠ¤ì²˜, ì‘ì€ ë””í…Œì¼ ë“± -> ê³ ì£¼íŒŒ
- ê³µê°„ ë„ë©”ì¸ : ì›ë³¸ ì´ë¯¸ì§€, ì‹œê³„ì—´ì˜ ì§ì ‘ì ì¸ í”½ì…€ ê°’
- ì£¼íŒŒìˆ˜ ë„ë©”ì¸ : ì´ë¯¸ì§€, ì‹œê³„ì—´ì˜ êµ¬ì„± ì„±ë¶„ì„ ì£¼ê¸°ì  ì‹ í˜¸ë“¤ë¡œ ë¶„í•´í•œ ê°’
- Fourier ë³€í™˜ì´ë€ : ì‹ í˜¸ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì‚¬ì¸íŒŒì˜ í•©ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ê²ƒ.
- ì´ Fourier ë³€í™˜ì„ ì´ìš©í•´ì„œ ì¤‘ê°„ Layerì˜ Feature Mapì„ ì£¼íŒŒìˆ˜ ë„ë©”ì¸ì—ì„œì˜ Feature Mapìœ¼ë¡œ ë³€í™˜í•˜ê³ , Teacherì™€ì˜ Attentionì„ ìˆ˜í–‰í•˜ê³  Studentë¥¼ ë³€í™˜í•œ ë’¤, Teacherì™€ì˜ ì£¼íŒŒìˆ˜ ë„ë©”ì¸ì—ì„œì˜ Feature Mapê³¼ MSEë¥¼ í†µí•´ Lossë¥¼ ê³„ì‚°í•œë‹¤.

---

## ğŸ§  ì£¼ìš” êµ¬ì„± ìš”ì†Œ

### 1. Frequency Attention Module (FAM)

- FAMì€ ì£¼íŒŒìˆ˜ ë„ë©”ì¸ìœ¼ë¡œ ë³€í™˜í•œ featureì— **í•™ìŠµ ê°€ëŠ¥í•œ í•„í„°ë¥¼ ì ìš©**í•˜ì—¬, Studentì˜ featureë¥¼ Teacherì˜ ë°©í–¥ìœ¼ë¡œ ì •ë ¬(ìœ ë„)í•˜ëŠ” ì—­í• ì„ í•œë‹¤.
- êµ¬ì„± íë¦„:
  1. `torch.fft.fft2()`ë¥¼ ì‚¬ìš©í•´ ì…ë ¥ featureë¥¼ ì£¼íŒŒìˆ˜ ë„ë©”ì¸ìœ¼ë¡œ ë³€í™˜
  2. ë³µì†Œìˆ˜ í•„í„°(`weights1`)ë¥¼ ì´ìš©í•œ í•™ìŠµ ê°€ëŠ¥í•œ convolution ì—°ì‚° ìˆ˜í–‰
  3. ì¤‘ì‹¬ ì£¼íŒŒìˆ˜ ì œê±°(Masking)ë¡œ ê³ ì£¼íŒŒ ê°•ì¡°
  4. `ifft2()`ë¡œ ë‹¤ì‹œ ê³µê°„ ë„ë©”ì¸ìœ¼ë¡œ ë³µì›
  5. ë³´ì¡° ë¶„ê¸°(`1x1 conv`)ì™€ ì¡°í•©í•˜ì—¬ ìµœì¢… attention feature ìƒì„±

---

## ğŸ” ì½”ë“œ ê¸°ë°˜ ë™ì‘ íë¦„

```python
x_ft = torch.fft.fft2(x, norm="ortho")  # FFT2D ìˆ˜í–‰
out_ft = self.compl_mul2d(x_ft, self.weights1)  # í•™ìŠµ ê°€ëŠ¥í•œ ë³µì†Œìˆ˜ í•„í„° ê³±
batch_fftshift = batch_fftshift2d(out_ft)  # ì¤‘ì‹¬ ì´ë™
# ì¤‘ì‹¬(low freq) ë§ˆìŠ¤í‚¹
batch_fftshift[:, :, cy-rh:cy+rh, cx-rw:cx+rw, :] = 0
out_ft = batch_ifftshift2d(batch_fftshift)
out_ft = torch.view_as_complex(out_ft)
out = torch.fft.ifft2(out_ft, norm="ortho").real  # ë³µì›
```


### CRD - 2024, 