## 24.11.13 공부할 내용
<li> Resnet의 Bottleneck 구조에 대해 더 깊은 공부 + Resnet 51을 구현한 코드를 보고 이해. </li>
<li> 교수님이 읽으라고 하신 논문 두 부에 대해 충분한 이해를 하고 가자. </li>
<li> 저번 주 논문 중 18번 Reference의 ESKD에 대한 논문을 읽고 이해해보자. </li>


## 논문 주요 내용 (배경지식)
### 기존의 KD의 loss
<ol>
<li> logits이란? </li>
<ul>
<li> 모델의 마지막 층에서 나오는 출력으로, 각 클래스에 대해 예측한 '점수'를 의미한다. </li>
<li> 이 점수는 아직 정규화되지 않은 상태이고, softmax를 적용하면 확률 분포로 변환된다. </li>
</ul>
<li> logit을 이용한 지식 전달 </li>
<ul>
<li> 지식 증류에서 교사 모델의 logit은 단순한 정답이 아닌, 클래스 간의 "미묘한 관계"를 나타내는 정보로 간주된다. </li>
<li> 예를 들어, 어떤 이미지가 고양이일 확률이 0.8이고, 개일 확률이 0.15, 새일 확률이 0.05라면, 교사 모델은 "이 이미지는 고양이에 가깝지만, 개일 가능성도 약간 있다"고 예측한 것임. </li>
<li> 학생 모델은 이러한 클래스 간의 유사성 정보를 배우게 되고, 단순히 정답을 맞추는 것보다도 더 깊은 클래스 간의 관계도 학습하게 된다. </li>
</ul>
<li> 지식 증류에서의 logit 전달 방식 </li>
<ul>
<li> 교사 모델이 생성한 logit을 student 모델의 학습 손실에 포함시켜, 학생 모델이 이 값을 따라가도록 유도한다. </li>
<li> logit 손실(KL Divergence loss) = (a)KL(교사 모델의 logit, 학생 모델의 logit) 으로 표현하는데 이는 두 모델의 출력 분포 간의 차이를 계산하는 식이다. </li>
</ul>
<li> 학생 모델은 두 가지 손실을 통해 학습한다. </li>
<ul>
<li> 일반적인 손실 : 학생 모델이 정답 라벨과 가까운 예측을 하도록 유도하는 손실 (Cross-entropy loss) </li>
<li> 지식 증류 손실 : 교사 모델의 logits을 따라가도록 유도하는 손실 (Distillation loss) </li>
</ul>
</ol>

![KD_loss](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/KD_lossfunc_KL.png)

### AMD loss
<li> 양성 특징(타겟 객체)와 음성 특징(background) 간의 각 거리(Angular Distance)를 사용하여 특징을 학습한다. </li>
<li> 이 때 특징들을 고차원 구(hypersphere)에 투영하여, 기존의 많은 특징 추출기에서 볼 수 있는 유사한 각 분포를 활용하는 방식이다. </li>
<li> AMD Loss의 작동 원리와 주요 개념 </li>
<ol>
<li> 고차원 구 투영(embedding) </li>
<ul>
<li> 특징 벡터를 고차원 구에 투영하여 학습함. 이를 통해 모델이 각도를 기준으로 양성과 음성 특징을 구분하게 하며, 특징의 방향성에 기반한 학습이 가능해짐. </li>
<li> 구에 투영된 특징 벡터는 방향성에 따라 가까운 특징(양성 특징)은 비슷한 각도로 유지하고, 먼 특징(음성 특징)은 더 큰 각도로 떨어지도록 유도한다. </li>
</ul>
<li> 양성 특징에 각 마진(angular margin) 추가 </li>
<ul>
<li> 양성 특징에 각 마진을 추가하여 더 집중된 특징 벡터를 만든다. 이 마진은 양성 특징 벡터를 구상에서 특정 각도로 모이게 하여, 모델이 중요한 특징을 더 뚜렷하게 구분할 수 있도록 한다. </li>
<li> 이로 인해 양성 특징 벡터는 구 내부에서 밀집된 각도 분포를 가지게 되며, 음성 특징과의 거리가 더 커져 모델이 쉽게 구분할 수 있다. </li>
</ul>
<li> 특징의 각 분포(angular distribution) </li>
<ul>
<li> 많은 특징 추출기에서 양성 특징은 특정 각도에 모여 있는 경향이 있다. AMD Loss는 이러한 특징을 활용하여 양성과 음성 특징 간의 각도를 명확하게 분리하며, 양성 특징은 좁은 각도 분포에 집중시키고 음성 특징은 더 넓은 각도 분포로 분리되도록 한다. </li>
</ul>
</ol>


### Spherical Embedding을 활용하여 KD를 개선하는 방안
<ol>
<li> 활성화된 특징을 얻기 위해 공간 주의(spacial attention) map을 계산하고, 양성 맵과 음성 맵으로 분리함. </li>
<ul>
<li> spacial attention map : 모델이 주목해야 할 영역 </li>
<li> 목적 : 모델이 학습하는 동안 더 중요한 특징에 집중하도록 유도하기 위함. </li>
<li> 방법 : 이미지나 데이터에서 spatial attention map을 계산함. </li>
<li> 이 spatial attention map을 positive map과 negative map으로 나눈다. </li>
<li> 모델이 주목해야 하는 활성화된 영역이 positive map, negative map은 덜 중요한 정보를 의미함. </li>
</ul>
<li> 특징을 고차원 구(hypershpere)에 투영하여 각도 거리(angular distance)를 반영하게 함. </li>
<ul>
<li> angular distance :  </li>
<li> 목적 : 지식 증류 과정에서 모델이 특징 간의 각도 차이를 인식하게 하여 더 나은 표현 학습을 유도하는 것. </li>
<li> 방법 : spatial attention map에서 얻은 positive map(특징)을 고차원 구에 투영한다. </li>
<li> 이 과정을 통해 특징 간의 관계를 각도(angular distance)로 나타낼 수 있다. </li>
<li> 효과 : 고차원 구 임베딩을 통해 특징 간의 각도 차이가 반영되므로, 특징 간의 유사성과 차이가 명확하게 나타난다.  </li>
</ul>
<li> 양성 특징에 각 마진(angular margin)을 추가하여 더 집중된(attentive) 특징 표현 생성 </li>
<ul>
<li> 목적 : 학생 모델이 교사 모델이 주목하는 중요한 특징에 더 집중하게 유도하는 것. </li>
<li> 방법 : 양성 특징에 각 마진(angular margin)을 도입하여, 특징들이 특정 각도로 더 밀집되도록 만든다. 이로 인해 양성 특징은 더 집중된 형태로 표현된다. (같은 클래스의 특징들이 더 비슷한 방향을 가지도록 유도.) </li>
<li> 효과 : 양성 특징이 더 집중된 분포를 가지게 되어, 모델이 중요한 정보에 더 주목하게 된다. 이렇게 특징 표현을 해서, 모델이 특정 객체나 중요한 정보를 더 잘 인식하고 구별할 수 있음. </li>
</ul>
<li> 증류 과정에서 학생 모델이 교사 모델의 더 분리된 결정 영역(decision regions)을 모방하여 분류 성능이 향상됨. </li>
<ul>
<li> 목적 : 학생 모델이 교사 모델의 결정 경계(deicision boundary)를 모방하여 더 좋은 분류 성능을 가지게 한다. (특정 지점을 기준으로 각도 차이가 작다면, 같은 클래스에 속하고, 각도가 크다면 서로 다른 클래스에 속한다. 이 각도 차이를 기준으로 결정 경계를 설정함.) </li>
<li> 방법 : 지식 증류 과정에서 학생 모델이 교사 모델의 more separated된 decision boundary를 모방하도록 학습시킨다. </li>
<li> 이렇게 하여 교사 모델이 특징 간의 구분을 명확히 하고, 더 높은 정확도로 클래스를 예측하는 것을 따라갈 수 있게 한다. </li>
<li> 효과 : 학생 모델은 교사 모델의 Decision Boundary를 모방함으로써, 더 나은 분류 성능을 발휘하게 된다. </li>
<li> 학생 모델이 교사 모델의 결정 경계를 모방한다는 것은, 학생 모델이 교사 모델이 설정한 클래스 간의 구분 방식과 결정 경계를 따라가도록 학습한다는 것임. </li>
<li> Angular Margin과 KL-divergence 손실을 함께 사용하여, 학생 모델이 교사 모델과 유사한 방향성과 각도를 가진 특징 벡터를 학습하도록 만든다. </li>
<li> 학생 모델이 교사 모델의 각도 분포와 특징 간의 거리(angular distance(두 벡터가 이루는 각도))를 학습함으로써, 교사 모델이 가진 결정 경계와 유사한 경계를 형성하게 됨. </li>
</ul>
<li> 이 Shperical Embedding방식에서의 특징 표현 규제(regularizatino) </li>
<ul>
<li> 목적 : 전체적으로 학생 모델이 교사 모델의 유용한 정보를 더 잘 학습하도록 만든다. </li>
<li> 방법 : 제안된 방법을 통해 학생 모델의 특징 표현이 교사 모델처럼 정보가 풍부하고 중요한 특징을 포함하도록 규제한다. </li>
<li> 효과 : 학생 모델이 교사 모델의 중요한 정보를 효과적으로 학습하여, 더 높은 성능을 발휘할 수 있다. 교사 모델의 표현력을 학생 모델이 닮아가도록 학습하는 과정이므로, 학생 모델이 더 좋은 특징을 학습하고, 최종 성능이 향상됨. </li>
<li> Angular Margin을 추가함으로써, 같은 클래스의 특징 벡터들이 서로 더 가까운 방향을 가리키도록 제약을 주는 것임. </li>
<li> 손실 함수에 Angular Margin을 추가하여, 같은 클래스의 벡터들이 일정한 각도 이상으로 더 가까워져야 손실이 줄어들도록 학습을 진행한다. </li>
</ul>
</ol>

## Abstract 정리
<ol>
<li> KD는 네트워크를 경량화하고, 메모리효율적으로 만들어 주었다. </li>
<li> 교사 모델은 pre-trained 모델을 주로 사용하고, Pre-Trained 모델은 이미 학습된 상태로 제공되는 모델을 의미함. (즉, 오픈소스 활용이 가능한 대규모 데이터셋에서 학습이 완료된 모델을 말하는 듯.), 즉, 이미 학습된 가중치를 가지고 나의 Domain에 맞춰서 미세하게 가중치를 조정해주면 됨. </li>
<li> Pre-Trained Model의 반대로는 From Scratch Model 이라고 해서 내가 어떤 특수한 도메인에서 사용하고자 할 때 처음부터 학습을 시켜서 만드는 모델을 말한다. </li>
<li> 이 논문에서는 기존의 KD와 다르게, 중간 층의 Feature Map을 Knowledge Distillation의 source로 사용하여 교사 네트워크의 지식을 학생 네트워크로 전달한다. </li>
<ul>
<li> 중간 층의 Feature Map은 입력 데이터의 저차원 특징(간단한 엣지, 패턴)부터, 고차원 특징(객체의 형태, 구조)까지 다양한 정보를 포함하고 있다. </li>
<li> 즉, 중간층의 특징 맵을 활용하면, 학생 네트워크가 교사 네트워크의 다층적인 특징 표현을 학습하게 되어서, 더 나은 일반화 성능을 기대할 수 있다. </li>
<li> 최종 출력만으로는 클래스에 대한 확률 분포 정도만 전달할 수 있지만, 중간층의 특징 맵을 사용하면 객체의 구체적인 세부 정보와 구조를 학생 모델이 학습할 수 있다. </li>
<li> 특히 객체의 위치, 모양, 텍스처 등의 세밀한 정보가 중간층의 특징 맵에 포함되어있다. </li>
<li> 즉, 중간 층의 Feature Map을 이용한 Distillation은, 학생 모델이 중간층의 Feature Map을 모방하도록 유도하여, 교사 모델의 내재된 표현 능력까지 학습하게 된다. </li>
<li> 이 중간층 Feature Map을 이용하는 KD(Intermediate Layer Distillation)에서의 손실 함수는 L2손실이라고 해서, 교사 모델과 학생 모델의 대응하는 중간층 Feature Map 간의 차이를 줄이는 손실함수이다. </li>
</ul>
</ol>

## Introduction

## BackGround
### Knowledge Distillation
<li> 두 가지의 접근 방식으로 나뉘었었다. </li> 
<ol>
<li> Response-based KD : 교사 모델의 최종 출력을 사용하여 학생 모델이 이 출력을 모방하도록 loss를 작성함. (KL-divergence로 교사 모델의 출력 분포를 모방하게 하고, Softmax를 통해 정답 값의 손실을 비교.) </li>
<li> Feature-based KD : 교사 모델의 중간층에서 추출한 특징(특징or 특징맵)을 사용하여 학생 모델이 이를 학습하게 하는 방식. (중간 층에서의 feature map을 normalization하여 학생이 교사 모델의 중간층 표현을 모방하도록 한다.) </li>
</ol>

### Feature-based Method in KD
<li> 목적 : 교사 모델의 Attention Map을 추출하고, 이를 학생 모델에 전달하여 학생 모델이 동일한 Attention Pattern을 학습하게 하는 것이다. </li>
<li> AT - Zagoruyko의 접근 방식 </li>
<ul>
<li> 교사 모델은 Sum of Squared Attention Mapping Function을 사용하여 Attention Map을 계산한다. </li>
<li> 이 방식은 교사 모델의 Feature Map을 각 채널별로 값들을 제곱하고, 결과들을 합산하여 하나의 Attention Map을 생성한다. </li>
<li> 즉, 하나의 Feature Map은 (높이 x 너비 x 채널) 의 3차원 구조인데, 각 채널에 포함된 값(높이 x 너비)들을 제곱한 다음, 모든 채널에 대해 합산(sum)을 하여 하나의 2차원 Attention Map으로 생성하는 것을 의미함. </li>
<li> 이렇게 수행하는 이유는 각 특성맵에 포함된 값들은 값이 클 수록 집중해서 봐야 할 값이라고 여겨지기 때문이다. (ex) 우리가 pooling을 수행할 때에 Maxpooling을 주로 사용하는 이유와 같다.) </li>
</ul>
<li> 이렇게 생성된 교사 모델의 Attention Map을 학생 모델의 중간 층 Feature Map과 Mapping하여 학생 모델이 교사 모델의 Attention Pattern을 모방하게 한다. </li>
<ul>
<li> 일단 학생 모델의 중간 층에서 Feature Map을 추출함. (교사 모델의 특정 층에서 얻은 Feature Map과 비슷한 위치에 있는 학생 모델의 층에서 Feature Map을 추출함.) </li>
<li> 교사 모델과 동일한 방법으로 학생 모델의 Feature Map을 Attention Map으로 변환한다. (두 Attention Map을 비교할 수 있게 하기 위함.) </li>
<li> 일반적으로, 교사 모델의 주의 맵과 학생 모델의 주의 맵 사이의 L2손실을 계산하여, 두 맵이 최대한 비슷해지도록 학습을 수행하게 된다. </li>
<li> 즉, 위의 Attention Map Loss를 기존의 다른 손실 함수들에 추가적으로 항을 더해서 최종 손실에 포함시키면, 모델 학습 과정에서 이 Attention Pattern을 같이 고려하도록 되는 것이다. </li>
</ul>
<li> 이 논문에서 제안한 새로운 접근 방식 </li>
<ul>
<li> 기존의 AT 방식에서 더 나아가, 교사 모델의 Positive Map과 Negative Map을 구분하는 능력까지도 학생 모델에 이식하는 것이 목표이다. </li>
<li> 먼저, 교사 모델이 Positive map과 Negative Map을 생성한다. </li>
<li> 이 과정은 보통 객체의 위치나, 예측과 관련된 특징을 통해 Positive, Negative Map을 정의한다. </li>
<li> 학생 모델도 양성, 음성 맵을 생성하게 한 뒤, 두 값의 차이를 줄이는 손실함수를 만들어 통합한다. </li>
</ul>

### Spherical Feature Embedding
<li> 기존 방법의 한계 </li>
<ul>
<li> 기존에는 유클리드 거리를 기반으로 특징을 구분했다. </li>
<li> 하지만 이 접근법은 open-set 환경에서 클래스 간의 명확한 구분이 어렵다는 한계를 가지고 있음. </li>
<li> Open-set 환경은 모델에 훈련되지 않은 새로운 클래스가 테스트 데이터에 포함될 수 있는 환경을 의미함. 즉, closed-set 환경은 모델이 훈련된 클래스와 동일한 클래스들로만 test-set이 구성되고, open-set 환경은 모델이 처음 보는 클래스의 샘플도 predict를 수행해야 하는 경우가 있다. </li>
<li> ex) 개와 고양이 사진을 학습해서 분류하다가 갑자기 새 사진이 나와버린 경우. </li>
<li> 그렇기 때문에 Open-set 환경에서는 intra-class distance(같은 클래스 내에서의 최대 거리)를 줄여서, 같은 클래스 샘플들이 feature space에서 서로 더 가까이 모이도록 학습을 해야 한다. 왜냐하면, 같은 클래스에 속하는 샘플들이 서로 밀집된 cluster를 형성하게 되어, 모델이 새로운 클래스의 샘플을 기존 클래스와 구분하기가 더 쉬워지기 때문. </li>
</ul>
<li> A-Softmax (angular-softmax) 도입 </li>
<ul>
<li> 특징 벡터는 Attention Map이나, Positive Map을 통해 강조된 Feature Map을 정규화(flatten 등)를 통해 특징 벡터로 변환한 것이다.
<li> A-softmax 함수는 특징 벡터 간의 각도 기반 Margin 을 증가시켜 특징을 구분한다. </li>
 </li>
<li> 즉, 특징 벡터들이 고차원 구 위에서 더 넓은 각도 차이를 가지도록 학습시켜 클래스 간의 구분을 더 명확히 한다. </li>
<li> 각도 기반 Margin을 증가시킨다는 것은 같은 클래스인 특징 벡터들이 비슷한 방향성을 갖도록 유도하는 것이다. </li>
<li> 특징 벡터의 시점은 큰 관계가 없고, 방향만 관계가 있는듯. </li>
<li> 특징 벡터들이 고차원 구 위에 투영되면, 그것을 A-softmax를 이용하여 최종 예측을 수행하는 것이다. </li>
<li> 이러한 방식이 Open-set 환경에서 유리한 이유는, 다른 클래스와의 각도 차이가 명확하게 확보되기 때문에, 학습되지 않은 unknown class의 샘플이 들어오면, 기존 클래스들과 쉽게 구분할 수 있다. </li>
</ul>
<li> AMC-loss를 이용한 각도 기반의 Margin Penalty </li>
<ul>
<li> A-softmax와 AMC-loss 모두 각도 기반의 Margin Penalty를 활용하여 고차원 구 위에서 특징을 더 잘 구별하도록 만든다. </li>
<li> 즉, 지금까지 특징들을 가지고 classification을 했다면, 여기서는 특징들을 이용해 특징 벡터를 만들고, 이를 고차원 구에 투영하여 비교를 해서 예측을 수행하는데, 이 때 기존의 softmax로 최종예측을 하는 것이 아닌, A-softmax와, AMC loss를 사용한다고 보면 된다. </li>
<li> AMC-loss는 Angular Margin based Contrastive Loss로, 이 또한 고차원 구에서의 Geodesic 거리를 기반으로 각도 기반 Margin Penalty를 활용하여 같은 클래스 내의 응집성을 향상시킨다. </li>
<li> 어떻게 하는지는 몰라  </li>
</ul>


## Proposed Method
### 내가 이해한 이 논문에서의 학습 절차
<ol>
<li> Teacher Model의 중간층에서 Feature Map을 추출해서, Attention Map으로 변환. </li>
<li> 대응하는 Student Model의 중간층에서 Feature Map을 추출해서 Attention Map으로 변환 후 두 Attention Map을 비교하는 loss항을 최종 loss에 추가. </li>
<li> 얻어진 Attention Map을 Teacher, Student모두 Positive Map, Negative Map으로 분리한 뒤, 각각 Positive Map, Negative Map이 얼마나 비슷한 지에 대한 loss항을 최종 loss에 추가. </li>
<li> 여기까지가 loss를 어떻게 Tuning해야 성능이 더 좋아지는지에 대한 이야기. </li>
<li> 여기서부터는 마지막 출력층에서 어떻게 Predict를 수행해야 성능이 더 좋을지에 대한 이야기 </li>
<li> 얻어진 Attention Map을 Positive, Negative Map으로 분리한 뒤, Angular Margin 을 곱해준 뒤, Flatten or Normalization을 통해 특징 벡터로 변환한다. </li>
<li> 이 특징벡터를 고차원 구에 투영하여 표현함. </li>
<li> 표현된 특징벡터들을 가지고, A-softmax나 AMD-loss를 통해 최종 예측을 수행한다. </li>
<li> 이제 최종 예측된 값을 가지고 위에서 tuning한 loss를 통해 parameter를 업데이트 한다. </li>
</ol>

### Generating Attention Map
<ol>
<li> 중간층 layer의 Feature Map을 사용하여 Attention Map을 만든다. </li>
<li> 그런데, Teacher와 Student모델의 Dimension Size를 맞춰주기 위해서, Attention Map을 정규화 해주어야 함. </li>
<li> 왜 Dimension Size를 맞춰줘야 하냐면, 그래야, Positive and Negative Map을 생성하는 데에 이점이 있기 때문. </li>
<li> 이 논문에서는 power value인 d=2 로 사용했다고 함. 가장 베스트 결과가 나왔다. </li>
<li> d = 2 라는것은 Attention Map을 생성할 때 Feature Map에서 각 depth의 (width, height)에 해당하는 값들을 제곱을 해서 모두 더한다는 의미이다. </li>
<li> Positive Map은 f / |f|, (f는 중간층에서 추출한 특성 맵.) 이고, Negative Map은 1 - Positive Map 이다. </li>
</ol>

### Angular Margin Computation
<ol>
<li> 우리는 AMD-loss라는 것을 제안한다. </li>
<li> 이 AMD-loss에서 AM-loss는, 아레의 세 개의 항으로 이루어져 있다. </li>
<li> A항은 교사 모델과 학생 모델의 양성/음성 맵 간의 각도 차이를 줄이기 위한 항이다. </li>
<li> P항은 교사와 학생 모델의 양성 맵을 일치시키기 위한 loss 항이다. </li>
<li> N항은 교사와 학생 모델의 음성 맵을 일치시키기 위한 loss 항이다. </li>
<li> 즉, 최종 AMD loss항은 학생 모델의 Cross-entropy항, LK 손실항, AM-loss항을 hyperparameter로 가중치를 곱해준 형태로 정의한다. </li>
</ol>

![AM_Loss](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/AM-Loss.jpg)

![AMD_Loss](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/AMD-Loss.jpg)



### Global and Locat Feature Distillation
<ol>
<li> 이것은, feature map을 전체적으로 쓰는 Global Feature과, Local Feature을 모두 고려해야 한다는 것을 의미한다. </li>
<li> 이 논문에서는 Local Feature는 Global Feature를 4등분한 것으로 생성했고, 각각의 AM_Loss는 아레와 같이 변경된다. </li>
<li> 또한 이 논문에서는 각각이 가지는 비율을 Global : Local = 8 : 2 로 지정했다. </li>
</ol>

![Global/Local Feature Distillation](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Global-Local-Feature-Distillation.jpg)


## Datasets
### Cifar-10
<li> RGB의 3채널 이미지 데이터이다. 각 클래스마다 Train set 5000개, Test set 1000개로 총 60000개의 데이터 샘플이 있다. </li>

### CINIC-10
<li> Cifar-10에 Data Augmentation을 적용하여 얻어진 이미지 데이터이다. </li>
<li> 이는, Train set 90000개, Test set 90000개, Val set 90000개로 총 27만 개의 데이터가 있다. </li>

### ImageNet
<li> 대규모 이미지 데이터셋으로, 1000개의 클래스가 있고, 120만 개의 학습 이미지들이 있다. </li>
<li> 이미지는 무작위로 잘린 뒤에 224 x 224로 조정되고, 수평으로 flip된다. </li>

### Tiny-ImageNet
<li> 이 논문에서 대규모 데이터셋도 적용하기 위해 가져온 데이터임. </li>
<li> Tiny-ImageNet의 이미지는 64 x 64 크기이고, 우리는 68 x 68로 패딩을 준 다음, 랜덤으로 64 x 64로 잘라낸 이미지를 수평 방향으로 Flip하여 사용했다. </li>
<li> 이렇게 이미지의 복잡성을 반영하였다. </li>
<li> Tiny-ImageNet은 Train set가 100,000장, test set가 10,000장, 200개의 클래스를 포함한다. </li>

## Experiment Setting

### Cifar-10, CINIC-10에 대한 설정
<li> Batch_size = 128 </li>
<li> Optimizer = SGD + Momentum(0.9) </li>
<li> Epochs = 200 </li>
<li> learn_rate = 초기 : 0.1, 40, 80, 120, 160 epoch에서 0.2배로 감소함 </li>
<li> 가중치 감쇠 = 0.0001 / 모델이 과적합되지 않게 제어함. </li>

### Tiny-ImageNet에 대한 설정
<li> Batch_size = 256 </li>
<li> Optimizer = SGD + Momentum(0.9) </li>
<li> Epochs = 100 </li>
<li> learn_rate = 초기 : 0.1, 30, 60, 90 epoch에서 0.1배로 감소함 </li>

### Network 선택
<li> 아레의 조합 쌍에서 최대의 성능이 나왔다. </li>
<li> 교사모델 : WRN-16-3 (너비가 3배로 확장된 구조) </li>
<li> 학생모델 : WRN-16-1 (너비가 기본 1배인 구조) </li>

### loss함수의 가중치 설정
<li> CIFAR-10 - λ1 : 0.1, λ2 : 0.9, τ=4 에서 최대 성능이 나왔다. </li>
<li> CINIC-10 - λ1 : 0.4, λ2 : 0.6, τ=16 </li>
<li> Tiny-ImageNet - λ1 : 0.7, λ2 : 0.3, τ=16 </li>
<li> ImageNet - λ1 : 1.0, λ2 : 1.0, τ=4 </li>

## 실험
### Attention Based Distillation
<li> 다양한 Attention Based Distillation과 기본 KD, AMD의 성능비교. </li>
<ul>
<li> AT방식 (Attention Transfer) 이란? </li>
<ol>
<li> Teacher Model의 활성화 기반 Spacial Attention Map을 Student Model로 전달하여, 특정 Layer 간의 지식을 효과적으로 증류하는 방법임. </li>
</ol>
<li> AFDS (Attentive Feature Distillation and Selection) </li>
<ol>
<li> Feature Distillation을 강조하고, Feature Selection을 통해 교사 모델의 중요한 Feature를 학생 모델이 잘 학습하도록 함. </li>
</ol>
<li> AFD (Attentive Feature Distillation) </li>
<ol>
<li> Channel과 Spatial Attention Map을 추출하여, 교사와 학생간의 유사한 특징을 식별하는 방식. </li>
<li> Attention Map을 통해 주요 특징을 효과적으로 전달한다. </li>
</ol>
</ul>
<li> 각 데이터셋 마다 4개의 압축 유형과, (교사, 학생) 모델 쌍이 지정됨. </li>
<li> 압축 유형 </li>
<ol>
<li> Channel : 각 Layer의 필터 수(채널 수)를 줄인다. </li>
<li> Depth : 전체 Layer 수를 줄인다. </li>
<li> Depth + Channel : Channel과 Depth를 동시에 수행 </li>
<li> Different Architecture : 다른 경량화 모델을 이용한다. </li>
</ol>

### AMD Loss Function에 대하여
<li> AMD loss function의 AM loss는 A, P, N의 세 가지로 나누어진다. </li>
<li> A는 Positive Map 과 Negative Map 간의 각도 차이를 강조, 교사 모델이 가진 중요한 특징 구분 능력을 학생 모델이 학습하게 한다. </li>
<li> P는 교사 모델과 학생 모델의 생성된 Positive Map 간의 유사도를 높이는 손실함수. </li>
<li> N은 교사 모델과 학생 모델의 생성된 Negative Map 간의 유사도를 높이는 손실함수. </li>
<li> Figure 5를 보면, AM loss 중 일부만을 사용하여 Accuracy를 관찰한 결과, 그에 포함되는 모든 것들이 중요한 의미를 가짐을 알아냄. </li>
<li> Figure 6를 보면, AM loss가 낮을수록 Accuracy가 높아진다는 연관성을 찾을 수 있다. </li>

![Figure5](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure5.jpg)

![Figure6](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure6.jpg)


### t-SNE visualization and Cluster Metrics.
<li> t-SNE란? </li>
<ul>
<li> 고차원 데이터를 저차원(2D or 3D)로 변환하여 데이터 간의 유사성과 클러스터링 구조를 시각화하는 기법이다. </li>
<li> Figure 7에서는, 교사 모델과 학생 모델의 출력 특징을 t-SNE로 시각화하여, 각 클래스가 고유한 Cluster를 형성하는지 확인한다. </li>
<li> 이 plot 분포를 통해 학생 모델이 교사 모델의 특징 분포를 얼마나 잘 모방하고 있는지 확인할 수 있다. </li>
</ul>
<li> V-Score (Clustering 지표) </li>
<ul>
<li> V-Score는 클러스터링 품질을 평가하는 정량적 지표로, 높은 V-Score가 더 나은 클러스터링 성능을 의미한다. </li>
<li> 즉, V-Score가 높다면, 클래스 간의 구분이 명확하고, 내부적으로 클래스가 밀집된 형태로 잘 나뉘어져있다고 평가할 수 있다. </li>
<li> Figure 7을 보면, t-SNE 시각화를 통해 각 모델의 출력 특징을 클러스터로 표현하고, V-Score를 이용하여 Teacher, KD, AMD(global), AMD(global + local)의 성능을 정량화 해서 표현했다. </li>
</ul>

![Figure7](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure7.jpg)

### Effect of Teacher Capacity
<li> 교사 모델의 성능이 지식 증류에서 학생 모델의 성능에 미치는 영향 </li>
<li> Table 8을 보면, 각 데이터셋에 대해서, 여러 Teacher Model에 대한 KD, AT, SP, AMD(g), AMD(g+l)에 대한 Acc들이 묘사되어 있다. </li>
<li> 대부분의 경우, Teacher 모델의 parameter 개수(capacity)가 높을 수록, Accuracy가 높아지는 경향은 있지만, 이게 유의미한 차이로 보이진 않는다. </li>
<li> 예를 들어, CINIC-10에서, 학생이 WRN 16-1이고, 교사가 WRN 40-1 일 때 교사의 parameter는 60만개이다. 그렇지만, 이 때의 성능이 교사가 WRN 40-2 (parameter가 230만개)일 때보다 성능이 더 좋다. </li>


## Trainning Environment
<li> Dataset = Cifar10 </li>
<li> python = 3.8.18 </li>
<li> pytorch = 2.4.1 + CUDA ??? </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 20 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.0005 </li>
<li> optimizer = Adam </li>



## Evaluation


## Results