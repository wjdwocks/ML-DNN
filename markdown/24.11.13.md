## 24.11.13 공부할 내용
<li> Resnet의 Bottleneck 구조에 대해 더 깊은 공부 + Resnet 51을 구현한 코드를 보고 이해. </li>
<li> 교수님이 읽으라고 하신 논문 두 부에 대해 충분한 이해를 하고 가자. </li>
<li> 저번 주 논문 중 18번 Reference의 ESKD에 대한 논문을 읽고 이해해보자. </li>


## 논문 주요 내용 (배경지식)
### 기존의 KD의 loss
<ol>
<li> logits이란? </li>
<ul>
<li> 모델의 마지막 층에서 나오는 출력으로, 각 클래스에 대해 예측한 '점수'를 의미한다. </li>
<li> 이 점수는 아직 정규화되지 않은 상태이고, softmax를 적용하면 확률 분포로 변환된다. </li>
</ul>
<li> logit을 이용한 지식 전달 </li>
<ul>
<li> 지식 증류에서 교사 모델의 logit은 단순한 정답이 아닌, 클래스 간의 "미묘한 관계"를 나타내는 정보로 간주된다. </li>
<li> 예를 들어, 어떤 이미지가 고양이일 확률이 0.8이고, 개일 확률이 0.15, 새일 확률이 0.05라면, 교사 모델은 "이 이미지는 고양이에 가깝지만, 개일 가능성도 약간 있다"고 예측한 것임. </li>
<li> 학생 모델은 이러한 클래스 간의 유사성 정보를 배우게 되고, 단순히 정답을 맞추는 것보다도 더 깊은 클래스 간의 관계도 학습하게 된다. </li>
</ul>
<li> 지식 증류에서의 logit 전달 방식 </li>
<ul>
<li> 교사 모델이 생성한 logit을 student 모델의 학습 손실에 포함시켜, 학생 모델이 이 값을 따라가도록 유도한다. </li>
<li> logit 손실(KL Divergence loss) = (a)KL(교사 모델의 logit, 학생 모델의 logit) 으로 표현하는데 이는 두 모델의 출력 분포 간의 차이를 계산하는 식이다. </li>
<li> logit은 그냥 각 모델의 출력(softmax)라고 보면 됨. </li>
</ul>
<li> 학생 모델은 두 가지 손실을 통해 학습한다. </li>
<ul>
<li> 일반적인 손실 : 학생 모델이 정답 라벨과 가까운 예측을 하도록 유도하는 손실 (Cross-entropy loss) </li>
<li> 지식 증류 손실 : 교사 모델의 logits을 따라가도록 유도하는 손실 (Distillation loss) </li>
</ul>
</ol>

![KD_loss](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/KD_lossfunc_KL.png)

### AMD loss
<li> 양성 특징(타겟 객체)와 음성 특징(background) 간의 각 거리(Angular Distance)를 사용하여 특징을 학습한다. </li>
<li> 이 때 특징들을 고차원 구(hypersphere)에 투영하여, 기존의 많은 특징 추출기에서 볼 수 있는 유사한 각 분포를 활용하는 방식이다. </li>
<li> AMD Loss의 작동 원리와 주요 개념 </li>
<ol>
<li> 고차원 구 투영(embedding) </li>
<ul>
<li> 특징 벡터를 고차원 구에 투영하여 학습함. 이를 통해 모델이 각도를 기준으로 양성과 음성 특징을 구분하게 하며, 특징의 방향성에 기반한 학습이 가능해짐. </li>
<li> 구에 투영된 특징 벡터는 방향성에 따라 가까운 특징(양성 특징)은 비슷한 각도로 유지하고, 먼 특징(음성 특징)은 더 큰 각도로 떨어지도록 유도한다. </li>
</ul>
<li> 양성 특징에 각 마진(angular margin) 추가 </li>
<ul>
<li> 양성 특징에 각 마진을 추가하여 더 집중된 특징 벡터를 만든다. 이 마진은 양성 특징 벡터를 구상에서 특정 각도로 모이게 하여, 모델이 중요한 특징을 더 뚜렷하게 구분할 수 있도록 한다. </li>
<li> 이로 인해 양성 특징 벡터는 구 내부에서 밀집된 각도 분포를 가지게 되며, 음성 특징과의 거리가 더 커져 모델이 쉽게 구분할 수 있다. </li>
</ul>
<li> 특징의 각 분포(angular distribution) </li>
<ul>
<li> 많은 특징 추출기에서 양성 특징은 특정 각도에 모여 있는 경향이 있다. AMD Loss는 이러한 특징을 활용하여 양성과 음성 특징 간의 각도를 명확하게 분리하며, 양성 특징은 좁은 각도 분포에 집중시키고 음성 특징은 더 넓은 각도 분포로 분리되도록 한다. </li>
</ul>
</ol>


### Spherical Embedding을 활용하여 KD를 개선하는 방안
<ol>
<li> 활성화된 특징을 얻기 위해 공간 주의(spacial attention) map을 계산하고, 양성 맵과 음성 맵으로 분리함. </li>
<ul>
<li> spacial attention map : 모델이 주목해야 할 영역 </li>
<li> 목적 : 모델이 학습하는 동안 더 중요한 특징에 집중하도록 유도하기 위함. </li>
<li> 방법 : 이미지나 데이터에서 spatial attention map을 계산함. </li>
<li> 이 spatial attention map을 positive map과 negative map으로 나눈다. </li>
<li> 모델이 주목해야 하는 활성화된 영역이 positive map, negative map은 덜 중요한 정보를 의미함. </li>
</ul>
<li> 특징을 고차원 구(hypershpere)에 투영하여 각도 거리(angular distance)를 반영하게 함. </li>
<ul>
<li> angular distance :  </li>
<li> 목적 : 지식 증류 과정에서 모델이 특징 간의 각도 차이를 인식하게 하여 더 나은 표현 학습을 유도하는 것. </li>
<li> 방법 : spatial attention map에서 얻은 positive map(특징)을 고차원 구에 투영한다. </li>
<li> 이 과정을 통해 특징 간의 관계를 각도(angular distance)로 나타낼 수 있다. </li>
<li> 효과 : 고차원 구 임베딩을 통해 특징 간의 각도 차이가 반영되므로, 특징 간의 유사성과 차이가 명확하게 나타난다.  </li>
</ul>
<li> 양성 특징에 각 마진(angular margin)을 추가하여 더 집중된(attentive) 특징 표현 생성 </li>
<ul>
<li> 목적 : 학생 모델이 교사 모델이 주목하는 중요한 특징에 더 집중하게 유도하는 것. </li>
<li> 방법 : 양성 특징에 각 마진(angular margin)을 도입하여, 특징들이 특정 각도로 더 밀집되도록 만든다. 이로 인해 양성 특징은 더 집중된 형태로 표현된다. (같은 클래스의 특징들이 더 비슷한 방향을 가지도록 유도.) </li>
<li> 효과 : 양성 특징이 더 집중된 분포를 가지게 되어, 모델이 중요한 정보에 더 주목하게 된다. 이렇게 특징 표현을 해서, 모델이 특정 객체나 중요한 정보를 더 잘 인식하고 구별할 수 있음. </li>
</ul>
<li> 증류 과정에서 학생 모델이 교사 모델의 더 분리된 결정 영역(decision regions)을 모방하여 분류 성능이 향상됨. </li>
<ul>
<li> 목적 : 학생 모델이 교사 모델의 결정 경계(deicision boundary)를 모방하여 더 좋은 분류 성능을 가지게 한다. (특정 지점을 기준으로 각도 차이가 작다면, 같은 클래스에 속하고, 각도가 크다면 서로 다른 클래스에 속한다. 이 각도 차이를 기준으로 결정 경계를 설정함.) </li>
<li> 방법 : 지식 증류 과정에서 학생 모델이 교사 모델의 more separated된 decision boundary를 모방하도록 학습시킨다. </li>
<li> 이렇게 하여 교사 모델이 특징 간의 구분을 명확히 하고, 더 높은 정확도로 클래스를 예측하는 것을 따라갈 수 있게 한다. </li>
<li> 효과 : 학생 모델은 교사 모델의 Decision Boundary를 모방함으로써, 더 나은 분류 성능을 발휘하게 된다. </li>
<li> 학생 모델이 교사 모델의 결정 경계를 모방한다는 것은, 학생 모델이 교사 모델이 설정한 클래스 간의 구분 방식과 결정 경계를 따라가도록 학습한다는 것임. </li>
<li> Angular Margin과 KL-divergence 손실을 함께 사용하여, 학생 모델이 교사 모델과 유사한 방향성과 각도를 가진 특징 벡터를 학습하도록 만든다. </li>
<li> 학생 모델이 교사 모델의 각도 분포와 특징 간의 거리(angular distance(두 벡터가 이루는 각도))를 학습함으로써, 교사 모델이 가진 결정 경계와 유사한 경계를 형성하게 됨. </li>
</ul>
<li> 이 Shperical Embedding방식에서의 특징 표현 규제(regularizatino) </li>
<ul>
<li> 목적 : 전체적으로 학생 모델이 교사 모델의 유용한 정보를 더 잘 학습하도록 만든다. </li>
<li> 방법 : 제안된 방법을 통해 학생 모델의 특징 표현이 교사 모델처럼 정보가 풍부하고 중요한 특징을 포함하도록 규제한다. </li>
<li> 효과 : 학생 모델이 교사 모델의 중요한 정보를 효과적으로 학습하여, 더 높은 성능을 발휘할 수 있다. 교사 모델의 표현력을 학생 모델이 닮아가도록 학습하는 과정이므로, 학생 모델이 더 좋은 특징을 학습하고, 최종 성능이 향상됨. </li>
<li> Angular Margin을 추가함으로써, 같은 클래스의 특징 벡터들이 서로 더 가까운 방향을 가리키도록 제약을 주는 것임. </li>
<li> 손실 함수에 Angular Margin을 추가하여, 같은 클래스의 벡터들이 일정한 각도 이상으로 더 가까워져야 손실이 줄어들도록 학습을 진행한다. </li>
</ul>
</ol>

## Abstract 정리
<ol>
<li> KD는 네트워크를 경량화하고, 메모리효율적으로 만들어 주었다. </li>
<li> 교사 모델은 pre-trained 모델을 주로 사용하고, Pre-Trained 모델은 이미 학습된 상태로 제공되는 모델을 의미함. (즉, 오픈소스 활용이 가능한 대규모 데이터셋에서 학습이 완료된 모델을 말하는 듯.), 즉, 이미 학습된 가중치를 가지고 나의 Domain에 맞춰서 미세하게 가중치를 조정해주면 됨. </li>
<li> Pre-Trained Model의 반대로는 From Scratch Model 이라고 해서 내가 어떤 특수한 도메인에서 사용하고자 할 때 처음부터 학습을 시켜서 만드는 모델을 말한다. </li>
<li> 이 논문에서는 기존의 KD와 다르게, 중간 층의 Feature Map을 Knowledge Distillation의 source로 사용하여 교사 네트워크의 지식을 학생 네트워크로 전달한다. </li>
<ul>
<li> 중간 층의 Feature Map은 입력 데이터의 저차원 특징(간단한 엣지, 패턴)부터, 고차원 특징(객체의 형태, 구조)까지 다양한 정보를 포함하고 있다. </li>
<li> 즉, 중간층의 특징 맵을 활용하면, 학생 네트워크가 교사 네트워크의 다층적인 특징 표현을 학습하게 되어서, 더 나은 일반화 성능을 기대할 수 있다. </li>
<li> 최종 출력만으로는 클래스에 대한 확률 분포 정도만 전달할 수 있지만, 중간층의 특징 맵을 사용하면 객체의 구체적인 세부 정보와 구조를 학생 모델이 학습할 수 있다. </li>
<li> 특히 객체의 위치, 모양, 텍스처 등의 세밀한 정보가 중간층의 특징 맵에 포함되어있다. </li>
<li> 즉, 중간 층의 Feature Map을 이용한 Distillation은, 학생 모델이 중간층의 Feature Map을 모방하도록 유도하여, 교사 모델의 내재된 표현 능력까지 학습하게 된다. </li>
<li> 이 중간층 Feature Map을 이용하는 KD(Intermediate Layer Distillation)에서의 손실 함수는 L2손실이라고 해서, 교사 모델과 학생 모델의 대응하는 중간층 Feature Map 간의 차이를 줄이는 손실함수이다. </li>
</ul>
</ol>

## Introduction

## BackGround
### Knowledge Distillation
<li> 두 가지의 접근 방식으로 나뉘었었다. </li> 
<ol>
<li> Response-based KD : 교사 모델의 최종 출력을 사용하여 학생 모델이 이 출력을 모방하도록 loss를 작성함. (KL-divergence로 교사 모델의 출력 분포를 모방하게 하고, Softmax를 통해 정답 값의 손실을 비교.) </li>
<li> Feature-based KD : 교사 모델의 중간층에서 추출한 특징(특징or 특징맵)을 사용하여 학생 모델이 이를 학습하게 하는 방식. (중간 층에서의 feature map을 normalization하여 학생이 교사 모델의 중간층 표현을 모방하도록 한다.) </li>
</ol>

### Feature-based Method in KD
<li> 목적 : 교사 모델의 Attention Map을 추출하고, 이를 학생 모델에 전달하여 학생 모델이 동일한 Attention Pattern을 학습하게 하는 것이다. </li>
<li> AT - Zagoruyko의 접근 방식 </li>
<ul>
<li> 교사 모델은 Sum of Squared Attention Mapping Function을 사용하여 Attention Map을 계산한다. </li>
<li> 이 방식은 교사 모델의 Feature Map을 각 채널별로 값들을 제곱하고, 결과들을 합산하여 하나의 Attention Map을 생성한다. </li>
<li> 즉, 하나의 Feature Map은 (높이 x 너비 x 채널) 의 3차원 구조인데, 각 채널에 포함된 값(높이 x 너비)들을 제곱한 다음, 모든 채널에 대해 합산(sum)을 하여 하나의 2차원 Attention Map으로 생성하는 것을 의미함. </li>
<li> 이렇게 수행하는 이유는 각 특성맵에 포함된 값들은 값이 클 수록 집중해서 봐야 할 값이라고 여겨지기 때문이다. (ex) 우리가 pooling을 수행할 때에 Maxpooling을 주로 사용하는 이유와 같다.) </li>
</ul>
<li> 이렇게 생성된 교사 모델의 Attention Map을 학생 모델의 중간 층 Feature Map과 Mapping하여 학생 모델이 교사 모델의 Attention Pattern을 모방하게 한다. </li>
<ul>
<li> 일단 학생 모델의 중간 층에서 Feature Map을 추출함. (교사 모델의 특정 층에서 얻은 Feature Map과 비슷한 위치에 있는 학생 모델의 층에서 Feature Map을 추출함.) </li>
<li> 교사 모델과 동일한 방법으로 학생 모델의 Feature Map을 Attention Map으로 변환한다. (두 Attention Map을 비교할 수 있게 하기 위함.) </li>
<li> 일반적으로, 교사 모델의 주의 맵과 학생 모델의 주의 맵 사이의 L2손실을 계산하여, 두 맵이 최대한 비슷해지도록 학습을 수행하게 된다. </li>
<li> 즉, 위의 Attention Map Loss를 기존의 다른 손실 함수들에 추가적으로 항을 더해서 최종 손실에 포함시키면, 모델 학습 과정에서 이 Attention Pattern을 같이 고려하도록 되는 것이다. </li>
</ul>
<li> 이 논문에서 제안한 새로운 접근 방식 </li>
<ul>
<li> 기존의 AT 방식에서 더 나아가, 교사 모델의 Positive Map과 Negative Map을 구분하는 능력까지도 학생 모델에 이식하는 것이 목표이다. </li>
<li> 먼저, 교사 모델이 Positive map과 Negative Map을 생성한다. </li>
<li> 이 과정은 보통 객체의 위치나, 예측과 관련된 특징을 통해 Positive, Negative Map을 정의한다. </li>
<li> 학생 모델도 양성, 음성 맵을 생성하게 한 뒤, 두 값의 차이를 줄이는 손실함수를 만들어 통합한다. </li>
</ul>

### Spherical Feature Embedding
<li> 기존 방법의 한계 </li>
<ul>
<li> 기존에는 유클리드 거리를 기반으로 특징을 구분했다. </li>
<li> 하지만 이 접근법은 open-set 환경에서 클래스 간의 명확한 구분이 어렵다는 한계를 가지고 있음. </li>
<li> Open-set 환경은 모델에 훈련되지 않은 새로운 클래스가 테스트 데이터에 포함될 수 있는 환경을 의미함. 즉, closed-set 환경은 모델이 훈련된 클래스와 동일한 클래스들로만 test-set이 구성되고, open-set 환경은 모델이 처음 보는 클래스의 샘플도 predict를 수행해야 하는 경우가 있다. </li>
<li> ex) 개와 고양이 사진을 학습해서 분류하다가 갑자기 새 사진이 나와버린 경우. </li>
<li> 그렇기 때문에 Open-set 환경에서는 intra-class distance(같은 클래스 내에서의 최대 거리)를 줄여서, 같은 클래스 샘플들이 feature space에서 서로 더 가까이 모이도록 학습을 해야 한다. 왜냐하면, 같은 클래스에 속하는 샘플들이 서로 밀집된 cluster를 형성하게 되어, 모델이 새로운 클래스의 샘플을 기존 클래스와 구분하기가 더 쉬워지기 때문. </li>
</ul>
<li> A-Softmax (angular-softmax) 도입 </li>
<ul>
<li> 특징 벡터는 Attention Map이나, Positive Map을 통해 강조된 Feature Map을 정규화(flatten 등)를 통해 특징 벡터로 변환한 것이다.
<li> A-softmax 함수는 특징 벡터 간의 각도 기반 Margin 을 증가시켜 특징을 구분한다. </li>
 </li>
<li> 즉, 특징 벡터들이 고차원 구 위에서 더 넓은 각도 차이를 가지도록 학습시켜 클래스 간의 구분을 더 명확히 한다. </li>
<li> 각도 기반 Margin을 증가시킨다는 것은 같은 클래스인 특징 벡터들이 비슷한 방향성을 갖도록 유도하는 것이다. </li>
<li> 특징 벡터의 시점은 큰 관계가 없고, 방향만 관계가 있는듯. </li>
<li> 특징 벡터들이 고차원 구 위에 투영되면, 그것을 A-softmax를 이용하여 최종 예측을 수행하는 것이다. </li>
<li> 이러한 방식이 Open-set 환경에서 유리한 이유는, 다른 클래스와의 각도 차이가 명확하게 확보되기 때문에, 학습되지 않은 unknown class의 샘플이 들어오면, 기존 클래스들과 쉽게 구분할 수 있다. </li>
</ul>
<li> AMC-loss를 이용한 각도 기반의 Margin Penalty </li>
<ul>
<li> A-softmax와 AMC-loss 모두 각도 기반의 Margin Penalty를 활용하여 고차원 구 위에서 특징을 더 잘 구별하도록 만든다. </li>
<li> 즉, 지금까지 특징들을 가지고 classification을 했다면, 여기서는 특징들을 이용해 특징 벡터를 만들고, 이를 고차원 구에 투영하여 비교를 해서 예측을 수행하는데, 이 때 기존의 softmax로 최종예측을 하는 것이 아닌, A-softmax와, AMC loss를 사용한다고 보면 된다. </li>
<li> AMC-loss는 Angular Margin based Contrastive Loss로, 이 또한 고차원 구에서의 Geodesic 거리를 기반으로 각도 기반 Margin Penalty를 활용하여 같은 클래스 내의 응집성을 향상시킨다. </li>
<li> 어떻게 하는지는 몰라  </li>
</ul>


## Proposed Method
### 내가 이해한 이 논문에서의 학습 절차
<ol>
<li> Teacher Model의 중간층에서 Feature Map을 추출해서, Attention Map으로 변환. </li>
<li> 대응하는 Student Model의 중간층에서 Feature Map을 추출해서 Attention Map으로 변환 후 두 Attention Map을 비교하는 loss항을 최종 loss에 추가. </li>
<li> 얻어진 Attention Map을 Teacher, Student모두 Positive Map, Negative Map으로 분리한 뒤, 각각 Positive Map, Negative Map이 얼마나 비슷한 지에 대한 loss항을 최종 loss에 추가. </li>
<li> 여기까지가 loss를 어떻게 Tuning해야 성능이 더 좋아지는지에 대한 이야기. </li>
<li> 여기서부터는 마지막 출력층에서 어떻게 Predict를 수행해야 성능이 더 좋을지에 대한 이야기 </li>
<li> 얻어진 Attention Map을 Positive, Negative Map으로 분리한 뒤, Angular Margin 을 곱해준 뒤, Flatten or Normalization을 통해 특징 벡터로 변환한다. </li>
<li> 이 특징벡터를 고차원 구에 투영하여 표현함. </li>
<li> 표현된 특징벡터들을 가지고, A-softmax나 AMD-loss를 통해 최종 예측을 수행한다. </li>
<li> 이제 최종 예측된 값을 가지고 위에서 tuning한 loss를 통해 parameter를 업데이트 한다. </li>
</ol>

### Generating Attention Map
<ol>
<li> 중간층 layer의 Feature Map을 사용하여 Attention Map을 만든다. </li>
<li> 그런데, Teacher와 Student모델의 Dimension Size를 맞춰주기 위해서, Attention Map을 정규화 해주어야 함. </li>
<li> 왜 Dimension Size를 맞춰줘야 하냐면, 그래야, Positive and Negative Map을 생성하는 데에 이점이 있기 때문. </li>
<li> 이 논문에서는 power value인 d=2 로 사용했다고 함. 가장 베스트 결과가 나왔다. </li>
<li> d = 2 라는것은 Attention Map을 생성할 때 Feature Map에서 각 depth의 (width, height)에 해당하는 값들을 제곱을 해서 모두 더한다는 의미이다. </li>
<li> Positive Map은 f / |f|, (f는 중간층에서 추출한 특성 맵.) 이고, Negative Map은 1 - Positive Map 이다. </li>
</ol>

### Angular Margin Computation
<ol>
<li> 우리는 AMD-loss라는 것을 제안한다. </li>
<li> 이 AMD-loss에서 AM-loss는, 아레의 세 개의 항으로 이루어져 있다. </li>
<li> A항은 교사 모델과 학생 모델의 양성/음성 맵 간의 각도 차이를 줄이기 위한 항이다. </li>
<li> P항은 교사와 학생 모델의 양성 맵을 일치시키기 위한 loss 항이다. </li>
<li> N항은 교사와 학생 모델의 음성 맵을 일치시키기 위한 loss 항이다. </li>
<li> 즉, 최종 AMD loss항은 학생 모델의 Cross-entropy항, LK 손실항, AM-loss항을 hyperparameter로 가중치를 곱해준 형태로 정의한다. </li>
</ol>

![AM_Loss](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/AM-Loss.jpg)

![AMD_Loss](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/AMD-Loss.jpg)



### Global and Locat Feature Distillation
<ol>
<li> 이것은, feature map을 전체적으로 쓰는 Global Feature과, Local Feature을 모두 고려해야 한다는 것을 의미한다. </li>
<li> 이 논문에서는 Local Feature는 Global Feature를 4등분한 것으로 생성했고, 각각의 AM_Loss는 아레와 같이 변경된다. </li>
<li> 또한 이 논문에서는 각각이 가지는 비율을 Global : Local = 8 : 2 로 지정했다. </li>
</ol>

![Global/Local Feature Distillation](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Global-Local-Feature-Distillation.jpg)


## Datasets
### Cifar-10
<li> RGB의 3채널 이미지 데이터이다. 각 클래스마다 Train set 5000개, Test set 1000개로 총 60000개의 데이터 샘플이 있다. </li>

### CINIC-10
<li> Cifar-10에 Data Augmentation을 적용하여 얻어진 이미지 데이터이다. </li>
<li> 이는, Train set 90000개, Test set 90000개, Val set 90000개로 총 27만 개의 데이터가 있다. </li>

### ImageNet
<li> 대규모 이미지 데이터셋으로, 1000개의 클래스가 있고, 120만 개의 학습 이미지들이 있다. </li>
<li> 이미지는 무작위로 잘린 뒤에 224 x 224로 조정되고, 수평으로 flip된다. </li>

### Tiny-ImageNet
<li> 이 논문에서 대규모 데이터셋도 적용하기 위해 가져온 데이터임. </li>
<li> Tiny-ImageNet의 이미지는 64 x 64 크기이고, 우리는 68 x 68로 패딩을 준 다음, 랜덤으로 64 x 64로 잘라낸 이미지를 수평 방향으로 Flip하여 사용했다. </li>
<li> 이렇게 이미지의 복잡성을 반영하였다. </li>
<li> Tiny-ImageNet은 Train set가 100,000장, test set가 10,000장, 200개의 클래스를 포함한다. </li>

## Experiment Setting

### Cifar-10, CINIC-10에 대한 설정
<li> Batch_size = 128 </li>
<li> Optimizer = SGD + Momentum(0.9) </li>
<li> Epochs = 200 </li>
<li> learn_rate = 초기 : 0.1, 40, 80, 120, 160 epoch에서 0.2배로 감소함 </li>
<li> 가중치 감쇠 = 0.0001 / 모델이 과적합되지 않게 제어함. </li>

### Tiny-ImageNet에 대한 설정
<li> Batch_size = 256 </li>
<li> Optimizer = SGD + Momentum(0.9) </li>
<li> Epochs = 100 </li>
<li> learn_rate = 초기 : 0.1, 30, 60, 90 epoch에서 0.1배로 감소함 </li>

### Network 선택
<li> 아레의 조합 쌍에서 최대의 성능이 나왔다. </li>
<li> 교사모델 : WRN-16-3 (너비가 3배로 확장된 구조) </li>
<li> 학생모델 : WRN-16-1 (너비가 기본 1배인 구조) </li>

### loss함수의 가중치 설정
<li> CIFAR-10 - λ1 : 0.1, λ2 : 0.9, τ=4 에서 최대 성능이 나왔다. </li>
<li> CINIC-10 - λ1 : 0.4, λ2 : 0.6, τ=16 </li>
<li> Tiny-ImageNet - λ1 : 0.7, λ2 : 0.3, τ=16 </li>
<li> ImageNet - λ1 : 1.0, λ2 : 1.0, τ=4 </li>

## 실험
### Attention Based Distillation
<li> 다양한 Attention Based Distillation과 기본 KD, AMD의 성능비교. </li>
<ul>
<li> AT방식 (Attention Transfer) 이란? </li>
<ol>
<li> Teacher Model의 활성화 기반 Spacial Attention Map을 Student Model로 전달하여, 특정 Layer 간의 지식을 효과적으로 증류하는 방법임. </li>
</ol>
<li> AFDS (Attentive Feature Distillation and Selection) </li>
<ol>
<li> Feature Distillation을 강조하고, Feature Selection을 통해 교사 모델의 중요한 Feature를 학생 모델이 잘 학습하도록 함. </li>
</ol>
<li> AFD (Attentive Feature Distillation) </li>
<ol>
<li> Channel과 Spatial Attention Map을 추출하여, 교사와 학생간의 유사한 특징을 식별하는 방식. </li>
<li> Attention Map을 통해 주요 특징을 효과적으로 전달한다. </li>
<li> 교사 모델의 Feature Map과 학생 모델에서 비슷한 layer에서 얻어온 Feature Map의 쌍을 대응시켜 비교한다. </li>
<li> 두 비슷한 layer에서 얻어온 Feature Map의 유사도를 Cosine Similarity와 같은 지표를 통해 비교함. </li>
</ol>
</ul>
<li> 각 데이터셋 마다 4개의 압축 유형과, (교사, 학생) 모델 쌍이 지정됨. </li>
<li> 압축 유형 </li>
<ol>
<li> Channel : 각 Layer의 필터 수(채널 수)를 줄인다. </li>
<li> Depth : 전체 Layer 수를 줄인다. </li>
<li> Depth + Channel : Channel과 Depth를 동시에 수행 </li>
<li> Different Architecture : 다른 경량화 모델을 이용한다. </li>
</ol>

### AMD Loss Function에 대하여
<li> AMD loss function의 AM loss는 A, P, N의 세 가지로 나누어진다. </li>
<li> A는 Positive Map 과 Negative Map 간의 각도 차이를 강조, 교사 모델이 가진 중요한 특징 구분 능력을 학생 모델이 학습하게 한다. </li>
<li> P는 교사 모델과 학생 모델의 생성된 Positive Map 간의 유사도를 높이는 손실함수. </li>
<li> N은 교사 모델과 학생 모델의 생성된 Negative Map 간의 유사도를 높이는 손실함수. </li>
<li> Figure 5를 보면, AM loss 중 일부만을 사용하여 Accuracy를 관찰한 결과, 그에 포함되는 모든 것들이 중요한 의미를 가짐을 알아냄. </li>
<li> Figure 6를 보면, AM loss가 낮을수록 Accuracy가 높아진다는 연관성을 찾을 수 있다. </li>

![Figure5](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure5.jpg)

![Figure6](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure6.jpg)


### t-SNE visualization and Cluster Metrics.
<li> t-SNE란? </li>
<ul>
<li> 고차원 데이터를 저차원(2D or 3D)로 변환하여 데이터 간의 유사성과 클러스터링 구조를 시각화하는 기법이다. </li>
<li> Figure 7에서는, 교사 모델과 학생 모델의 출력 특징을 t-SNE로 시각화하여, 각 클래스가 고유한 Cluster를 형성하는지 확인한다. </li>
<li> 이 plot 분포를 통해 학생 모델이 교사 모델의 특징 분포를 얼마나 잘 모방하고 있는지 확인할 수 있다. </li>
</ul>
<li> V-Score (Clustering 지표) </li>
<ul>
<li> V-Score는 클러스터링 품질을 평가하는 정량적 지표로, 높은 V-Score가 더 나은 클러스터링 성능을 의미한다. </li>
<li> 즉, V-Score가 높다면, 클래스 간의 구분이 명확하고, 내부적으로 클래스가 밀집된 형태로 잘 나뉘어져있다고 평가할 수 있다. </li>
<li> Figure 7을 보면, t-SNE 시각화를 통해 각 모델의 출력 특징을 클러스터로 표현하고, V-Score를 이용하여 Teacher, KD, AMD(global), AMD(global + local)의 성능을 정량화 해서 표현했다. </li>
</ul>

![Figure7](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure7.jpg)

### Effect of Teacher Capacity
<li> 교사 모델의 성능이 지식 증류에서 학생 모델의 성능에 미치는 영향 </li>
<li> Table 8을 보면, 각 데이터셋에 대해서, 여러 Teacher Model에 대한 KD, AT, SP, AMD(g), AMD(g+l)에 대한 Acc들이 묘사되어 있다. </li>
<li> 대부분의 경우, Teacher 모델의 parameter 개수(capacity)가 높을 수록, Accuracy가 높아지는 경향은 있지만, 이게 유의미한 차이로 보이진 않는다. </li>
<li> 예를 들어, CINIC-10에서, 학생이 WRN 16-1이고, 교사가 WRN 40-1 일 때 교사의 parameter는 60만개이다. 그렇지만, 이 때의 성능이 교사가 WRN 40-2 (parameter가 230만개)일 때보다 성능이 더 좋다. </li>

### 교사 모델과 학생 모델의 구조의 차이와 성능 비교
<li> SP(Similarity - Preserving KD)에서는 교사와 학생 모델의 구조적 차이가 클 때 최적의 성능을 찾기 어려웠다. (학생 모델의 성능이 낮았음) </li>
<li> AMD는 이러한 교사-학생 모델 간의 구조적 차이가 큰 네 가지 상황 모두에서 SP보다 우월한 성능을 보여줬다. </li>

![Table9](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Table9.jpg)

### 최적의 하이퍼파라미터 r(감마)를 찾은 방법
<li> 감마는 AM loss에서 지식 증류 강도를 조절하는 요소로, 전체 Loss에서 AM Loss항이 얼마의 비중을 갖게 할 지를 정해주는 역할을 한다. </li>
<li> Figure 8을 보면, (교사 : WRN16-3, 학생 : WRN16-1)의 쌍을 CIFAR-10, CINIC-10 에서 돌려보며 감마 값을 비교한 것과, (교사 : WRN-1, 학생 : WRN16-1)의 쌍을 CIFAR-10과 CINIC-10에서 돌려보며 감마 값을 비교한 결과가 나온다. </li>
<li> 결과를 보면, CIFAR-10에서는 감마 값이 3000~7000 사이일 때 좋은 결과가 나타나고, CINIC-10에서는 감마 값이 5000일 때 최고의 정확도를 보였다. </li>

![Figure8](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure8.jpg)

### 최적의 하이퍼파라미터 m(Angular Margin)을 찾은 방법.
<li> m(Angular Margin)의 역할 : 양성특징과 음성 특징 사이의 간격을 늘려주는 역할을 한다. </li>
<li> how? : 원래의 Positive Map과 Negative Map사이에 각도가 ∂였다면 m + ∂이 되도록 하여 양성 특징과 음성 특징 간의 각도 차이를 늘려서 모델이 두 특징을 더 잘 구분하도록 유도한다. </li>
<li> how? : 손실함수를 구할 때 이 마진이 포함된 각도 차이를 기준으로 손실을 계산하기 때문에 좀 더 두개가 많이 다르다고 인식을 하기 때문. </li>
<li> Figure9에서는 위와 같이 두 데이터셋과, 두 (T, S) 쌍에 대하여 1~2사이의 Angular Margin을 적용하여 실험을 한 뒤 성능을 나타냈다. </li>

![Figure9](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure9.jpg)

### 논문에서 Activation Map에 대한 분석. (Grad-cam을 사용했는데 이게 뭐냐?)
<li> Grad-CAM (Gradient-weighted Class Activation Mapping)은 특정 클래스에 대한 이미지의 중요한 영역을 시각화하는 기법이다. </li>
<li> Grad-CAM은 모델의 예측에 중요한 특징을 시각적으로 표현하는 localization map을 제공한다. </li>
<li> 즉, 중간층의 Activation Map을 시각화해서 모델이 예측을 할 때 어떤 영역을 중요하게 여겼는지, 빨간색 영역으로 표현한 것이다. </li>
<li> 이를 통해서 지식 증류 과정에서 중요한 특징이 잘 전달되었는지 확인할 수 있다. </li>

### 이 Grad-CAM을 통해서 AMD가 얼마나 좋은 방법인지 직관적으로 볼 수 있다.
<li> Figure10을 보면, low-level(32x32), mid-level(16x16), high-level(8x8)에서의 낮은층, 중간층, 깊은 층의 Activation Map을 시각화 한것인데, 깊어질수록, AMD가 다른 Method들에 비해 빨간 색 영역이 Target Object에 집중되었다는 것을 볼 수 있다. </li>
<li> 이 그림을 보면, AMD 방식이 다른 방법들에 비해 target 객체에 더 높은 가중치를 두고, 배경에는 가중치를 적게 준다는 것을 알 수 있음. </li>
<li> 즉, AMD가 타겟 객체에 더 높은 가중치를 두었기 때문에, 이는 target 객체에 더 집중된 활성화 맵을 생성한 것이라고 볼 수 있다. </li>
<li> 즉, AMD로 학습한 학생 모델이 더 높은 분류 능력을 갖고 있다는 것을 보여주는 그림이다. </li>

![Figure10](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure10.jpg)


### AMD에서 Global 과 Local 특징을 함께 사용하면 좋은 이유
<li> Global features : 전체 이미지를 포괄적으로 반영하여 Activation Map을 생성한 것. </li>
<li> Local features : 이미지의 특정 세부 영역을 반영하여 더 미세한 Activation Map을 생성한 것. </li>
<li> Figure12를 보면 Global Features만 사용한 것 보다 Global + Local Features를 사용한 것이 Teacher Model이 생성한 activation map과 더 비슷했다. (난 잘 모르겠다.) </li>
<li> 또한 AMD(global + local)이 foreground object에 더 높은 가중치를 둬서 집중하는 경향이 있었음. </li>
<li> 즉, AMD(global) 보다 AMD(global + local)이 더 성능이 좋다고 볼 수 있다. </li>

![Figure12](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure12.jpg)


### AMD를 다른 방법들과 결합해보자.
<li> 기존 학습 기법들과 쉽게 조합되어서 일반화 성능을 높일 수 있는지 보자. </li>
<li> Fine-Grained Features </li>
<ul>
<li> 특정 클래스 내에서도 매우 세밀하게 구분되는 특징들을 학습하는 것. </li>
<li> 유사한 클래스 간의 차이를 보다 정교하게 학습하는 데 초점을 맞춘다. </li>
<li> 고해상도 특징 추출 등의 방법을 사용해서, 객체의 주요 세부 사항에 집중하도록 유도함. </li>
</ul>
<li> Augmentation Method </li>
<ul>
<li> 데이터 증강 기법으로, 학습 데이터를 다양한 방식으로 변형하여 모델이 더 강력하고, 일반화된 성능을 가지도록 한다. </li>
<li> 즉, 데이터를 이리저리 돌려보고, 자르고, 회전시키고, 반전시키고, 밝기를 바꾸던가 해서 좀 더 일반화된 성능을 기대할 수 있다. </li>
</ul>
<li> SP(다른 Distillation Method들과의 결합 대표적으로 SP) </li>
<ul>
<li> 학생 모델이 교사 모델의 특징 간 유사성을 보존하도록 학습하는 방식. </li>
<li> SP는 특징 간 유사도 관계를 보존함으로써, 학생 모델이 교사 모델이 가진 표현력을 최대한 따르게 함. </li>
<li> 즉, 특징 간의 코사인 유사도 or 유클리드 거리를 기반으로 교사 모델의 특징 구조를 따르게 학습한다? </li>
</ul>

### Fine-Grained Feature-Based Distillation
<li> Fine-Grained 방식을 결합함. </li>
<li> 교사 모델이 일반적으로 더 복잡하고, 섬세한 정보를 포함하고 있다는 가정에서 출발. </li>
<li> 그렇기 때문에 이 더 복잡한 패턴을 학생 모델이 학습한다면, 성능을 더 향상시킬 수 있다. </li>
<li> Fine-Grained Feature를 활용한다는 것은, 교사 모델의 미세한 정보를 학생 모델이 최대한 잘 따라가도록 돕는 것을 의미한다. </li>
<li> Negative Feature는 예측하고자 하는 클래스와 무관한 정보이다. (ex) 고양이를 찾고 싶다면, 고양이가 없는 배경이나 풀떼기 등이 negative feature)</li>
<li> 이 때 Binary Mask를 이용하여 negative feature를 걸러내는 역할을 한다. </li>
<li> Binary Mask를 통해 교사 모델의 특성 맵에서 객체가 있는 부분과 객체가 없는 부분을 구분하고, 특정 임계값을 기준으로 객체가 있을 만한 부분은 그대로 유지하고(0.5를 넘는) 객체가 없을 것으로 판단되는 부분은 0으로 설정하여 binary mask를 만든다. </li>
<li> 이렇게 만들어진 binary mask는 객체가 위치한 중요한 영역만 남겨두고, 불필요한 영역을 제거한 특성 맵을 만듦 (masked feature map) </li>
<li> 이 masked feature map을 학생 모델에 전달한다. </li>
<li> 즉, 이 masked feature map을 통해 교사 모델이 중요하다고 생각한 영역을 동일하게 학습을 하게 되어 성능 향상을 기대할 수 있는 것임. </li>
<li> 그런데, 특성 맵에서 중요한 부분을 교사 맵에서 알아오는 것이기 때문에, 교사 모델과 학생 모델이 비슷한 구조로 이루어져 있어야 한다. </li>
<li> Figure13을 보면 (d)네트워크 쌍에서 AMD(g+l, m)에서 성능이 월등히 좋은데, 이것은 교사 모델과 학생 모델의 구조가 많이 다르기 때문임. </li>
<li> 즉, 교사 모델과 학생 모델의 구조적 차이가 오히려 학생 모델이 중요한 특성만을 추출하고 학습할 수 있게 유도해주기 때문이다. </li>
<li> 결론 : KD는 교사 모델과 학생 모델의 네트워크 구조가 같으면 같을 수록 분포가 비슷하기 때문에 좋은 성능을 내지만, 네트워크 구조가 다르다면, Fine-Grained Features와 같은 보조 기법을 사용하여 성능을 증가시킬 수 있다. </li>

![Figure13](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure13.jpg)

### Applying Augmentation Methods
<li> 교사 모델은 원래의 데이터셋으로 pre-trained model을 사용하고, 학생 모델에만 데이터 증강을 적용하는 것인듯. </li>
<li> MixUp 기법 </li>
<ul>
<li> 두 개의 이미지를 섞고, 해당 이미지의 라벨도 혼합하여 새로운 학습 샘플을 생성한다. </li>
<li> 진짜로 섞는다. 거짓말 아님. </li>
<li> 다양한 데이터 변형을 학습할 수 있어서 일반화 성능이 향상된다. </li>
<li> αMixup = 0.2는 베타 분포의 α값을 의미하고, 실제로 이미지가 합쳐질 때는 λ가 0~1 사이에 값으로 랜덤으로 정해진다. </li>
<li> λx_1 + (1-λ)x_2 와 같이 이미지가 생성됨. </li>
</ul>
<li> Mixup 적용 효과 </li>
<ul>
<li> Figure14를 보면, 대부분의 방법(KD, AT, AFD, AMD)에서 mixup을 적용했을 때 성능이 향상됨. (Student라고 써있는게, 그냥 쌩으로 돌린거) </li>
<li> 전통적인 KD에서는 Mixup을 적용했더니 성능이 떨어짐 → Mixup이 혼합된 라벨을 생성하는데 이것은 교사 모델이 정확한 logits을 전달하는 데 어려움이 있기 때문이다. </li>
<li> KD는 교사 모델의 명확한 로짓 정보 전달을 기반으로 성능을 높히기 때문. </li>
<li> AMD(g+l)과 Mixup의 조합은 다른 방법들보다 특히 좋은 성능을 보임. 이는 AMD(g+l) 방식이 교사 모델의 중요한 지역 정보와 전역 정보를 모두 반영한 학습 방법이기 때문에, 다양한 데이터 변형을 포함하는 Mixup기법과 상호 보완적으로 작용하기 때문이다. </li>
</ul>

![Figure14](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure14.jpg)

<li> AFD에서 Teacher Network가 WRN28-1일 때 성능이 나빠진 이유 </li>
<ul>
<li> AFD에서는 교사와 학생이 비슷한 특징을 공유하는 것이 중요한데, Mixup이 큰 네트워크에서 생성한 복잡한 패턴이 작은 네트워크에 부정적인 영향을 미침 </li>
<li> Mixup이 AFD의 의도된 특징 정렬을 방해해서 효과를 떨어뜨린다. </li>
</ul>

<li> Mixup의 일반화 및 정규화 효과를 평가하기 위한 ECE/NLL 지표 </li>
<ol>
<li> ECE(기대 보정 오류) </li>
<ul>
<li> 모델이 얼마나 잘 보정(calibration)되었는지를 측정하는 지표 </li>
<li> 보정이란, 모델의 예측 확률이 실제 정확도와 얼마나 일치하는지를 의미함. </li>
<li> 모델의 예측 확률을 구간으로 나타내는데 (그 구간의 평균 - 실제 정확도) = 보정 오류 라고 하고, 이 보정 오류를 전체 구간에 대해 가중 평균하면 ECE가 된다. </li>
<li> 즉, 낮은 ECE는 모델이 잘 보정되었다는 의미임 (예측 확률이 실제 정확도와 일치함.) </li>
<li> 결론 : 모델이 "이 이미지가 고양이일 확률이 80%다" 라고 한다면 실제로 80%확률로 고양이여야 한다. (ECE가 낮다면, 아주아주 신뢰할만한 모델이다.) </li>
</ul>
<li> NLL(음의 로그 가능도) </li>
<ul>
<li> 확률 모델이 예측한 확률이 실제 관측된 결과와 얼마나 일치하는지를 평가하는 지표 </li>
<li> 모델이 예측한 확률 값을 로그를 사용하여 변환한 뒤, 실제 결과에 해당하는 확률의 로그 값을 음수로 변환하여 합침.?/?? </li>
<li> 모델이 높은 확률로 예측한 결과가 실제로 일치한다면 NLL이 낮아지고, 그렇지 않으면 NLL이 높아진다. </li>
<li> 낮은 NLL은 모델이 예측 확률을 신뢰할 수 있게 제공한다는 것을 의미한다. </li>
<li> 높은 NLL은 모델의 예측 확률이 실제 결과와 일치하지 않거나 불안정하다는 것을 나타낸다. </li>
</ul>
</ol>


<li> Table10과 Figure15 분석 </li>
<ul>
<li> 그냥 아무런 테크닉 없이 Resnet16-1에 Mixup 데이터 증강 기법만 적용한다면 NLL/ECE 값이 증가함. </li>
<li> 이것은 Mixup이 데이터 샘플을 섞고, 라벨도 섞으면서 불확실성이 증가하기 때문이다. </li>
<li> 하지만 KD, AT, AFD, AMD(g), AMD(g+l) 에 대해서는 모두 다 ECE/NLL이 감소하는 효과를 얻었다. </li>
<li> 특히, AMD(g+l)과 Mixup을 동시에 적용했을 때 아주 많이 감소했다. </li>
</ul>

![Figure15](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Figure15.jpg)

![Table10](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Table10.jpg)

<li> CutMix 데이터 증강 기법 </li>
<ul>
<li> Cutmix는 두 사진 중에서 일부를 떼어서 한쪽에 붙이는 것이다.  </li>
<li> 아레 예시가 있음. </li>
<li> Figure 16을 보면, CutMix를 적용했을 때/안했을 때를 봤을 때 큰 차이가 있는 것을 알 수 있다. </li>
</ul>

![Cutmix](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/Cutmix.jpg)

<li> MoEx 데이터 증강 기법 </li>
<ul>
<li> MoEx는 두 특성 맵(Feature Map)에서 평균과 표준편차를 교환하여 모델이 더욱 일반화될 수 있도록 돕는 방식임. </li>
<li> 즉, 특정 레이어에서 두 샘플의 Feature map 통계를 서로 교환함. 모델은 다양한 통계적 특성을 학습하게 된다. </li>
<li> Moex도 AFD에서는 성능이 떨어짐. AFD는 Teacher와 Student의 feature 쌍으로 지식을 증류하는데, 학생 모델에만 적용하기 때문에 그럼. </li>
<li> MoEx의 Layer Index가 3일 때 최대의 성능을 냈다. </li>
<li> 하지만 from scratch인 모델에서는 Layer Index가 1(Stage가 1?)일 때 최대의 성능이었다. </li>
<li>  </li>
</ul>



































## 주요 내용 요약
### 여러 KD 기법들 비교
<li> KD </li>
<ul>
<li> 기본 아이디어 : 교사 모델의 soft출력을 학생 모델이 학습하도록 하여, 학생 모델이 더 작은 크기에서도 교사 모델과 유사한 성능을 내도록 유도하는 것. </li>
<li> 방법 : 교사 모델의 soft labels를 통해 학생 모델을 학습시키며, logits의 차이를 손실 함수로 계산해서 학생 모델이 교사 모델의 분류 패턴을 따르게 유도함. </li>
<li> 손실함수 : 학생 모델의 최종 출력에 대한 crossEntropy항 + 학생 모델의 출력 분포와 교사 모델의 출력 분포를 비교하는 KL_divergence 항 </li>
</ul>
<li> SP (Similarity-Preserving KD) </li>
<ul>
<li> 기본 아이디어 : 학생 모델이 교사 모델과 유사한 Feature Space를 유지하도록 유도하여 성능을 향상시킴 </li>
<li> 방법 : 교사 모델과 학생 모델 간의 Feature Map 간의 유사성을 유지하는 방향으로 loss function을 추가함. 즉, 같은 입력이라면 유사한 Feature Map을 추출하도록 함. </li>
<li> loss 함수 : 학생 모델의 최종 출력에 대한 CrossEntropy항 + 학생 모델과 교사 모델의 중간 Feature Map들 사이의 유사성 비교를 위한 Feature Similarity 항 (Cosine Similarity로 확인) </li>
</ul>
<li> AT (Attention Transfer) </li>
<ul>
<li> 기본 아이디어 : 교사 모델의 Attention Map을 학생 모델이 학습하여, 중요한 영역에 집중하는 방법을 습득함. </li>
<li> 방법 : 교사 모델의 특정 Layer에서 추출한 Attention Map을 손실 함수로 사용하여 학생 모델이 유사한 Attention Map을 가지도록 학습 </li>
<li> loss 함수 : 학생 모델의 출력과 실제 레이블간의 CrossEntropy + 교사 모델의 특정 레이어의 Attention Map과 학생 모델의 Attention Map의 유사성을 비교하는 MSE항. </li>
</ul>
<li> AFD (Attention based Feature Distillation) </li>
<ul>
<li> 기본 아이디어 : 교사와 학생 모델의 특성 맵 쌍 간의 유사성을 최대화하여 교사 모델이 중요하다고 생각한 특징을 학생 모델도 학습하게 함. </li>
<li> 방법 : 교사와 학생 모델의 특정 위치의 특성 맵 쌍을 비교하여 유사하게 유지되도록 손실 함수를 정의한다. </li>
<li> 주의 할 점 : 두 Feature Map 쌍을 비슷하게 유지하는 것은 네트워크 구조 상 비슷 한 위치에 있어야 한다. 또한 DataAugmentation을 적용 시 이 유사성을 어긋나게 할 수 있음. </li>
<li> loss 함수 : 학생 모델의 출력과 실제 레이블 간의 CrossEntropy + 교사 모델과 학생 모델의 Attention Map이 유사하도록 하는 Cosine Similarity항 + 특정 위치의 Feature Map 쌍의 유사도를 비교하여 일관성을 유지하는 Feature Similarity 항. </li>
</ul>
<li> AFDS (Attentive Feature Distillation with Selection) </li>
<ul>
<li> 기본 아이디어 : 교사 모델의 중요한 정보를 강조하여 선택적으로 학습하도록 유도한다. </li>
<li> 방법 : 교사 모델의 중요한 Feature Map을 선택(Selection)하여 학생 모델이 이를 학습하게 한다. 학생 모델이 불필요한 정보를 제외하고, 중요한 특성에 집중하게끔 손실 함수를 최적화한다. </li>
<li> loss 함수 : CrossEntropy 항 + 교사 모델에서 선택적으로 중요한 Attention Map만 추출하여 학생이 학습하게 하는 Selective Attention Matching항 + 특정 특성들만 유사하게 유지되도록 하는 Feature Selection Similarity항 </li>
</ul>


### 내가 이해한 AMD (Angular Margin Distillation)
<li> 교사 모델의 중간 층에서 Feature Map을 추출하여 Attention Map으로 변환. </li>
<li> 여기서 추출한 Feature Map하나로 한 쌍의 Positive, Negative Map을 만들면 AMD(g)이다. </li>
<li> AMD(g+l)은 추출한 Feature Map하나로, 전체를 이용해서 Positive, Negative Map한 쌍을 만들고, 이 Feature Map을 4등분 하여, 4개의 Positive, Negative Map을 만들어 총 5쌍을 만들고, 각각에 같은 가중치를 주는 방식이다. </li>
<li> 그 Attention Map을 f라 하고, Positive Map은 f / |f|로 나타냄. Negative Map은 1 - f / |f|임. </li>
<li> 학생 모델에서도 비슷한 위치에 있는 Feature Map을 추출하여 위와 같이 Positive Map과 Negative Map을 생성함. </li>
<li> 교사 모델이 만들어낸 Positive map과 Negative Map 사이의 Angular Distance를 학생 모델이 따라할 수 있도록 A_loss항을 추가한다. </li>
<li> 이 때 Angular Margin을 도입하여, Positive Map과 Negative Map사이의 각도가 더 커지게 만들어서, 학생 모델이 좀 더 확실하게 학습할 수 있게 해준다. </li>
<li> 교사 모델이 만들어낸 Positive Map과 학생 모델이 만들어낸 Positive Map 간의 차이를 비교하는 손실 항도 추가함. </li>
<li> 교사 모델이 만들어낸 Negative Map과 학생 모델이 만들어낸 Negative Map 간의 차이를 비교하는 손실 항도 추가함. </li>
<li> 즉, 최종 AMD의 loss는 (학생 모델의 최종 출력에 대한 CrossEntropy항 + 교사 모델의 출력 logits과 학생 모델의 출력 logits의 분포를 비교하는 KL_Divergence항 + Angular Margin을 이용한 Positive, Negative Map들을 비교하는 AM_Loss항) 으로 나타낼 수 있다. </li>


## 두 번째 논문
### AMC Loss를 사용해보아라 (Angular Margin Contrastive)
<li> 이미지 분류에서 제일 주로 쓰이는게 Cross_entropy인데, 이는 단순히 예측한 클래스와 실제 클래스가 다른 경우에 패널티를 부여하는 방식이다. </li>
<li> 그렇기에 각 클래스 간의 명확한 구분이나, 동일 클래스 내에서의 데이터 밀집성을 충분히 고려하지 않는다는 한계가 있다. </li>
<li> 그래서 Center Loss와 Contrastive Loss같은게 발견됨. </li>
<li> Center Loss와 Contrastive Loss는 모두 Feature Clustering의 품질을 향상시키는 데 도움을 주지만, 각기 다른 한계점이 존재한다. </li>
<li> Center Loss는 클래스 내의 밀집도는 높일 수 있지만, 클래스 간의 분리가 부족하고, </li>
<li> Contrastive loss는 클래스 간의 분리도는 높이지만, 데이터 샘플의 쌍을 만드는데 계산 복잡도가 늘어나서 학습 속도가 느려질 수 있다. </li>
<li> 이와 같은 방식들은 Euclidean metric(유클리드 거리)에 의존한다. </li>
<li> 하지만, ~~한 연구들에 의해 검증되었는데, Cross Entropy를 통해 학습된 deep features는 본질적으로 각도 기반의 분포를 가진다. </li>
<li> 즉, 위 두 Center Loss와 Contrastive Loss는 두 가지 문제점이 있다. </li>
<li> Center Loss는 Crossentropy와 함께 써야 하는데, CrossEntropy를 통해 학습된 features는 각도 기반의 분포를 갖는데 반해 Center Loss는 Euclidean distance를 이용한 방식이다. </li>
<li> Contrastive Loss는 데이터 쌍을 구성해야 하는데, 대규모 데이터에서는 너무 오래 걸린다. </li>
<li> 그래서 이 논문에서는 Contrastive loss의 약점을 해결하기 위해 새로운 접근 방식을 제안한다. </li>
<ol>
<li> 첫 번째로, unit-Hilbert Hypershpere에 이미지를 매핑한다. </li>
<li> 학습된 특징이 가지는 각도 기반 분포 특성과 기하학적 속성을 더 잘 반영할 수 있다. </li>
<li> 이렇게 표현하면 Geodesic Distance(각도 기번 거리)를 측정하기에 더 잘 맞다. </li>
<li> 두 점간의 Geodesic Distance를 Closed-form의 형태로 계산할 수 있게 됨으로, 효율적으로 계산할 수 있어 학습 속도를 높일 수 있다. </li>
<li> 즉, Contrastive loss는 두 점 간의 거리를 비교하며 손실 값을 계산하는데, 데이터를 unit-hilbert Sphere에 옮김으로써, 더 쉽게 Geodesic Distance를 계산할 수 있고, Euclidean Distance보다 Feature에 더 잘 맞다. </li>
<li> 두 번째로, Contrastive loss는 데이터 두개를 쌍을 지어서 샘플링을 해야 한다고 했다. </li>
<li> 이 때 Doubly Stochastic Sampling(이중 확률 샘플링)방법을 사용하여, 데이터 쌍을 효율적으로 구성할 수 있게 해준다. </li>
<li> 이 Doubly Stochastic Sampling 덕분에 Contrastive loss 방식에서 데이터 쌍을 짓는 시간을 효과적으로 줄여줌. </li>
</ol>
<li> 뒤의 내용 요약 </li>
<ol>
<li> Grad-CAM을 통해 활성화 Map을 시각화함. </li>
<li> 세 가지 손실 함수를 비교할것임. </li>
<li> CrossEntropy : 객체의 중요한 부분에 주목하긴 하지만, 배경 정보에도 반응한다. </li>
<li> Euclidean Contrastive loss + CrossEntropy : 활성화 맵이 흐릿하고, 해석하기 어려운 결과임. (객체 부분을 명확히 구분 하지 못한 것 같음.) </li>
<li> AMC-Loss + CrossEntropy : 배경의 영향을 줄이면서, 객체의 특정 부분을 명확하게 구분해냈다. </li>
</ol>


## 주요 내용 요약
### Center Loss와 Contrastive Loss
<li> Center Loss  </li>
<ul>
<li> 동일한 클래스에 속한 데이터들이 특징 공간에서 서로 가까이 위치하도록 유도하는 손실 함수. </li>
<li> 이를 통해 동일한 클래스 내 데이터 간의 거리가 줄어들어, 클래스 내의 응집력이 높아진다. </li>
<li> 각 클래스에 대해 고유한 중심점을 정의하고, 데이터가 어떤 클래스에 속하면, 그 데이터의 Feature Vector가 해당 클래스의 중심점과 가까워지도록 Center Loss가 작용함. </li>
<li> Center Loss는 CrossEntropy와 함께 사용되며, CrossEntropy는 클래스 간의 분리를 담당하고, Center Loss는 클래스 내 데이터의 응집력을 담당한다. </li>
<li> 단점 : 클래스 간의 거리를 멀리 유지하는 기능이 부족하여 서로 다른 클래스 간의 분리가 부족하다. </li>
</ul>
<li> Contrastive Loss </li>
<ul>
<li> 쌍으로 구성된 데이터 간의 거리를 학습하는 손실 함수임. </li>
<li> 두 데이터가 같은 클래스에 속하는지 여부에 따라 손실 값이 달라지며, 주로 유사한 데이터 간의 거리를 줄이고, 다른 클래스의 데이터는 거리가 증가하게 설계됨. </li>
<li> 두 데이터 쌍을 입력으로 받고, 두 샘플이 같은 클래스라면 가까워지게, 다른 클래스라면 멀어지게 학습한다. </li>
<li> 단점 : 데이터 쌍을 구성해야 학습을 할 수 있는 방법인데, 데이터의 개수가 커질 수록 계산 비용이 가파르게 증가한다. </li>
</ul>

### background
<li> Cross-Entropy Loss </li>
<ul>
<li> 아주 어려운 수식이었구나 너 나같은 인간은 알아볼 수 조차 없구나 </li>
<li> CrossEntropy는 모델이 예측한 확률 분포와 실제 정답의 분파 간의 차이를 줄이는 방식으로 학습이 진행된다. </li>
<li> 이를 통해 모델은 각 클래스에 속할 확률을 정확하게 예측하도록 유도됨. </li>
<li> 수식을 살펴보면, Softmax를 통해 모델의 예측값을 확률 분포로 변환하고, log를 씌워서 Cross Entropy를 계산한다. </li>
</ul>
<li> CrossEntropy의 한계 </li>
<ul>
<li> 내재적 클래스 간 거리 최적화 부족 : Cross-Entropy는 각 샘플이 올바른 클래스에 속할 확률을 높이는 데 중점을 두지, 클래스 간의 거리를 충분히 멀리 떨어뜨리지는 못함. </li>
<li> 즉, 각 클래스가 서로 명확히 구분되도록 만드는 기능이 부족하다. (햇갈리는 것은 계속 햇갈리게 구분한다.) </li>
<li> 또한 클래스 내 변이가 큰 데이터가 있다면, 모델이 이를 잘 구분하지 못할 수도 있다.  </li>
</ul>
<li> Contrastive Loss </li>
<ul>
<li> 위의 CrossEntropy의 한계를 극복하기 위해 Contrastive loss가 등장함. </li>
<li> Contrastive Loss를 사용하면, 클래스 간의 분리를 강화하면서, 클래스 내의 응집도를 유지할 수 있다. </li>
<li> Contrastive Loss는 두 데이터 샘플 쌍이 같은 클래스일 때와 다른 클래스 일 때 다르게 계산된다. </li>
<li> 만약 같은 클래스라면 (S_ij = 1), 두 샘플 간의 거리가 최소화되도록 |x1 - x2|^2을 사용함. </li>
<li> 만약 다른 클래스라면 (s_ij = 0)이라면, 두 샘플 간의 거리가 최소한 m(마진)만큼 떨어지도록 max(0, m - |x1 - x2|^2)을 사용한다. </li>
<li> 다른 클래스라면 충분히 거리가 이미 떨어져 있다면 loss = 0, 아니라면 (m-거리)로 적용해서 더 떨어질 수 있도록 해주는 것임. </li>
<li> m(마진)은 클래스 간의 거리도 크게 유지할 수 있고, 심지어 같은 클래스의 샘플조차도 더 분리될 가능싱이 높아진다.(너무 가까이 뭉치지 않게 해줌.) </li>
</ul>
<li> Spherical-type Loss </li>
<ul>
<li> 기존의 contrastive loss는 유클리드 거리 기반이다. 그렇기 때문에, 심층 특징(깊의 layer에서의 feature)의 고유한 각도 기반 분포와의 호환성이 떨어진다. </li>
<li> 하지만 위에서 봤듯이, high-level features는 각도 기반으로 분포하는 경향이 있기 때문에, 호환성이 떨어진다. </li>
<li> Spherical-type Loss는 고수준 특징들의 각도 기반 분포 특성을 고려하여 설계된 손실 함수들이다. </li>
<li> Weiyang이 SphereFace라는 방법을 통해 심층 특징과 가중치 간의 각도를 고려하는 방식을 제안함. </li>
<li> 이진 분류의 경우 결정 경계에서 각도와 관련된 cos(m∂) 표현을 사용하여 클래스 간 구분을 더 명확히 한다. </li>
<li> 여기서 m은 각도 마진을 제어하는 역할을 하며, 클래스 간의 분리를 더 강화한다. </li>
<li> Spherical Softmax는 기존의 softmax의 지수함수가 아닌 2차 함수를 사용한다. </li>
<li> Taylor Softmax는 2차 Taylor 전개를 사용함. </li>
<li> 이렇게 하면, 모든 logit을 계산하지 않고도 정확한 Gradient를 계산할 수 있다. </li>
</ul>

### Proposed Method
<li> 제안된 방식(네트워크 구조) </li>
<ul>
<li> CNN 아키텍처 개요 : 3x3 conv층을 세번 거침. </li>
<li> 사이사이에 두번 2x2 maxpooling을 거쳐서 특성 맵 크기를 반으로 줄임. </li>
<li> Conv층들이 끝나면, GAP(Global Average Pooling)을 통해 1차원 벡터(Deep Feature)로 변환함. </li>
<li> 이 Deep Feature를 고차원 구에 투영해서 각도 기반 특징으로 생성한다. </li>
<li> AMC-Loss랑 CrossEntropy Loss를 통해 파라미터를 업데이트한다. </li>
</ul>
<li> AMC - Loss가 학습 중에 어떻게 작동하는가? </li>
<ul>
<li> 각 이미지의 Feature Vector는 단위 벡터로 정규화되어 초구 위의 점으로 표현된다. </li>
<li> 이 초구 표현을 통해 모델은 각도 기반으로 특징을 학습하며, 클래스 간의 구분을 더욱 명확히 할 수 있다. </li>
<li> 두 점 z1과 z2의 측지 거리는 내적의 역연산을 통해서 얻을 수 있다. </li>
<li> 두 점이 동일한 클래스에 속하면 가까운 위치에, 다른 클래스에 속하면 먼 위치에 있도록 조정한다. </li>
<li> 학습 과정에서 AMD Loss를 통해서 같은 클래스의 특징 벡터는 서로 가깝게(축지 거리가 작음), 다른 클래스의 벡터는 멀리 떨어지도록(측지 거리가 큼) 조정하여 클래스 간 구분을 강화한다. </li>
</ul>
<li> AMC - Loss가 무엇인가? </li>
<ul>
<li> AMC Loss (L_A는 Contrastive Loss와 비슷해보인다.) </li>
<li> Euclidean 거리를 사용하던 것이 각도 거리로 변했고 </li>
<li> 두 클래스가 다를 때 Euclidean Margin을 사용하던 것을 각도 마진으로 변경함. </li>
<li> 이를 통해 두 데이터 샘플이 같은 클래스라면, 두 샘플의 각도 거리를 줄이는 방향으로 학습이 진행되고 </li>
<li> 두 샘플이 다른 클래스라면 두 샘플의 각도 거리를 넓히는 방향으로 학습이 진행될 것이다. </li>
</ul>
<li> AMC에서의 계산 비용 문제 </li>
<ul>
<li> 학습 데이터 쌍의 크기가 커서 전체 학습 세트에 대해서 파라미터를 업데이트 하는 대신에 미니배치에 기반하여 업데이트를 수행한다. </li>
<li> 하지만, 이 CNN모델은 AMC_Loss와 CrossEntropy를 함께 사용하여 경사 하강법을 통해 반복적으로 최적화된다. </li>
<li> 즉, 미니배치라도 배치 내 모든 샘플 조합에 대한 측지 거리를 계산해야 하기 때문에, 여전히 계산이 부담이 된다. </li>
<li> 구체적으로 미니배치 내에 n개의 샘필이 있다면 O(n^2)의 샘플 쌍을 맺고, O(p)만큼의 측지 거리 계산 비용이 발생해서 총 O(n^2p)의 시간이 걸림. </li>
<li> 이 때문에 doubly stochastic sampled data pairs 방식을 통해 측지 거리를 계산함. </li>
</ul>
<li> Doubly Stochastic Sampled Data Pairs : 이중 확률적 샘플링 데이터 쌍 </li>
<ul>
<li> 미니 배치를 하나 만든다. n개의 크기 </li>
<li> 정확히 반으로 두 그룹으로 나눔. n/2, n/2 </li>
<li> Combination이 아닌 그냥 1대1 대응으로 샘플 쌍을 생성한다. </li>
<li> O(np/2) 까지 계산 비용을 줄일 수 있다. </li>
<li> 또 한 이 방법은 사전에 데이터 쌍을 미리 구성해 놓을 필요 없이, 학습 중에 실시간으로 샘플 쌍을 구성하고, S_ij(두 데이터가 같은 클래스인지)도 네트워크의 예측에 의해 정할 수 있다. </li>
</ul>
<li> 이 과정을 간략하게 보여주는 수도 코드가 있다. </li>

### Experiments
<li> AMC와 Euclidean Contrastive loss 방식을 비교하기 위한 여러 하이퍼파라미터들 정의 </li>
<li> batch_size = 128, max_lr = 0.003, Adam Momentum(0.9, 0.999), Ramp up, ramp down 까지 모두 같고, 람다와 마진만 다르다 (람다도 똑같다.) </li>
<li> 두 방식의 클러스터링 성능을 동질성(Homogeneity)와 완전성(Completeness)를 통해 평가함. </li>
<ul>
<li> 동질성 : 동일한 클래스의 데이터만이 한 클러스터에 포함되도록 하는 성질. 각 클러스터가 오직 하나의 클래스만 포함할 때 높아진다. 클래스 간 구분이 잘 되면 높은 값을 가짐. </li>
<li> 완전성 : 주어진 클래스에 속하는 모든 데이터가 하나의 클러스터 내에 포함되도록 하는 성질이다. 하나의 클래스가 여러 클러스터로 분산되지 않고, 하나의 클러스터에 잘 모인다면 완전성이 높아짐. </li>
</ul>
<li> 이 논문에서는 Cross Entropy만 사용했을 때, Euclidean Contrastive loss와 CE를 사용했을 때, AMC_Loss와 CE를 사용했을 때를 t-SNE와 Feature Visualization을 통해 보여줌. </li>
<li> 당연히 AMC + CE일 때 시각적으로도 잘 분리되고, 잘 뭉친것 처럼 보임. </li>
<li> p-value를 통한 성능 향상 확인 </li>
<ul>
<li> +AMC_Loss와 +Eucd 간의 p-value를 통해 얼마나 유의미하게 성능이 향상되었는지 알아봄. </li>
<li> p-value가 0.05 미만이면 우연이 아닌 통계적으로 유의미하다고 볼 수 있는데, SVHN이랑 CIFAR100과 같은 대규모 데이터셋에서 p-value가 매우 낮게 나옴. (통계적으로 유의미했다.) </li>
</ul>
<li> 또한 각 방법론에 대한 Activation Map을 보면, +AMC_Loss 가 객체에 더 집중하고, 배경을 잘 무시하는 것이 보인다. </li>
<li> Parameter Tuning에 대해서 </li>
<ul>
<li> λ는 CrossEntropy와 AMC_Loss 사이의 가중치 비율을 조정하는 역할을 한다. </li>
<li> λ값이 클수록 AMC-Loss 비중이 커지고, 작을수록 CrossEntropy 비중이 커진다. </li>
<li> 이 논문에서의 최적의 λ값 테스트 방법 : 각도 마진(mg)를 고정 후 λ값을 1 ~ 0.001까지 조정하여 성능을 평가함. </li>
<li> 이 논문에서의 최적의 mg값 테스트 방법 : λ= 0.1로 고정한 상태에서, 각도 마진을 0.5 ~ 1.5까지 조정하여 서로 다른 클래스 간의 분리 성능을 평가함. </li>
</ul>


### 중요한 것 같은거
<li> 논문의 주요 흐름 </li>
<ol>
<li> CrossEntropy는 high level features를 거리 기반으로 학습을 시도하기 때문에 각도 기반으로 분포되어있는 high level features를 제대로 학습하지 못한다. </li>
<li> 그래서 Center Loss와 Contrastive Loss가 나왔다. </li>
<li> Center Loss는 클래스 내부의 데이터들이 잘 뭉치게는 하지만, 클래스 간의 거리를 멀게 하지는 못함. Contrastive Loss는 클래스 내부의 데이터들을 잘 뭉치게도 하고, 클래스 간의 거리도 잘 멀게 하지만, 모든 데이터 쌍 조합을 통해 학습을 해야해서 비용이 너무 많이 든다. </li>
<li> 그래서, mini-batch를 통한 Contrastive Loss가 등장함. (그래도 combination을 하면 n^2까지 커져서 쉽지 않다,) </li>
<li> 그래서 Doubly Stochastic Sampled Data Pairs(이중 확률적 샘플링 데이터 쌍)이 나옴. 이거는 미니 배치를 반으로 나눈 뒤, Combination 조합이 아닌, 일대일 대응으로만 데이터 쌍을 만들어서 비용을 줄일 수 있다. </li>
<li> Angular Margin과 Contrastive loss를 합친 AMC Loss를 제시한다. (Doubly Stochastic Sampled Data Pairs를 사용함.) 이거는, GAP를 통해 만들어진 Feature Vector를 고차원 구에 Embedding한 뒤, 각도 거리?(두 Feature vector(x1, x2)를 unit vector화 하고, 내적의 역연산을 통해 각도를 알아냄)의 제곱을 손실항으로 둬서, 같은 클래스라면 이 각도 거리를 줄이는 방향으로 학습하고, 다른 클래스라면 이 각도 거리를 늘리는 방향(Angular Margin보다 크게)으로 손실을 줘서 학습을 하게 하는 방식임 </li>
<li> 물론 이 방법도 CrossEntropy와 같이 적용함. </li>
</ol>


### PCA와 SVD
<li> PCA(Principal Component Analysis) </li>
<ul>
<li> PCA는 고차원 데이터에서 주요 정보를 유지하면서 차원을 축소하는 기법이다. (주요 성분을 뽑아내는 방식으로, 데이터의 분산을 최대화하는 방향을 찾아 원래 데이터의 정보 손실을 최소화하며 축소함.) </li>
<li> 주성분(Principal Components)는 데이터의 분산이 가장 큰 방향으로 먼저 설정됨. </li>
<li> 이 주성분을 찾기 위해 공분산 행렬을 고유값(Av = λv, λ가 고유값, v가 고유벡터) 분해하여, 가장 고유값(분산)이 큰 고유 벡터를 선택함. 그 다음 성분은 이 주성분과 직교하고, 두번째로 큰 분산을 가진 방향을 선택함. </li>
<li> 이미지 데이터나 텍스트 데이터와 같은 고차원 데이터를 2D or 3D로 축소하여 시각화하면, Cluster를 파악하기 쉽다. </li>
<li> t-SNE는 비선형 관계를 잘 표현하여 복잡한 구조를 시각화 하는데 좋고, PCA는 선형 변환을 기반으로 하며 빠르고, 계산 효율성이 좋다. 복잡한 구조를 잡아내긴 힘들다. </li>
</ul>

![PCA](https://github.com/wjdwocks/ML-DNN/raw/main/markdown/24.11.13/PCA.jpg)

<li> SVD (Singular Value Decomposition) </li>
<ul>
<li>  </li>
</ul>


## Trainning Environment
<li> Dataset = Cifar10, CINIC10, Tiny ImageNet </li>
<li> python = 3.8.18 </li>
<li> pytorch = 2.4.1 + CUDA ??? </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 20 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.0005 </li>
<li> optimizer = Adam </li>



## Evaluation


## Results