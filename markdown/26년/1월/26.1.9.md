Channels 방식으로
Training에서 CE_loss를 제거. → 이거는 무조건
Tokenizer도 불러오지 말자.   → 이거도 무조건

codebook 개수를 줄여보자.   4개 ~ 8 16 32 까지도.. (하나씩 나아가자.) 
Hyperparameter 여러번 수정해가면서 실행. (Codebook 고도화가 잘 되도록 (Acc는 부수적))


Acc보다는 Codebook 및 Sub-Sequence를 잘 만드는것을 목표로 한다는 느낌.


원본과 recon된것의 MSE도 비교?


Classification CE_loss를 빼고, 하이퍼파라미터를 잘 바꿔서 Codebook 학습이 되게 한 뒤, Epoch을 늘려서 결과를 확인해보자.