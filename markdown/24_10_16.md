## 24.10.16 공부한 내용
<li> 파이토치를 통한 인공 신경망 학습을 이해하고, MNIST, CIFAR-10의 분류 데이터셋을 Convolution Layer와 Linear Layer를 통하여 학습을 해보고, 여러 HyperParameter에 대해 결과를 비교해본다.</li>

## MNIST, CIFAR-10 Datasets
<li> MNIST는 0 ~ 9까지의 손글씨 그림(10개의 클래스, 28 x 28, 1channel(gray)), 60000개의 Train_set, 10000개의 test_set으로 이루어져 있다.</li>
<li>CIFAR-10 60000개의 컬러 이미지 (10개의 클래스, 32 x 32, 3channel(R, G, B))로 이루어져 있다. Train_set는 50000개, Test_set는 10000개가 있다.</li>

## 내가 작성한 학습 모델 - MNIST
<ol> 
<li><strong>Conv2D(1, 10, kernel_size=3, padding='same')</strong>: 입력 채널 1개(흑백 이미지), 필터의 개수를 10개로 하여 출력 채널 10개, kernel_size=3, padding을 samepadding으로 하여 특성맵의 크기를 원래의 크기와 같게 함.</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 크기의 필터로 공간 축소, 28 x 28 -> 14 x 14</li> 
<li><strong>ReLU()</strong>: 활성화 함수로 비선형성 추가</li> 
<li><strong>Conv2D(10, 32)</strong>: 입력 채널 10개, 출력 채널 32개</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 필터로 추가 다운샘플링, 14 x 14 -> 7 x 7</li> 
<li><strong>ReLU()</strong>: 비선형성 추가</li> 
<li><strong>Flatten()</strong>: 2D 출력을 1D 벡터로 변환</li> 
<li><strong>Linear(7*7*32, 100)</strong>: 완전 연결층, 입력 7x7x32개, 출력 100개</li> 
<li><strong>ReLU()</strong>: 활성화 함수 적용</li> 
<li><strong>Dropout(0.3)</strong>: 출력 뉴런 중 30%를 비활성화하여 각 뉴런들이 끼치는 영향을 고루게 하여 과적합을 방지함.</li>
<li><strong>Linear(100, 10)</strong>: 출력층, 10개 클래스에 대한 확률 출력 (MNIST 숫자 0~9)</li> </ol>

## 내가 작성한 학습 모델 - Cifar-10
<ol> 
<li><strong>Conv2D(3, 15, kernel_size=3, padding='same')</strong>: 입력 채널 3개 (RGB 이미지), 출력 채널 15개</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 크기의 필터로 공간 축소, 32 x 32 -> 16 x 16</li> 
<li><strong>ReLU()</strong>: 활성화 함수로 비선형성 추가</li> 
<li><strong>Conv2D(10, 45, kernel_size=3, padding='same')</strong>: 입력 채널 15개, 출력 채널 45개</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 필터로 추가 다운샘플링, 16 x 16 -> 8 x 8</li> 
<li><strong>ReLU()</strong>: 비선형성 추가</li> 
<li><strong>Flatten()</strong>: 2D 출력을 1D 벡터로 변환</li> 
<li><strong>Linear(8*8*45, 100)</strong>: 완전 연결층, 입력 8*8*45개, 출력 100개</li> 
<li><strong>ReLU()</strong>: 활성화 함수 적용</li> 
<li><strong>Dropout(0.3)</strong>: 출력 뉴런 중 30%를 비활성화하여 각 뉴런들이 끼치는 영향을 고루게 하여 과적합을 방지함.</li>
<li><strong>Linear(100, 10)</strong>: 출력층, 10개 클래스에 대한 확률 출력 (cifar-10 각 클래스.)</li> </ol>

## 파이토치에서 학습 과정
<ol>
<li>데이터셋을 학습하기 전에 전처리할 파이프라인을 구성함. transform = transforms.Compose([ # 파이프 라인을 만듦.
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])</li>
<li>데이터 샘플을 가져온다. train_dataset = torchvision.datasets.FashionMNIST(
		root='./fashionMNIST',
		train=True,
		download=True,
		transform=transform) # test_dataset도 이와 비슷하게 함.</li>
<li>학습 데이터를 검증 데이터 세트로 나눈다.
	train_size = int(0.8 * len(train_dataset))
	val_size = len(train_dataset) - train_size
	train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size]) # 20%만 떼어줌.</li>
</ol>


## Trainning Environment
<li> python = 3.8.18 </li>
<li> pytorch = 1.13.0+cu117 </li>
<li> GPU = Intel(R) Iris(R) Xe Graphics </li>
<li> CPU = 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz, 2419Mhz, 4 코어, 8 논리 프로세서 </li>
<li> epoch = 20 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.001 </li>
<li> optimizer = Adam </li>

## Evaluation
|      Methods           |    MAE    |   MAP    |
|      -------           |   ----    |   ----   |
|     Retinanet          |  4.634    |  10.449  |
|     Faster RCNN        |  3.312    |  10.297  |
|     RepPoints          |  1.471    |  3.436   |
|     Centernet          |  0.766    |  1.981   |
|     Mada-Centernet     |  0.696    |  1.806   |
|     Proposed Centernet |  0.640    |  1.602   |

## Results
<li> 실험 결과를 통해, 제안한 로컬 어텐션 기반의 MaDa-CenterNet(Local Attention)이 기존의 MaDa-CenterNet의 성능을 개선할 수 있었으며 제안한 로컬 어텐션 모델이 해충 카운팅에 효과적임을 입증하였다. </li>
<img src="./image/Result_image.png"/>
