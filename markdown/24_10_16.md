## 24.10.16 공부한 내용
<li> 파이토치를 통한 인공 신경망 학습을 이해하고, MNIST, CIFAR-10의 분류 데이터셋을 Convolution Layer와 Linear Layer를 통하여 학습을 해보고, 여러 HyperParameter에 대해 결과를 비교해본다.</li>

## MNIST, CIFAR-10 Datasets
<li> MNIST는 0 ~ 9까지의 손글씨 그림(10개의 클래스, 28 x 28, 1channel(gray)), 60000개의 Train_set, 10000개의 test_set으로 이루어져 있다.</li>
<li>CIFAR-10 60000개의 컬러 이미지 (10개의 클래스, 32 x 32, 3channel(R, G, B))로 이루어져 있다. Train_set는 50000개, Test_set는 10000개가 있다.</li>

## 내가 작성한 학습 모델 - MNIST
<ol> 
<li><strong>Conv2D(1, 10)</strong>: 입력 채널 1개(흑백 이미지), 출력 채널 10개</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 크기의 필터로 공간 축소, 28 x 28 -> 14 x 14</li> 
<li><strong>ReLU()</strong>: 활성화 함수로 비선형성 추가</li> 
<li><strong>Conv2D(10, 32)</strong>: 입력 채널 10개, 출력 채널 32개</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 필터로 추가 다운샘플링, 14 x 14 -> 7 x 7</li> 
<li><strong>ReLU()</strong>: 비선형성 추가</li> 
<li><strong>Flatten()</strong>: 2D 출력을 1D 벡터로 변환</li> 
<li><strong>Linear(7*7*32, 100)</strong>: 완전 연결층, 입력 7x7x32개, 출력 100개</li> 
<li><strong>ReLU()</strong>: 활성화 함수 적용</li> 
<li><strong>Linear(100, 10)</strong>: 출력층, 10개 클래스에 대한 확률 출력 (MNIST 숫자 0~9)</li> </ol>

## Trainning Environment
<li> python = 3.8.18 </li>
<li> pytorch = 1.13.0+cu117 </li>
<li> GPU = A100 </li>
<li> CPU = Intel(R) Xeon(R) Gold 5317 CPU @ 3.00GHz </li>
<li> epoch = 100 </li>
<li> batch size = 8 </li>
<li> learning rate = 0.001 </li>
<li> optimizer = Adam </li>

## Evaluation
|      Methods           |    MAE    |   MAP    |
|      -------           |   ----    |   ----   |
|     Retinanet          |  4.634    |  10.449  |
|     Faster RCNN        |  3.312    |  10.297  |
|     RepPoints          |  1.471    |  3.436   |
|     Centernet          |  0.766    |  1.981   |
|     Mada-Centernet     |  0.696    |  1.806   |
|     Proposed Centernet |  0.640    |  1.602   |

## Results
<li> 실험 결과를 통해, 제안한 로컬 어텐션 기반의 MaDa-CenterNet(Local Attention)이 기존의 MaDa-CenterNet의 성능을 개선할 수 있었으며 제안한 로컬 어텐션 모델이 해충 카운팅에 효과적임을 입증하였다. </li>
<img src="./image/Result_image.png"/>
