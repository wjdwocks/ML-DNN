## 24.10.16 공부한 내용
<li> 파이토치를 통한 인공 신경망 학습을 이해하고, MNIST, CIFAR-10의 분류 데이터셋을 Convolution Layer와 Linear Layer를 통하여 학습을 해보고, 여러 HyperParameter에 대해 결과를 비교해본다.</li>

## MNIST, CIFAR-10 Datasets
<li> MNIST는 0 ~ 9까지의 손글씨 그림(10개의 클래스, 28 x 28, 1channel(gray)), 60000개의 Train_set, 10000개의 test_set으로 이루어져 있다.</li>
<li>CIFAR-10 60000개의 컬러 이미지 (10개의 클래스, 32 x 32, 3channel(R, G, B))로 이루어져 있다. Train_set는 50000개, Test_set는 10000개가 있다.</li>

## 내가 작성한 학습 모델 - MNIST
<ol> 
<li><strong>Conv2D(1, 10, kernel_size=3, padding='same')</strong>: 입력 채널 1개(흑백 이미지), 필터의 개수를 10개로 하여 출력 채널 10개, kernel_size=3, padding을 samepadding으로 하여 특성맵의 크기를 원래의 크기와 같게 함.</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 크기의 필터로 공간 축소, 28 x 28 -> 14 x 14</li> 
<li><strong>ReLU()</strong>: 활성화 함수로 비선형성 추가</li> 
<li><strong>Conv2D(10, 32)</strong>: 입력 채널 10개, 출력 채널 32개</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 필터로 추가 다운샘플링, 14 x 14 -> 7 x 7</li> 
<li><strong>ReLU()</strong>: 비선형성 추가</li> 
<li><strong>Flatten()</strong>: 2D 출력을 1D 벡터로 변환</li> 
<li><strong>Linear(7*7*32, 100)</strong>: 완전 연결층, 입력 7x7x32개, 출력 100개</li> 
<li><strong>ReLU()</strong>: 활성화 함수 적용</li> 
<li><strong>Dropout(0.3)</strong>: 출력 뉴런 중 30%를 비활성화하여 각 뉴런들이 끼치는 영향을 고루게 하여 과적합을 방지함.</li>
<li><strong>Linear(100, 10)</strong>: 출력층, 10개 클래스에 대한 확률 출력 (MNIST 숫자 0~9)</li> </ol>

## 내가 작성한 학습 모델 - Cifar-10
<ol> 
<li><strong>Conv2D(3, 15, kernel_size=3, padding='same')</strong>: 입력 채널 3개 (RGB 이미지), 출력 채널 15개</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 크기의 필터로 공간 축소, 32 x 32 -> 16 x 16</li> 
<li><strong>ReLU()</strong>: 활성화 함수로 비선형성 추가</li> 
<li><strong>Conv2D(10, 45, kernel_size=3, padding='same')</strong>: 입력 채널 15개, 출력 채널 45개</li> 
<li><strong>MaxPooling(2, 2)</strong>: 2x2 필터로 추가 다운샘플링, 16 x 16 -> 8 x 8</li> 
<li><strong>ReLU()</strong>: 비선형성 추가</li> 
<li><strong>Flatten()</strong>: 2D 출력을 1D 벡터로 변환</li> 
<li><strong>Linear(8*8*45, 100)</strong>: 완전 연결층, 입력 8*8*45개, 출력 100개</li> 
<li><strong>ReLU()</strong>: 활성화 함수 적용</li> 
<li><strong>Dropout(0.3)</strong>: 출력 뉴런 중 30%를 비활성화하여 각 뉴런들이 끼치는 영향을 고루게 하여 과적합을 방지함.</li>
<li><strong>Linear(100, 10)</strong>: 출력층, 10개 클래스에 대한 확률 출력 (cifar-10 각 클래스.)</li> </ol>

## 파이토치에서 학습 과정
<ol>
<li>데이터셋을 학습하기 전에 전처리할 파이프라인을 구성함. transform = transforms.Compose([ # 파이프 라인을 만듦.
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])</li>
<li>데이터 샘플을 가져온다. train_dataset = torchvision.datasets.FashionMNIST(
		root='./fashionMNIST',
		train=True,
		download=True,
		transform=transform) # test_dataset도 이와 비슷하게 함.</li>
<li>학습 데이터를 검증 데이터 세트로 나눈다.
	train_size = int(0.8 * len(train_dataset))<br>
	val_size = len(train_dataset) - train_size<br>
	train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size]) # 20%만 떼어줌.</li>
<li>각 데이터 세트를 배치단위로 나누어준다. 
	train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True) <br>
	test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True) <br>
	val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)
</li>
<li>위에서 만든 모델대로 모델 객체를 만든다. model = myModel()</li>
<li>optimizer와 criterion을 정의함.<br>
optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 모델의 학습 가능한 파라미터들을 미리 알려주어 학습 과정에서 업데이트할 대상으로 지정한다.<br>
- 미리 옵티마이저가 파라미터를 알지 못하면 어떤 값을 업데이트해야 할지 모름.<br>
	criterion = nn.CrossEntropyLoss() # 모델의 예측과 실제 정답 간의 차이를 계산하는 손실 함수를 정의하는 역할을 함.
</li>
<br>
<li>def train_model() 함수를 작성하여 모델의 학습 과정을 정의함.<br>
1. 각 epoch를 시작하기 전에 설정할 것 설정. patience=0, min_val_loss = float('inf'), best_model = model.state_dict()<br>
2. 각 epoch에 들어가서, 모델을 train()모드로 변환하고, 계산할 train_loss, train_correct, train_total을 초기화해줌.<br>
3. 각 datasets의 batch_size만큼씩 불러오며 inputs과 targets로 나누어서 dataloader를 반복한다.<br>
4. 각 반복당 optimizer의 가중치 기울기를 0으로 초기화 -> 모델의 Forward를 진행하며 모델의 예측값을 계산한다. -> 계산한 예측값과 target값을 이용하여 loss를 계산한다. -> loss를 가지고, backward()를 하여, 손실값을 기준으로 각 파라미터의 기울기를 계산한다. -> 계산한 기울기로 optimizer가 파라미터를 업데이트한다.<br>
5. 이번 batch_size에서의 train_loss를 누적해서 더해주고, train_correct, train_total을 누적해서 더해준다.<br>
6. 계산한 값들을 가지고, 이번 epoch의 train_loss, train_accuracy를 구한다.<br>
7. 모델을 model.eval()로 검증 모드로 변환하고, with torch.no_grad():를 통해 파라미터의 기울기를 변환하지 않으면서, 검증을 진행한다.<br>
8. 각 epoch의 마지막에 val_loss를 기준으로 min_val_loss보다 작다면, patience = 0으로 초기화 해주고, val_loss가 증가했다면, patience += 1을 통해 늘려주고, max_patience에 다다르면, 더이상의 학습을 종료하고, 최적의 model_state를 저장한다.<br>
9. test_loader에 대해서도 val_loader에서 했던 것처럼 학습을 진행해보고, 결과를 받아본다.
</li>
</ol>


## 각 Optimizer 비교
<li>Adam : SGD와, Momentum, RMSprop, Adagrad의 개념을 결합한 옵티마이저임.</li>
<li>Adagrad : 각 파라미터마다 학습률을 개별적으로 조정하여 학습 속도를 최적화한다.</li>
<li>RMSprop : 기울기 제곱에 대한 지수 이동 평균(EMA)를 기울기의 2차 모멘트를 추적하여 학습률 조정 (뭔소린지 모르겠음)</li>
<li>SGD : batch 또는 데이터 샘플을 사용하여 기울기를 계산하고, 그 기울기로 파라미터 업데이트</li>
<li>SGD+momentum : 모멘텀을 추가하면, 이전 업데이트 값의 일정 비율을 가중치로 더하면서 업데이트를 한다.</li>
<br>

| Optimizer  | 학습률 조정 방식        | Momentum | 적합한 문제                         |
|-------------|-------------------------|-------------|-------------------------------------|
| SGD         | 고정 학습률             | 없음        | 단순한 데이터셋                    |
| Momentum    | 고정 학습률             | 사용        | 빠른 수렴이 필요한 경우            |
| Adagrad     | 파라미터마다 다른 학습률 | 없음        | 드문드문한(sparse) 특징 학습        |
| RMSprop     | 지수 이동 평균 사용     | 없음        | 비정규화된 데이터셋, RNN 등        |
| Adam        | RMSprop + Momentum      | 사용        | 대부분의 딥러닝 모델               |

## Trainning Environment
<li> python = 3.8.18 </li>
<li> pytorch = 2.4.1+cpu </li>
<li> GPU = Intel(R) Iris(R) Xe Graphics </li>
<li> CPU = 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz, 2419Mhz, 4 코어, 8 논리 프로세서 </li>
<li> epoch = 20 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.001 </li>
<li> optimizer = Adam (Adagrad, RMSprop, SGD, SGD+Momentum 도 사용.) </li>



## MNIST데이터셋, Adam에서 lr = 0.01, 0.001, 0.0001 로 바꿔가며 돌려본 결과
<li>patience = 2로 주었더니, lr = 0.01에서와 lr = 0.001에서는 조기종료가 되었고, lr = 0.0001에서는 20epoch까지 모두 채웠다. val_accuracy는 lr = 0.0001일 때가 가장 높았다.</li>




## Evaluation
| Optimizer      | MNIST  | Cifar-10 |
|----------------|--------|----------|
| Adam           | 0.989  | 0.696    |
| Adagrad        | 0.879  | 0.495    |
| RMSprop        | 0.873  | 0.522    |
| SGD            | 0.806  | 0.404    |
| SGD+momentum   | 0.879  | 0.648    |

## Results
<li> 같은 구조를 가진 모델인데, MNIST와 Cifar-10에 Accuracy 차이가 너무 많이 났다. 그래서 Cifar-10에 대한 나의 모델이 잘못되었나 고민을 해보다가 VGG 라는 모델을 알게 되었는데, 이 VGG모델은 3x3 크기의 작은 커널을 엄청 사용하고, Convolution층도 매우 많고, Linear층을 3개정도 통과하는 아주 복잡한 모델이었다. 이런 모델로 Cifar-10을 학습했을 때 결과가 90%이상 나온다는 글을 보게 되었습니다. 그래서 내가 MNIST에서 얻은 그 Acc들은 이 Channel의 깊이가 1인 간단한 데이터셋이라서 높은 Acc를 얻은 것이었고, Cifar-10은 생각보다 어려운 데이터셋이라서 나의 간단한 모델로는 Acc가 낮게 나온다는 것을 알게 되었습니다. 또한 그런 글들을 보니 저는 Epoch 20을 기준으로 했는데 너무 낮은 수였다는것을 늦게 알았습니다.</li>
<img src='markdown/images/VGG_Cifar10.png'>
