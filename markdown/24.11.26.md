## 24.11.13 공부할 내용
<li> 첫 번째 논문 : Leveraging Topological Guidance for Improved Knowledge Distillation </li>
<li> 두 번째 논문 : Topological Persistence Guided Knowledge Distillation for Wearable Sensor Data </li>

## 첫 번째 논문
### Abstract 정리
<li> 이미지 분류 작업에서 복잡하고, 노이즈가 많은 데이터에서는 TDA를 활용해서 위상적 종보를 통해 성능과 견고성(robustness)을 개선할 수 있다. </li>
<li> 근데 소형 기기에서는 TDA의 계산량을 버틸 수가 없음. </li>
<li> 이 논문에서는 TGD(Topological Guidance-based Knowledge Distillation)이라는 프레임워크를 제안한다. </li>
<li> TGD는 TDA 기반의 topological information을 Knowledge Distillation에 확용하여 경량 모델을 학습시킨다. </li>
<li> 1. 경량 모델 학습 : KD를 통해 성능이 우수한 경량 모델 학습. </li>
<li> 2. 다수의 교사 모델 활용 : 여러 교사 모델로부터 위상 정보를 동시에 학습. </li>
<li> 3. 교사-학생 간 지식 격차 해소 : 교사 간 및 교사-학생 간의 지식 격차를 줄이기 위한 통합 메커니즘 제안. </li>

### Introduction 정리
<li> 연구 배경 및 문제점 </li>
<ul>
<li> 딥러닝은 컴퓨터 비전 작업에서 유용한 특징을 추출하고 복잡한 문제를 해결하는 데 있어 큰 성과를 보여줌. </li>
</ul>



## Trainning Environment
<li> Dataset = Cifar10, CINIC10, Tiny ImageNet </li>
<li> python = 3.8.18 </li>
<li> pytorch = 2.4.1 + CUDA ??? </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 20 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.0005 </li>
<li> optimizer = Adam </li>



## Evaluation


## Results