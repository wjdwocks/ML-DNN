## 24.11.13 공부할 내용
<li> 첫 번째 논문 : Leveraging Topological Guidance for Improved Knowledge Distillation </li>
<li> 두 번째 논문 : Topological Persistence Guided Knowledge Distillation for Wearable Sensor Data </li>

## 첫 번째 논문
### Abstract 정리
<li> 이미지 분류 작업에서 복잡하고, 노이즈가 많은 데이터에서는 TDA를 활용해서 위상적 종보를 통해 성능과 견고성(robustness)을 개선할 수 있다. </li>
<li> 근데 소형 기기에서는 TDA의 계산량을 버틸 수가 없음. </li>
<li> 이 논문에서는 TGD(Topological Guidance-based Knowledge Distillation)이라는 프레임워크를 제안한다. </li>
<li> TGD는 TDA 기반의 topological information을 Knowledge Distillation에 확용하여 경량 모델을 학습시킨다. </li>
<li> 1. 경량 모델 학습 : KD를 통해 성능이 우수한 경량 모델 학습. </li>
<li> 2. 다수의 교사 모델 활용 : 여러 교사 모델로부터 위상 정보를 동시에 학습. </li>
<li> 3. 교사-학생 간 지식 격차 해소 : 교사 간 및 교사-학생 간의 지식 격차를 줄이기 위한 통합 메커니즘 제안. </li>

### Introduction 정리
<li> 연구 배경 및 문제점 </li>
<ul>
<li> 딥러닝은 컴퓨터 비전 작업에서 유용한 특징을 추출하고 복잡한 문제를 해결하는 데 있어 큰 성과를 보여줌. </li>
<li> 실제 데이터는 구조적으로 복잡하고, 노이즈가 많아 학습 및 일반화 성능을 떨어뜨리는 경우가 많다. </li>
<li> TDA는 데이터의 위상적 구조를 분석하여 복잡한 데이터를 효과적으로 이해할 수 있도록 도와준다. (TDA를 기반으로 데이터의 위상적 특징을 PI로 표현을 한다.) </li>
<li> TDA는 계산량이 많아 소형 디바이스나 자원 제한이 있는 환경에서 적용하기 어렵다. </li>
</ul>
<li> 연구 동기 </li>
<ul>
<li> TDA의 강점 활용 : 위상적 특징은 데이터의 구조를 더 잘 표현하고, 기존 딥러닝 모델이 놓칠 수 있는 정보를 보완할 가능성이 있다. </li>
<li> 소형 디바이스에 적용 : 직접적으로 TDA를 계산하는 것이 불가능하기에 이를 간접적으로 학습시키는 방법이 필요하다. </li>
<li> Knowledge Distillation(KD)의 가능성 : 복잡한 Teacher 모델의 지식을 경량화된 Student모델에 전달하는 기법을 통해 위의 일들을 해결할 수 있을 것이다. </li>
</ul>
<li> 제안 방법 </li>
<ul>
<li> TGD라는 것을 제시한다. </li>
<li> TDA를 활용해 추출된 위상적 특징(Persistence Image)를 Teacher 모델이 학습함. </li>
<li> Student 모델은 Teacher 모델의 지식을 KD로 학습하고, 위상적 정보를 간접적으로 학습을 한 것이 됨. </li>
<li> Teacher1은 원본 이미지로 학습, Teacher2는 TDA로 얻은 PI를 기반으로 학습함. </li>
<li> 위 두 Teacher를 통해 소형 디바이스에서 위상적 특징의 장점을 활용하면서, 경량 모델의 성능을 극대화할 수 있다. </li>
</ul>
<li> 주요 기여 </li>
<ul>
<li> TDA 기반 정보 활용의 간소화 : TDA의 높은 계산량 문제를 해결하고, 위상적 특징을 효과적으로 전달할 수 있다. </li>
<li> 다중 Teacher를 활용하여 서로 다른 데이터 표현(PI, 원본)을 학습시킨다. </li>
<li> 경량 모델의 실용성 증대 : 소형 디바이스에서도 높은 성능을 유지하며, TDA의 장점을 활용 가능. </li>
</ul>
<li> TGD의 Loss </li>
<ul>
<li> 1. Student Logits Loss(CE) </li>
<li> 2. KL-Divergence Loss </li>
<ul>
<li> 이 논문에서의 KL Loss는 다중 교사를 사용하기 때문에 a(KL(T1, S)) + (1-a)KL(T2, S)를 사용함. </li>
</ul>
<li> 3. Similarity Loss : Teacher1과 Teacher2 간의 유사성 정보를 계산하여 두 Teacher로부터 유용한 정보를 모두 증류받는 것이 목표인듯. </li>
</ul>
<li> Similarity Loss에 관하여 </li>
<ul>
<li> 이 Similarity Loss는 다중 교사를 사용한 지식 증류 기법에서 여러 교사의 지식을 모두 전달하기 위한 방법이다. </li>
<li> 이 논문에서 Similarity Loss는 중간층에서 얻은 Feature map을 이용하여 계산하는 것 같다. </li>
<li> 우선 두 교사 모델의 중간층(같은 부분)의 Feature map을 얻어와서 가중합을 통한 새로운 Feature Map을 생성한다. </li>
<li> 이후, 학생 모델의 중간층에서도 Feature Map을 얻어와서 두 Feature Map을 행렬로 표현함. </li>
<li> |두 행렬의 차|^2을 통해 두 중간층 feature map이 최대한 비슷해지도록 유도한다. </li>
</ul>

## 두 번째 논문
### Abstract 정리
<li> 센서 데이터에서 TDA를 통한 Robust한 Feature를 사용하기 힘든 이유 </li>
<ol>
<li> TDA를 계산하는데 드는 엄청난 비용 </li>
<li> 딥러닝과 TDA에서 얻는 신호 표현 방식이 달라서 이들을 융합하는 것이 어렵다. </li>
</ol>
<li> 이 논문에서 제안하는 방법 </li>
<ol>
<li> 첫 번째 교사 네트워크 : row time-series 데이터를 학습함. </li>
<li> 두 번째 교사 네트워크 : TDA를 통해 얻어진 PI를 학습함. </li>
</ol>
<li> 이 방법의 이점(기대 효과?) </li>
<ul>
<li> 상호 보완정 정보 활용 : 여러 교사로부터 얻은 정보를 결합하여 풍부한 표현력을 가진 compact한 모델을 생성함. </li>
<li> 새로운 제약 조건 도입 : feature correlation map에 대한 직교성 제약을 적용하여 특징 표현력을 향상시키고, 학생 모델이 교사로부터 쉽게 학습할 수 있게 함. </li>
<li> 어닐링 전략 적용 : KD과정에서 Annealing(하이퍼 파라미터 점진적 조정)을 통해 빠른 수렴과 안정적인 학습을 가능하게 한다. </li>
</ul>

### Introduction 정리
<li> Sensor Data의 Robustness를 위하여 여기서도 두 교사 모델을 이용한 TGD를 제안한다. </li>
<li> 여기서도 마찬가지로, 두 교사 모델에서 중간층의 Feature map을 추출하여 합친 것과 학생 모델의 중간층에서 나온 Feature Map을 비교하려고 했다. </li>
<li> 그런데 Seonsor Data는 시계열 신호로, 개별 Feature Map의 값보다는 Feature 간의 관계가 더 중요한 경우가 많기 때문에, 중간 Layer의 Feature Correlation Map을 사용한다. </li>
<li> Sensor Data의 세 번째 Loss항은 Image와 애초부터 다르다. </li>
<li> Sensor Data는 각 특성 맵 자체가 중요한 것이 아닌, Feature들 간의 관계가 중요하기 때문에 Similarity Map(내부 특징들 간의 유사성)을 얻어온다. </li>
<li> 이렇게 얻은 두 교사의 Similarity Map을 합친다. </li>
<li> 합쳐진 Similarity Map을 k개의 map으로 쪼갠다.(고차원의 정보를 더 작은 단위로 나누어 처리하기 위함?) </li>
<li> K개의 Map을 더 작은 단위(Patch)로 분할한다. </li>
<li> Patch별로 직교성 제약(OF)를 적용하여 각 Patch가 독립적이고, 명확한 정보를 갖도록 변환한다. </li>
<li> 그래서 Orthogonality Features(GT)와 학생 모델의 Similarity Map을 Patch한 후 만들어진 Orthogonality Features(GS)를 비교하는 loss항을 만들게 됨. </li>

## Trainning Environment
<li> Dataset = Cifar10, CINIC10, Tiny ImageNet </li>
<li> python = 3.8.18 </li>
<li> pytorch = 2.4.1 + CUDA ??? </li>
<li> GPU = NVIDIA GeForce RTX 3080 </li>
<li> CPU = 12th Gen Intel(R) Core(TM) i5-12400F, 2500Mhz, 6 코어, 12 논리 프로세서 </li>
<li> epoch = 20 </li>
<li> batch size = 64 </li>
<li> learning rate = 0.0005 </li>
<li> optimizer = Adam </li>



## Evaluation


## Results